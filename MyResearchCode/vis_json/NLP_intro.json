{
    "BFSinput": {
        "0": {
            "10": [
                0
            ],
            "11": [
                0
            ]
        },
        "1": {
            "0": [
                1,
                25,
                27
            ],
            "10": [
                0
            ],
            "11": [
                0,
                24,
                25,
                27
            ],
            "24": [
                1
            ],
            "25": [
                24,
                27
            ],
            "27": [
                24
            ]
        },
        "2": {
            "0": [
                2
            ],
            "10": [
                0
            ],
            "11": [
                0,
                2
            ]
        },
        "3": {
            "0": [
                1,
                25,
                27
            ],
            "10": [
                0
            ],
            "11": [
                0,
                24,
                25,
                27
            ],
            "24": [
                1,
                3
            ],
            "25": [
                24,
                27
            ],
            "27": [
                24
            ]
        },
        "4": {
            "0": [
                1,
                4,
                25,
                27
            ],
            "1": [
                4,
                27
            ],
            "10": [
                0
            ],
            "11": [
                0,
                4,
                24,
                25,
                27
            ],
            "24": [
                1,
                4
            ],
            "25": [
                24,
                27
            ]
        },
        "5": {
            "0": [
                1,
                5,
                25,
                27
            ],
            "10": [
                0,
                5
            ],
            "11": [
                0,
                5,
                24,
                25,
                27
            ],
            "24": [
                1
            ],
            "25": [
                5,
                24,
                27
            ],
            "27": [
                5,
                24
            ]
        },
        "6": {},
        "7": {},
        "8": {},
        "9": {
            "0": [
                1,
                15,
                20,
                25,
                27
            ],
            "1": [
                20,
                27
            ],
            "10": [
                0
            ],
            "11": [
                0,
                20,
                24,
                25,
                27
            ],
            "15": [
                20
            ],
            "20": [
                9
            ],
            "24": [
                1
            ],
            "25": [
                24,
                27
            ]
        },
        "10": {},
        "11": {},
        "12": {},
        "13": {
            "12": [
                13
            ]
        },
        "14": {},
        "15": {
            "0": [
                15
            ],
            "10": [
                0
            ],
            "11": [
                0
            ]
        },
        "16": {},
        "17": {},
        "18": {
            "0": [
                1,
                18,
                25,
                27
            ],
            "1": [
                18,
                27
            ],
            "10": [
                0
            ],
            "11": [
                0,
                18,
                24,
                25,
                27
            ],
            "25": [
                24,
                27
            ],
            "27": [
                18,
                24
            ]
        },
        "19": {
            "0": [
                1,
                4,
                5,
                25,
                27
            ],
            "1": [
                4
            ],
            "4": [
                19
            ],
            "5": [
                19
            ],
            "7": [
                19
            ],
            "10": [
                0,
                5
            ],
            "11": [
                0,
                4,
                5,
                24,
                25,
                27
            ],
            "24": [
                1,
                4,
                19
            ],
            "25": [
                5,
                24,
                27
            ],
            "27": [
                5,
                24
            ]
        },
        "20": {
            "0": [
                1,
                15,
                20,
                25,
                27
            ],
            "1": [
                20,
                27
            ],
            "10": [
                0
            ],
            "11": [
                0,
                20,
                24,
                25,
                27
            ],
            "15": [
                20
            ],
            "24": [
                1
            ],
            "25": [
                24,
                27
            ]
        },
        "21": {
            "0": [
                1,
                15,
                25,
                27
            ],
            "10": [
                0
            ],
            "11": [
                0,
                24,
                25,
                27
            ],
            "15": [
                21
            ],
            "24": [
                1
            ],
            "25": [
                21,
                24,
                27
            ],
            "27": [
                21,
                24
            ]
        },
        "22": {
            "8": [
                22
            ],
            "11": [
                22
            ]
        },
        "23": {},
        "24": {
            "0": [
                1,
                25,
                27
            ],
            "10": [
                0
            ],
            "11": [
                0,
                24,
                25,
                27
            ],
            "24": [
                1
            ],
            "25": [
                24,
                27
            ],
            "27": [
                24
            ]
        },
        "25": {
            "0": [
                25
            ],
            "10": [
                0
            ],
            "11": [
                0,
                25
            ]
        },
        "26": {},
        "27": {
            "0": [
                1,
                25,
                27
            ],
            "10": [
                0
            ],
            "11": [
                0,
                24,
                25,
                27
            ],
            "24": [
                1
            ],
            "25": [
                24,
                27
            ],
            "27": [
                24
            ]
        },
        "28": {
            "0": [
                1,
                15,
                20,
                25,
                27
            ],
            "1": [
                20,
                27,
                28
            ],
            "10": [
                0
            ],
            "11": [
                0,
                20,
                24,
                25,
                27
            ],
            "15": [
                20,
                21
            ],
            "20": [
                28
            ],
            "21": [
                28
            ],
            "24": [
                1,
                28
            ],
            "25": [
                21,
                24,
                27
            ],
            "27": [
                21
            ]
        },
        "29": {
            "16": [
                29
            ]
        }
    },
    "RemovedCycleLinks": {
        "0": {},
        "1": {
            "1": [
                27
            ]
        },
        "2": {},
        "3": {
            "1": [
                27
            ]
        },
        "4": {
            "27": [
                24
            ]
        },
        "5": {
            "1": [
                27
            ]
        },
        "6": {},
        "7": {},
        "8": {},
        "9": {
            "27": [
                24
            ]
        },
        "10": {},
        "11": {},
        "12": {},
        "13": {},
        "14": {},
        "15": {},
        "16": {},
        "17": {},
        "18": {
            "24": [
                1
            ]
        },
        "19": {
            "1": [
                27
            ]
        },
        "20": {
            "27": [
                24
            ]
        },
        "21": {
            "1": [
                27
            ]
        },
        "22": {},
        "23": {},
        "24": {
            "1": [
                27
            ]
        },
        "25": {},
        "26": {},
        "27": {
            "1": [
                27
            ]
        },
        "28": {
            "27": [
                24
            ]
        },
        "29": {}
    },
    "VideoSequence_ConceptInfo": {
        "0": {
            "5isBs5WFbf0": [
                10
            ],
            "NT40U8zU1bg": [
                11,
                0
            ],
            "n25JjoixM3I": [
                0,
                11,
                10
            ]
        },
        "1": {
            "5isBs5WFbf0": [
                10,
                25,
                27
            ],
            "NT40U8zU1bg": [
                11,
                0
            ],
            "Sx3Fpw0XCXk": [
                24,
                27,
                0,
                25
            ],
            "n25JjoixM3I": [
                0,
                11,
                25,
                24,
                10,
                27
            ],
            "w9OUpjiu_zg": [
                27,
                1,
                11,
                25,
                24
            ]
        },
        "2": {
            "5isBs5WFbf0": [
                10
            ],
            "NT40U8zU1bg": [
                11,
                0
            ],
            "n25JjoixM3I": [
                0,
                11,
                2,
                10
            ]
        },
        "3": {
            "5isBs5WFbf0": [
                10,
                25,
                27
            ],
            "NT40U8zU1bg": [
                11,
                0
            ],
            "Sx3Fpw0XCXk": [
                24,
                3,
                27,
                0,
                25
            ],
            "n25JjoixM3I": [
                0,
                11,
                25,
                24,
                10,
                27
            ],
            "w9OUpjiu_zg": [
                27,
                1,
                11,
                25,
                24
            ]
        },
        "4": {
            "5isBs5WFbf0": [
                10,
                25,
                27
            ],
            "NT40U8zU1bg": [
                11,
                0
            ],
            "Sx3Fpw0XCXk": [
                24,
                27,
                0,
                25
            ],
            "fOvTtapxa9c": [
                11,
                4,
                10,
                24,
                1,
                0
            ],
            "n25JjoixM3I": [
                0,
                11,
                25,
                4,
                24,
                10,
                27
            ],
            "w9OUpjiu_zg": [
                27,
                1,
                11,
                25,
                24,
                4
            ]
        },
        "5": {
            "5isBs5WFbf0": [
                10,
                25,
                27
            ],
            "MNvT5JekDpg": [
                5,
                1,
                27,
                10,
                11,
                24,
                0,
                25
            ],
            "NT40U8zU1bg": [
                11,
                0
            ],
            "Sx3Fpw0XCXk": [
                24,
                27,
                0,
                25
            ],
            "n25JjoixM3I": [
                0,
                11,
                25,
                24,
                10,
                27,
                5
            ],
            "w9OUpjiu_zg": [
                27,
                1,
                11,
                25,
                24
            ]
        },
        "6": {},
        "7": {},
        "8": {},
        "9": {
            "5isBs5WFbf0": [
                10,
                25,
                27
            ],
            "NT40U8zU1bg": [
                11,
                0
            ],
            "Sx3Fpw0XCXk": [
                24,
                15,
                27,
                0,
                25
            ],
            "Y90BJzUcqlI": [
                10,
                11,
                9,
                25,
                0
            ],
            "fOvTtapxa9c": [
                20,
                11,
                10,
                15,
                24,
                1,
                0
            ],
            "n25JjoixM3I": [
                0,
                11,
                25,
                24,
                10,
                27
            ],
            "w9OUpjiu_zg": [
                27,
                1,
                11,
                25,
                24
            ]
        },
        "10": {},
        "11": {},
        "12": {},
        "13": {
            "d4gGtcobq8M": [
                13,
                12
            ]
        },
        "14": {},
        "15": {
            "5isBs5WFbf0": [
                10
            ],
            "NT40U8zU1bg": [
                11,
                0
            ],
            "Sx3Fpw0XCXk": [
                15,
                0
            ],
            "n25JjoixM3I": [
                0,
                11,
                10
            ]
        },
        "16": {},
        "17": {},
        "18": {
            "5isBs5WFbf0": [
                10,
                25,
                27
            ],
            "FLZvOKSCkxY": [
                0,
                18,
                11,
                10,
                1,
                25,
                27
            ],
            "NT40U8zU1bg": [
                11,
                0
            ],
            "Sx3Fpw0XCXk": [
                24,
                27,
                0,
                25
            ],
            "n25JjoixM3I": [
                0,
                11,
                25,
                24,
                10,
                27
            ],
            "w9OUpjiu_zg": [
                27,
                1,
                11,
                25,
                24
            ]
        },
        "19": {
            "5isBs5WFbf0": [
                10,
                25,
                27
            ],
            "MNvT5JekDpg": [
                5,
                1,
                27,
                10,
                11,
                24,
                0,
                25
            ],
            "NT40U8zU1bg": [
                11,
                0
            ],
            "Sx3Fpw0XCXk": [
                24,
                27,
                0,
                25
            ],
            "fOvTtapxa9c": [
                11,
                4,
                10,
                24,
                1,
                0
            ],
            "n25JjoixM3I": [
                0,
                11,
                19,
                25,
                4,
                24,
                10,
                27,
                5,
                7
            ],
            "w9OUpjiu_zg": [
                27,
                1,
                11,
                25,
                24,
                4
            ],
            "yKN8a8jgIN8": [
                7,
                1,
                19
            ]
        },
        "20": {
            "5isBs5WFbf0": [
                10,
                25,
                27
            ],
            "NT40U8zU1bg": [
                11,
                0
            ],
            "Sx3Fpw0XCXk": [
                24,
                15,
                27,
                0,
                25
            ],
            "fOvTtapxa9c": [
                20,
                11,
                10,
                15,
                24,
                1,
                0
            ],
            "n25JjoixM3I": [
                0,
                11,
                25,
                24,
                10,
                27
            ],
            "w9OUpjiu_zg": [
                27,
                1,
                11,
                25,
                24
            ]
        },
        "21": {
            "5isBs5WFbf0": [
                10,
                25,
                27
            ],
            "MNvT5JekDpg": [
                21,
                1,
                27,
                10,
                11,
                24,
                0,
                25
            ],
            "NT40U8zU1bg": [
                11,
                0
            ],
            "Sx3Fpw0XCXk": [
                24,
                15,
                27,
                0,
                21,
                25
            ],
            "n25JjoixM3I": [
                0,
                11,
                25,
                24,
                10,
                27
            ],
            "w9OUpjiu_zg": [
                27,
                1,
                11,
                25,
                24
            ]
        },
        "22": {
            "FLZvOKSCkxY": [
                22,
                11
            ],
            "NT40U8zU1bg": [
                11,
                8,
                22
            ]
        },
        "23": {},
        "24": {
            "5isBs5WFbf0": [
                10,
                25,
                27
            ],
            "NT40U8zU1bg": [
                11,
                0
            ],
            "Sx3Fpw0XCXk": [
                24,
                27,
                0,
                25
            ],
            "n25JjoixM3I": [
                0,
                11,
                25,
                24,
                10,
                27
            ],
            "w9OUpjiu_zg": [
                27,
                1,
                11,
                25,
                24
            ]
        },
        "25": {
            "5isBs5WFbf0": [
                10,
                25
            ],
            "NT40U8zU1bg": [
                11,
                0
            ],
            "n25JjoixM3I": [
                0,
                11,
                25,
                10
            ]
        },
        "26": {},
        "27": {
            "5isBs5WFbf0": [
                10,
                25,
                27
            ],
            "NT40U8zU1bg": [
                11,
                0
            ],
            "Sx3Fpw0XCXk": [
                24,
                27,
                0,
                25
            ],
            "n25JjoixM3I": [
                0,
                11,
                25,
                24,
                10,
                27
            ],
            "w9OUpjiu_zg": [
                27,
                1,
                11,
                25,
                24
            ]
        },
        "28": {
            "5isBs5WFbf0": [
                10,
                25,
                27
            ],
            "MNvT5JekDpg": [
                21,
                28,
                1,
                27,
                10,
                11,
                24,
                0,
                25
            ],
            "NT40U8zU1bg": [
                11,
                0
            ],
            "Sx3Fpw0XCXk": [
                24,
                15,
                27,
                0,
                21,
                25
            ],
            "fOvTtapxa9c": [
                20,
                11,
                10,
                15,
                24,
                1,
                0
            ],
            "n25JjoixM3I": [
                0,
                11,
                25,
                24,
                10,
                27
            ],
            "w9OUpjiu_zg": [
                27,
                1,
                11,
                25,
                24
            ]
        },
        "29": {
            "w9OUpjiu_zg": [
                16,
                29
            ]
        }
    },
    "concept_relationship": {
        "links": [
            {
                "prerequisite": null,
                "similarity": 0.9999999999999999,
                "source": 0,
                "target": 0
            },
            {
                "prerequisite": 0.3894715268520792,
                "similarity": 0.5238612787525829,
                "source": 0,
                "target": 1
            },
            {
                "prerequisite": 3.0843973206045314,
                "similarity": 0.5081988897471611,
                "source": 0,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.12909944487358055,
                "source": 0,
                "target": 3
            },
            {
                "prerequisite": 2.919274129105488,
                "similarity": 0.44364916731037085,
                "source": 0,
                "target": 4
            },
            {
                "prerequisite": 5.111968527418952,
                "similarity": 0.6825741858350554,
                "source": 0,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.12909944487358055,
                "source": 0,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.09128709291752767,
                "source": 0,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.09128709291752767,
                "source": 0,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.18257418583505533,
                "source": 0,
                "target": 9
            },
            {
                "prerequisite": 0.46971004105568315,
                "similarity": 0.6599457958749615,
                "source": 10,
                "target": 0
            },
            {
                "prerequisite": 0.000622423746367784,
                "similarity": 0.6796689244236598,
                "source": 11,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.12909944487358055,
                "source": 0,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.12909944487358055,
                "source": 0,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 0,
                "target": 14
            },
            {
                "prerequisite": 5.534010017357358,
                "similarity": 0.6825741858350554,
                "source": 0,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 0,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 0,
                "target": 17
            },
            {
                "prerequisite": 4.23299677186381,
                "similarity": 0.7236067977499789,
                "source": 0,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.09128709291752767,
                "source": 0,
                "target": 19
            },
            {
                "prerequisite": 5.180292500678623,
                "similarity": 0.6825741858350554,
                "source": 0,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.18257418583505533,
                "source": 0,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.223606797749979,
                "source": 0,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 0,
                "target": 23
            },
            {
                "prerequisite": null,
                "similarity": 0.2927700218845599,
                "source": 0,
                "target": 24
            },
            {
                "prerequisite": 1.1590326444161843,
                "similarity": 0.5512320380383546,
                "source": 0,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 0.12909944487358055,
                "source": 0,
                "target": 26
            },
            {
                "prerequisite": 0.14915427430857842,
                "similarity": 0.5238612787525829,
                "source": 0,
                "target": 27
            },
            {
                "prerequisite": null,
                "similarity": 0.37909944487358055,
                "source": 0,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 0,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.5238612787525829,
                "source": 1,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 1.0,
                "source": 1,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.42677669529663687,
                "source": 1,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 1,
                "target": 3
            },
            {
                "prerequisite": 1.4380142003600227,
                "similarity": 0.7651650429449552,
                "source": 1,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.375,
                "source": 1,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 1,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.375,
                "source": 1,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 1,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 1,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.2551551815399144,
                "source": 1,
                "target": 10
            },
            {
                "prerequisite": null,
                "similarity": 0.294174202707276,
                "source": 1,
                "target": 11
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 1,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 1,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 1,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.375,
                "source": 1,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 1,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 1,
                "target": 17
            },
            {
                "prerequisite": 4.192161609856004,
                "similarity": 0.4541241452319315,
                "source": 1,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.12499999999999997,
                "source": 1,
                "target": 19
            },
            {
                "prerequisite": 3.4990428818646166,
                "similarity": 0.625,
                "source": 1,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.12499999999999997,
                "source": 1,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.2041241452319315,
                "source": 1,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 1,
                "target": 23
            },
            {
                "prerequisite": 0.40655489664740974,
                "similarity": 0.8340765523905305,
                "source": 24,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.42677669529663687,
                "source": 1,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 1,
                "target": 26
            },
            {
                "prerequisite": 0.055798831314478825,
                "similarity": 0.49999999999999994,
                "source": 1,
                "target": 27
            },
            {
                "prerequisite": 3.9726865588047797,
                "similarity": 0.6767766952966369,
                "source": 1,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 1,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.5081988897471611,
                "source": 2,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.42677669529663687,
                "source": 2,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 1.0,
                "source": 2,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 2,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 2,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 2,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 2,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 2,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 2,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 2,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.2886751345948129,
                "source": 2,
                "target": 10
            },
            {
                "prerequisite": 3.62126610839938,
                "similarity": 0.5273500981126146,
                "source": 11,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 2,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 2,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 2,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 2,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 2,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 2,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 0.2886751345948129,
                "source": 2,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 2,
                "target": 19
            },
            {
                "prerequisite": null,
                "similarity": 0.42677669529663687,
                "source": 2,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 2,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.39433756729740643,
                "source": 2,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 2,
                "target": 23
            },
            {
                "prerequisite": null,
                "similarity": 0.28347335475692037,
                "source": 2,
                "target": 24
            },
            {
                "prerequisite": null,
                "similarity": 0.3333333333333333,
                "source": 2,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 2,
                "target": 26
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 2,
                "target": 27
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 2,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 2,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.12909944487358055,
                "source": 3,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 3,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 3,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 1.0,
                "source": 3,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 3,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 3,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 3,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 3,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 3,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 3,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 3,
                "target": 10
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 3,
                "target": 11
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 3,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 3,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 3,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.35355339059327373,
                "source": 3,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 3,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 3,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 3,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 3,
                "target": 19
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 3,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.35355339059327373,
                "source": 3,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 3,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 3,
                "target": 23
            },
            {
                "prerequisite": 3.187142449951186,
                "similarity": 0.4389822365046136,
                "source": 24,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.41666666666666663,
                "source": 3,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 3,
                "target": 26
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 3,
                "target": 27
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 3,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 3,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.44364916731037085,
                "source": 4,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.7651650429449552,
                "source": 4,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 4,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 4,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 1.0,
                "source": 4,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 4,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 4,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 4,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 4,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 4,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.14433756729740646,
                "source": 4,
                "target": 10
            },
            {
                "prerequisite": 4.100384542271943,
                "similarity": 0.5273500981126146,
                "source": 11,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 4,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 4,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 4,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 4,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 4,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 4,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 4,
                "target": 18
            },
            {
                "prerequisite": 1.8567290251753448,
                "similarity": 0.6767766952966369,
                "source": 4,
                "target": 19
            },
            {
                "prerequisite": null,
                "similarity": 0.42677669529663687,
                "source": 4,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 4,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 4,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 4,
                "target": 23
            },
            {
                "prerequisite": 1.524960420241468,
                "similarity": 0.5334733547569204,
                "source": 24,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.41666666666666663,
                "source": 4,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 4,
                "target": 26
            },
            {
                "prerequisite": null,
                "similarity": 0.42677669529663687,
                "source": 4,
                "target": 27
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 4,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 4,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.6825741858350554,
                "source": 5,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.375,
                "source": 5,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 5,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 5,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 5,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.9999999999999999,
                "source": 5,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 5,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.24999999999999994,
                "source": 5,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 5,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 5,
                "target": 9
            },
            {
                "prerequisite": 4.843628746868234,
                "similarity": 0.4541241452319315,
                "source": 10,
                "target": 5
            },
            {
                "prerequisite": 4.6091915277224755,
                "similarity": 0.44611613513818404,
                "source": 11,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 5,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 5,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 5,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 5,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 5,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 5,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 5,
                "target": 18
            },
            {
                "prerequisite": 1.1148221838076169,
                "similarity": 0.49999999999999994,
                "source": 5,
                "target": 19
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 5,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.24999999999999994,
                "source": 5,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 5,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 5,
                "target": 23
            },
            {
                "prerequisite": null,
                "similarity": 0.26726124191242434,
                "source": 5,
                "target": 24
            },
            {
                "prerequisite": 4.025763757032227,
                "similarity": 0.4857022603955158,
                "source": 25,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 5,
                "target": 26
            },
            {
                "prerequisite": 4.071878689746962,
                "similarity": 0.49999999999999994,
                "source": 27,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.35355339059327373,
                "source": 5,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 5,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.12909944487358055,
                "source": 6,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 6,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 6,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 6,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 6,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 6,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 1.0,
                "source": 6,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 6,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 6,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.35355339059327373,
                "source": 6,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 6,
                "target": 10
            },
            {
                "prerequisite": null,
                "similarity": 0.1386750490563073,
                "source": 6,
                "target": 11
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 6,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 6,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 6,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 6,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 6,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 6,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 6,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 6,
                "target": 19
            },
            {
                "prerequisite": null,
                "similarity": 0.35355339059327373,
                "source": 6,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 6,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 6,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 6,
                "target": 23
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 6,
                "target": 24
            },
            {
                "prerequisite": null,
                "similarity": 0.16666666666666666,
                "source": 6,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 6,
                "target": 26
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 6,
                "target": 27
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 6,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 6,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.09128709291752767,
                "source": 7,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.375,
                "source": 7,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 7,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 7,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 7,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.24999999999999994,
                "source": 7,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 7,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.9999999999999999,
                "source": 7,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 7,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 7,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.10206207261596575,
                "source": 7,
                "target": 10
            },
            {
                "prerequisite": null,
                "similarity": 0.09805806756909201,
                "source": 7,
                "target": 11
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 7,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 7,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 7,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 7,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 7,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.35355339059327373,
                "source": 7,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 7,
                "target": 18
            },
            {
                "prerequisite": 0.02071897537887457,
                "similarity": 0.4999999999999999,
                "source": 7,
                "target": 19
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 7,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 7,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 7,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 7,
                "target": 23
            },
            {
                "prerequisite": null,
                "similarity": 0.13363062095621217,
                "source": 7,
                "target": 24
            },
            {
                "prerequisite": null,
                "similarity": 0.1178511301977579,
                "source": 7,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 7,
                "target": 26
            },
            {
                "prerequisite": null,
                "similarity": 0.12499999999999997,
                "source": 7,
                "target": 27
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 7,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 7,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.09128709291752767,
                "source": 8,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 8,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 8,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 8,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 8,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 8,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 8,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 8,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.9999999999999999,
                "source": 8,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 8,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 8,
                "target": 10
            },
            {
                "prerequisite": null,
                "similarity": 0.09805806756909201,
                "source": 8,
                "target": 11
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 8,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 8,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 8,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 8,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 8,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 8,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 8,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 8,
                "target": 19
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 8,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 8,
                "target": 21
            },
            {
                "prerequisite": 0.8593771796805546,
                "similarity": 0.4541241452319315,
                "source": 8,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.35355339059327373,
                "source": 8,
                "target": 23
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 8,
                "target": 24
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 8,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 0.35355339059327373,
                "source": 8,
                "target": 26
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 8,
                "target": 27
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 8,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 8,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.18257418583505533,
                "source": 9,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 9,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 9,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 9,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 9,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 9,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.35355339059327373,
                "source": 9,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 9,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 9,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.9999999999999999,
                "source": 9,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.10206207261596575,
                "source": 9,
                "target": 10
            },
            {
                "prerequisite": null,
                "similarity": 0.19611613513818402,
                "source": 9,
                "target": 11
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 9,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 9,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 9,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 9,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 9,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 9,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 9,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 9,
                "target": 19
            },
            {
                "prerequisite": 1.2844981006680096,
                "similarity": 0.49999999999999994,
                "source": 20,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 9,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 9,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 9,
                "target": 23
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 9,
                "target": 24
            },
            {
                "prerequisite": null,
                "similarity": 0.2357022603955158,
                "source": 9,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 9,
                "target": 26
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 9,
                "target": 27
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 9,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 9,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.6599457958749615,
                "source": 10,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.2551551815399144,
                "source": 10,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.2886751345948129,
                "source": 10,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 10,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.14433756729740646,
                "source": 10,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.4541241452319315,
                "source": 10,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 10,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.10206207261596575,
                "source": 10,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 10,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.10206207261596575,
                "source": 10,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 1.0,
                "source": 10,
                "target": 10
            },
            {
                "prerequisite": null,
                "similarity": 0.3602883460614461,
                "source": 10,
                "target": 11
            },
            {
                "prerequisite": null,
                "similarity": 0.14433756729740646,
                "source": 10,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.14433756729740646,
                "source": 10,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.39433756729740643,
                "source": 10,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.10206207261596575,
                "source": 10,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 10,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 10,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 0.25000000000000006,
                "source": 10,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.10206207261596575,
                "source": 10,
                "target": 19
            },
            {
                "prerequisite": null,
                "similarity": 0.3520620726159658,
                "source": 10,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.10206207261596575,
                "source": 10,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.1666666666666667,
                "source": 10,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 10,
                "target": 23
            },
            {
                "prerequisite": null,
                "similarity": 0.2727723627949905,
                "source": 10,
                "target": 24
            },
            {
                "prerequisite": null,
                "similarity": 0.2886751345948129,
                "source": 10,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 10,
                "target": 26
            },
            {
                "prerequisite": null,
                "similarity": 0.3061862178478973,
                "source": 10,
                "target": 27
            },
            {
                "prerequisite": null,
                "similarity": 0.14433756729740646,
                "source": 10,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 10,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.6796689244236598,
                "source": 11,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.294174202707276,
                "source": 11,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.5273500981126146,
                "source": 11,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 11,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.5273500981126146,
                "source": 11,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.44611613513818404,
                "source": 11,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.1386750490563073,
                "source": 11,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.09805806756909201,
                "source": 11,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.09805806756909201,
                "source": 11,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.19611613513818402,
                "source": 11,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.3602883460614461,
                "source": 11,
                "target": 10
            },
            {
                "prerequisite": null,
                "similarity": 0.9999999999999999,
                "source": 11,
                "target": 11
            },
            {
                "prerequisite": null,
                "similarity": 0.1386750490563073,
                "source": 11,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.1386750490563073,
                "source": 11,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 11,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.09805806756909201,
                "source": 11,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.1386750490563073,
                "source": 11,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 11,
                "target": 17
            },
            {
                "prerequisite": 4.992797801988416,
                "similarity": 0.49019223070763074,
                "source": 11,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.09805806756909201,
                "source": 11,
                "target": 19
            },
            {
                "prerequisite": 5.511961418580978,
                "similarity": 0.44611613513818404,
                "source": 11,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.348058067569092,
                "source": 11,
                "target": 21
            },
            {
                "prerequisite": 4.528485449702682,
                "similarity": 0.49019223070763074,
                "source": 11,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 11,
                "target": 23
            },
            {
                "prerequisite": 2.160140739087246,
                "similarity": 0.5120712091804795,
                "source": 11,
                "target": 24
            },
            {
                "prerequisite": 1.186547348427453,
                "similarity": 0.573575114464717,
                "source": 11,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 0.1386750490563073,
                "source": 11,
                "target": 26
            },
            {
                "prerequisite": 2.5064267063317907,
                "similarity": 0.49514516892273003,
                "source": 11,
                "target": 27
            },
            {
                "prerequisite": null,
                "similarity": 0.3886750490563073,
                "source": 11,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.1386750490563073,
                "source": 11,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.12909944487358055,
                "source": 12,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 12,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 12,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 12,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 12,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 12,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 12,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 12,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 12,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 12,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.14433756729740646,
                "source": 12,
                "target": 10
            },
            {
                "prerequisite": null,
                "similarity": 0.1386750490563073,
                "source": 12,
                "target": 11
            },
            {
                "prerequisite": null,
                "similarity": 1.0,
                "source": 12,
                "target": 12
            },
            {
                "prerequisite": 0.10735928988584309,
                "similarity": 0.5,
                "source": 12,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 12,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 12,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 12,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 12,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 12,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 12,
                "target": 19
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 12,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 12,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 12,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 12,
                "target": 23
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 12,
                "target": 24
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 12,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 12,
                "target": 26
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 12,
                "target": 27
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 12,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 12,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.12909944487358055,
                "source": 13,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 13,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 13,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 13,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 13,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 13,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 13,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 13,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 13,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 13,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.14433756729740646,
                "source": 13,
                "target": 10
            },
            {
                "prerequisite": null,
                "similarity": 0.1386750490563073,
                "source": 13,
                "target": 11
            },
            {
                "prerequisite": null,
                "similarity": 0.5,
                "source": 13,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 1.0,
                "source": 13,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 13,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 13,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 13,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 13,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 13,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 13,
                "target": 19
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 13,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 13,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 13,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 13,
                "target": 23
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 13,
                "target": 24
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 13,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 13,
                "target": 26
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 13,
                "target": 27
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 13,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 13,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 14,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 14,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 14,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 14,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 14,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 14,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 14,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 14,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 14,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 14,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.39433756729740643,
                "source": 14,
                "target": 10
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 14,
                "target": 11
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 14,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 14,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 1.0,
                "source": 14,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 14,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 14,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 14,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 14,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 14,
                "target": 19
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 14,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 14,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 14,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 14,
                "target": 23
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 14,
                "target": 24
            },
            {
                "prerequisite": null,
                "similarity": 0.41666666666666663,
                "source": 14,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 14,
                "target": 26
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 14,
                "target": 27
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 14,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 14,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.6825741858350554,
                "source": 15,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.375,
                "source": 15,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 15,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.35355339059327373,
                "source": 15,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 15,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 15,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 15,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 15,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 15,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 15,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.10206207261596575,
                "source": 15,
                "target": 10
            },
            {
                "prerequisite": null,
                "similarity": 0.09805806756909201,
                "source": 15,
                "target": 11
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 15,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 15,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 15,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.9999999999999999,
                "source": 15,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 15,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 15,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 15,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 15,
                "target": 19
            },
            {
                "prerequisite": 1.7203620972824518,
                "similarity": 0.75,
                "source": 15,
                "target": 20
            },
            {
                "prerequisite": 0.015767769297493794,
                "similarity": 0.49999999999999994,
                "source": 15,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 15,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 15,
                "target": 23
            },
            {
                "prerequisite": null,
                "similarity": 0.26726124191242434,
                "source": 15,
                "target": 24
            },
            {
                "prerequisite": null,
                "similarity": 0.3678511301977579,
                "source": 15,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 15,
                "target": 26
            },
            {
                "prerequisite": null,
                "similarity": 0.375,
                "source": 15,
                "target": 27
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 15,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 15,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 16,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 16,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 16,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 16,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 16,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 16,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 16,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 16,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 16,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 16,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 16,
                "target": 10
            },
            {
                "prerequisite": null,
                "similarity": 0.1386750490563073,
                "source": 16,
                "target": 11
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 16,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 16,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 16,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 16,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 1.0,
                "source": 16,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 16,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 16,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 16,
                "target": 19
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 16,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 16,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 16,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 16,
                "target": 23
            },
            {
                "prerequisite": null,
                "similarity": 0.1889822365046136,
                "source": 16,
                "target": 24
            },
            {
                "prerequisite": null,
                "similarity": 0.16666666666666666,
                "source": 16,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 16,
                "target": 26
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 16,
                "target": 27
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 16,
                "target": 28
            },
            {
                "prerequisite": 0.3138287682108164,
                "similarity": 0.5,
                "source": 16,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 17,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 17,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 17,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 17,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 17,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 17,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 17,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.35355339059327373,
                "source": 17,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 17,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 17,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 17,
                "target": 10
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 17,
                "target": 11
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 17,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 17,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 17,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 17,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 17,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 1.0,
                "source": 17,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 17,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.35355339059327373,
                "source": 17,
                "target": 19
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 17,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 17,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 17,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 17,
                "target": 23
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 17,
                "target": 24
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 17,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 17,
                "target": 26
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 17,
                "target": 27
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 17,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 17,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.7236067977499789,
                "source": 18,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.4541241452319315,
                "source": 18,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.2886751345948129,
                "source": 18,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 18,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 18,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 18,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 18,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 18,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 18,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 18,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.25000000000000006,
                "source": 18,
                "target": 10
            },
            {
                "prerequisite": null,
                "similarity": 0.49019223070763074,
                "source": 18,
                "target": 11
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 18,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 18,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 18,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 18,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 18,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 18,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 1.0,
                "source": 18,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 18,
                "target": 19
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 18,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 18,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.3333333333333334,
                "source": 18,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 18,
                "target": 23
            },
            {
                "prerequisite": null,
                "similarity": 0.1091089451179962,
                "source": 18,
                "target": 24
            },
            {
                "prerequisite": null,
                "similarity": 0.34622504486493766,
                "source": 18,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 18,
                "target": 26
            },
            {
                "prerequisite": 3.5080440493441283,
                "similarity": 0.4541241452319315,
                "source": 27,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 18,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 18,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.09128709291752767,
                "source": 19,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.12499999999999997,
                "source": 19,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 19,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 19,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.6767766952966369,
                "source": 19,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.49999999999999994,
                "source": 19,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 19,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.4999999999999999,
                "source": 19,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 19,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 19,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.10206207261596575,
                "source": 19,
                "target": 10
            },
            {
                "prerequisite": null,
                "similarity": 0.09805806756909201,
                "source": 19,
                "target": 11
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 19,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 19,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 19,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 19,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 19,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.35355339059327373,
                "source": 19,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 19,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.9999999999999999,
                "source": 19,
                "target": 19
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 19,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 19,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 19,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 19,
                "target": 23
            },
            {
                "prerequisite": 2.959971790428772,
                "similarity": 0.6336306209562121,
                "source": 24,
                "target": 19
            },
            {
                "prerequisite": null,
                "similarity": 0.3678511301977579,
                "source": 19,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 19,
                "target": 26
            },
            {
                "prerequisite": null,
                "similarity": 0.12499999999999997,
                "source": 19,
                "target": 27
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 19,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 19,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.6825741858350554,
                "source": 20,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.625,
                "source": 20,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.42677669529663687,
                "source": 20,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 20,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.42677669529663687,
                "source": 20,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 20,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.35355339059327373,
                "source": 20,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 20,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 20,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.49999999999999994,
                "source": 20,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.3520620726159658,
                "source": 20,
                "target": 10
            },
            {
                "prerequisite": null,
                "similarity": 0.44611613513818404,
                "source": 20,
                "target": 11
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 20,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 20,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 20,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.75,
                "source": 20,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 20,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 20,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 20,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 20,
                "target": 19
            },
            {
                "prerequisite": null,
                "similarity": 0.9999999999999999,
                "source": 20,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 20,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 20,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 20,
                "target": 23
            },
            {
                "prerequisite": null,
                "similarity": 0.38363062095621214,
                "source": 20,
                "target": 24
            },
            {
                "prerequisite": null,
                "similarity": 0.3678511301977579,
                "source": 20,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 20,
                "target": 26
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 20,
                "target": 27
            },
            {
                "prerequisite": 0.33578788205919197,
                "similarity": 0.5,
                "source": 20,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 20,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.18257418583505533,
                "source": 21,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.12499999999999997,
                "source": 21,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 21,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.35355339059327373,
                "source": 21,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 21,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.24999999999999994,
                "source": 21,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 21,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 21,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 21,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 21,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.10206207261596575,
                "source": 21,
                "target": 10
            },
            {
                "prerequisite": null,
                "similarity": 0.348058067569092,
                "source": 21,
                "target": 11
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 21,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 21,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 21,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.49999999999999994,
                "source": 21,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 21,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 21,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 21,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 21,
                "target": 19
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 21,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.9999999999999999,
                "source": 21,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 21,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 21,
                "target": 23
            },
            {
                "prerequisite": null,
                "similarity": 0.26726124191242434,
                "source": 21,
                "target": 24
            },
            {
                "prerequisite": 4.23895532364768,
                "similarity": 0.4857022603955158,
                "source": 25,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 21,
                "target": 26
            },
            {
                "prerequisite": 3.8174750887780307,
                "similarity": 0.49999999999999994,
                "source": 27,
                "target": 21
            },
            {
                "prerequisite": 0.012424816908706893,
                "similarity": 0.6035533905932737,
                "source": 21,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 21,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.223606797749979,
                "source": 22,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.2041241452319315,
                "source": 22,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.39433756729740643,
                "source": 22,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 22,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 22,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 22,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 22,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 22,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.4541241452319315,
                "source": 22,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 22,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.1666666666666667,
                "source": 22,
                "target": 10
            },
            {
                "prerequisite": null,
                "similarity": 0.49019223070763074,
                "source": 22,
                "target": 11
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 22,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 22,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 22,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 22,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 22,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 22,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 0.3333333333333334,
                "source": 22,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 22,
                "target": 19
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 22,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 22,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 1.0,
                "source": 22,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 22,
                "target": 23
            },
            {
                "prerequisite": null,
                "similarity": 0.1091089451179962,
                "source": 22,
                "target": 24
            },
            {
                "prerequisite": null,
                "similarity": 0.34622504486493766,
                "source": 22,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 0.2886751345948129,
                "source": 22,
                "target": 26
            },
            {
                "prerequisite": null,
                "similarity": 0.10206207261596575,
                "source": 22,
                "target": 27
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 22,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 22,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 23,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 23,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 23,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 23,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 23,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 23,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 23,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 23,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.35355339059327373,
                "source": 23,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 23,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 23,
                "target": 10
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 23,
                "target": 11
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 23,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 23,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 23,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 23,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 23,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 23,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 23,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 23,
                "target": 19
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 23,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 23,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 23,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 1.0,
                "source": 23,
                "target": 23
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 23,
                "target": 24
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 23,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 23,
                "target": 26
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 23,
                "target": 27
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 23,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 23,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.2927700218845599,
                "source": 24,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.8340765523905305,
                "source": 24,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.28347335475692037,
                "source": 24,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.4389822365046136,
                "source": 24,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.5334733547569204,
                "source": 24,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.26726124191242434,
                "source": 24,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 24,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.13363062095621217,
                "source": 24,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 24,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 24,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.2727723627949905,
                "source": 24,
                "target": 10
            },
            {
                "prerequisite": null,
                "similarity": 0.5120712091804795,
                "source": 24,
                "target": 11
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 24,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 24,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 24,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.26726124191242434,
                "source": 24,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.1889822365046136,
                "source": 24,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 24,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 0.1091089451179962,
                "source": 24,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.6336306209562121,
                "source": 24,
                "target": 19
            },
            {
                "prerequisite": null,
                "similarity": 0.38363062095621214,
                "source": 24,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.26726124191242434,
                "source": 24,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.1091089451179962,
                "source": 24,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 24,
                "target": 23
            },
            {
                "prerequisite": null,
                "similarity": 0.9999999999999998,
                "source": 24,
                "target": 24
            },
            {
                "prerequisite": 1.3782603483109457,
                "similarity": 0.5019763153394847,
                "source": 25,
                "target": 24
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 24,
                "target": 26
            },
            {
                "prerequisite": 0.13900239972131934,
                "similarity": 0.5840765523905305,
                "source": 27,
                "target": 24
            },
            {
                "prerequisite": 4.280266162681741,
                "similarity": 0.6889822365046137,
                "source": 24,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.1889822365046136,
                "source": 24,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.5512320380383546,
                "source": 25,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.42677669529663687,
                "source": 25,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.3333333333333333,
                "source": 25,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.41666666666666663,
                "source": 25,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.41666666666666663,
                "source": 25,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.4857022603955158,
                "source": 25,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.16666666666666666,
                "source": 25,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.1178511301977579,
                "source": 25,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 25,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.2357022603955158,
                "source": 25,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.2886751345948129,
                "source": 25,
                "target": 10
            },
            {
                "prerequisite": null,
                "similarity": 0.573575114464717,
                "source": 25,
                "target": 11
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 25,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 25,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.41666666666666663,
                "source": 25,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.3678511301977579,
                "source": 25,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.16666666666666666,
                "source": 25,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 25,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 0.34622504486493766,
                "source": 25,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.3678511301977579,
                "source": 25,
                "target": 19
            },
            {
                "prerequisite": null,
                "similarity": 0.3678511301977579,
                "source": 25,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.4857022603955158,
                "source": 25,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.34622504486493766,
                "source": 25,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 25,
                "target": 23
            },
            {
                "prerequisite": null,
                "similarity": 0.5019763153394847,
                "source": 25,
                "target": 24
            },
            {
                "prerequisite": null,
                "similarity": 1.0,
                "source": 25,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 25,
                "target": 26
            },
            {
                "prerequisite": 1.8292647433180842,
                "similarity": 0.6035533905932737,
                "source": 25,
                "target": 27
            },
            {
                "prerequisite": null,
                "similarity": 0.41666666666666663,
                "source": 25,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.41666666666666663,
                "source": 25,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.12909944487358055,
                "source": 26,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 26,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 26,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 26,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 26,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 26,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 26,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 26,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.35355339059327373,
                "source": 26,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 26,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 26,
                "target": 10
            },
            {
                "prerequisite": null,
                "similarity": 0.1386750490563073,
                "source": 26,
                "target": 11
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 26,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 26,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 26,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 26,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 26,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 26,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 26,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 26,
                "target": 19
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 26,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 26,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.2886751345948129,
                "source": 26,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 26,
                "target": 23
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 26,
                "target": 24
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 26,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 1.0,
                "source": 26,
                "target": 26
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 26,
                "target": 27
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 26,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 26,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.5238612787525829,
                "source": 27,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.49999999999999994,
                "source": 27,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 27,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 27,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.42677669529663687,
                "source": 27,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.49999999999999994,
                "source": 27,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 27,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.12499999999999997,
                "source": 27,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 27,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 27,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.3061862178478973,
                "source": 27,
                "target": 10
            },
            {
                "prerequisite": null,
                "similarity": 0.49514516892273003,
                "source": 27,
                "target": 11
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 27,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 27,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 27,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.375,
                "source": 27,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 27,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 27,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 0.4541241452319315,
                "source": 27,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.12499999999999997,
                "source": 27,
                "target": 19
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 27,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.49999999999999994,
                "source": 27,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.10206207261596575,
                "source": 27,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 27,
                "target": 23
            },
            {
                "prerequisite": null,
                "similarity": 0.5840765523905305,
                "source": 27,
                "target": 24
            },
            {
                "prerequisite": null,
                "similarity": 0.6035533905932737,
                "source": 27,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 27,
                "target": 26
            },
            {
                "prerequisite": null,
                "similarity": 1.0,
                "source": 27,
                "target": 27
            },
            {
                "prerequisite": null,
                "similarity": 0.42677669529663687,
                "source": 27,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.42677669529663687,
                "source": 27,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.37909944487358055,
                "source": 28,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.6767766952966369,
                "source": 28,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 28,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 28,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 28,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.35355339059327373,
                "source": 28,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 28,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 28,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 28,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 28,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.14433756729740646,
                "source": 28,
                "target": 10
            },
            {
                "prerequisite": null,
                "similarity": 0.3886750490563073,
                "source": 28,
                "target": 11
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 28,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 28,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 28,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 28,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 28,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 28,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 28,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 28,
                "target": 19
            },
            {
                "prerequisite": null,
                "similarity": 0.5,
                "source": 28,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.6035533905932737,
                "source": 28,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 28,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 28,
                "target": 23
            },
            {
                "prerequisite": null,
                "similarity": 0.6889822365046137,
                "source": 28,
                "target": 24
            },
            {
                "prerequisite": null,
                "similarity": 0.41666666666666663,
                "source": 28,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 28,
                "target": 26
            },
            {
                "prerequisite": null,
                "similarity": 0.42677669529663687,
                "source": 28,
                "target": 27
            },
            {
                "prerequisite": null,
                "similarity": 1.0,
                "source": 28,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 28,
                "target": 29
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 29,
                "target": 0
            },
            {
                "prerequisite": null,
                "similarity": 0.17677669529663687,
                "source": 29,
                "target": 1
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 29,
                "target": 2
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 29,
                "target": 3
            },
            {
                "prerequisite": null,
                "similarity": 0.25,
                "source": 29,
                "target": 4
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 29,
                "target": 5
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 29,
                "target": 6
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 29,
                "target": 7
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 29,
                "target": 8
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 29,
                "target": 9
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 29,
                "target": 10
            },
            {
                "prerequisite": null,
                "similarity": 0.1386750490563073,
                "source": 29,
                "target": 11
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 29,
                "target": 12
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 29,
                "target": 13
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 29,
                "target": 14
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 29,
                "target": 15
            },
            {
                "prerequisite": null,
                "similarity": 0.5,
                "source": 29,
                "target": 16
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 29,
                "target": 17
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 29,
                "target": 18
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 29,
                "target": 19
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 29,
                "target": 20
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 29,
                "target": 21
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 29,
                "target": 22
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 29,
                "target": 23
            },
            {
                "prerequisite": null,
                "similarity": 0.1889822365046136,
                "source": 29,
                "target": 24
            },
            {
                "prerequisite": null,
                "similarity": 0.41666666666666663,
                "source": 29,
                "target": 25
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 29,
                "target": 26
            },
            {
                "prerequisite": null,
                "similarity": 0.42677669529663687,
                "source": 29,
                "target": 27
            },
            {
                "prerequisite": null,
                "similarity": 0.0,
                "source": 29,
                "target": 28
            },
            {
                "prerequisite": null,
                "similarity": 1.0,
                "source": 29,
                "target": 29
            }
        ],
        "nodes": [
            {
                "conceptCountForEachVid": {
                    "3Q8wacwA4gs": 2,
                    "4vLlF3flSeg": 16,
                    "FLZvOKSCkxY": 7,
                    "GDso6md3DBw": 2,
                    "LAtzapS2GBU": 11,
                    "MC97BZqdq0w": 5,
                    "MNvT5JekDpg": 2,
                    "NT40U8zU1bg": 3,
                    "Sx3Fpw0XCXk": 1,
                    "Y90BJzUcqlI": 1,
                    "_RY1QUXjV10": 3,
                    "d4gGtcobq8M": 2,
                    "fOvTtapxa9c": 1,
                    "n25JjoixM3I": 14,
                    "uCUdlM8KnPk": 5
                },
                "count": 75,
                "group": 1,
                "index": 0,
                "name": "natural language processing",
                "videos_id": [
                    [
                        "4vLlF3flSeg",
                        16
                    ],
                    [
                        "n25JjoixM3I",
                        14
                    ],
                    [
                        "LAtzapS2GBU",
                        11
                    ],
                    [
                        "FLZvOKSCkxY",
                        7
                    ],
                    [
                        "MC97BZqdq0w",
                        5
                    ],
                    [
                        "uCUdlM8KnPk",
                        5
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "4vLlF3flSeg": 3,
                    "FLZvOKSCkxY": 1,
                    "LAtzapS2GBU": 1,
                    "MC97BZqdq0w": 3,
                    "MNvT5JekDpg": 5,
                    "fOvTtapxa9c": 2,
                    "w9OUpjiu_zg": 13,
                    "yKN8a8jgIN8": 1
                },
                "count": 29,
                "group": 1,
                "index": 1,
                "name": "machine learning",
                "videos_id": [
                    [
                        "w9OUpjiu_zg",
                        13
                    ],
                    [
                        "MNvT5JekDpg",
                        5
                    ],
                    [
                        "4vLlF3flSeg",
                        3
                    ],
                    [
                        "MC97BZqdq0w",
                        3
                    ],
                    [
                        "fOvTtapxa9c",
                        2
                    ],
                    [
                        "LAtzapS2GBU",
                        1
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "3Q8wacwA4gs": 1,
                    "4vLlF3flSeg": 4,
                    "fOvTtapxa9c": 2,
                    "n25JjoixM3I": 6
                },
                "count": 13,
                "group": 1,
                "index": 2,
                "name": "human language",
                "videos_id": [
                    [
                        "n25JjoixM3I",
                        6
                    ],
                    [
                        "4vLlF3flSeg",
                        4
                    ],
                    [
                        "fOvTtapxa9c",
                        2
                    ],
                    [
                        "3Q8wacwA4gs",
                        1
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "Sx3Fpw0XCXk": 3
                },
                "count": 3,
                "group": 1,
                "index": 3,
                "name": "google wave",
                "videos_id": [
                    [
                        "Sx3Fpw0XCXk",
                        3
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "MC97BZqdq0w": 1,
                    "fOvTtapxa9c": 3,
                    "n25JjoixM3I": 2,
                    "w9OUpjiu_zg": 1
                },
                "count": 7,
                "group": 1,
                "index": 4,
                "name": "computer science",
                "videos_id": [
                    [
                        "fOvTtapxa9c",
                        3
                    ],
                    [
                        "n25JjoixM3I",
                        2
                    ],
                    [
                        "w9OUpjiu_zg",
                        1
                    ],
                    [
                        "MC97BZqdq0w",
                        1
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "MNvT5JekDpg": 8,
                    "n25JjoixM3I": 1
                },
                "count": 9,
                "group": 1,
                "index": 5,
                "name": "natural language generation",
                "videos_id": [
                    [
                        "MNvT5JekDpg",
                        8
                    ],
                    [
                        "n25JjoixM3I",
                        1
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "GDso6md3DBw": 3
                },
                "count": 3,
                "group": 1,
                "index": 6,
                "name": "text similarity",
                "videos_id": [
                    [
                        "GDso6md3DBw",
                        3
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "n25JjoixM3I": 1,
                    "yKN8a8jgIN8": 8
                },
                "count": 9,
                "group": 1,
                "index": 7,
                "name": "watson",
                "videos_id": [
                    [
                        "yKN8a8jgIN8",
                        8
                    ],
                    [
                        "n25JjoixM3I",
                        1
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "4kyJVwew0lg": 5,
                    "NT40U8zU1bg": 1
                },
                "count": 6,
                "group": 1,
                "index": 8,
                "name": "mouse",
                "videos_id": [
                    [
                        "4kyJVwew0lg",
                        5
                    ],
                    [
                        "NT40U8zU1bg",
                        1
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "GDso6md3DBw": 23,
                    "Y90BJzUcqlI": 1
                },
                "count": 24,
                "group": 1,
                "index": 9,
                "name": "similarity",
                "videos_id": [
                    [
                        "GDso6md3DBw",
                        23
                    ],
                    [
                        "Y90BJzUcqlI",
                        1
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "3Q8wacwA4gs": 1,
                    "4vLlF3flSeg": 5,
                    "5isBs5WFbf0": 9,
                    "FLZvOKSCkxY": 1,
                    "LAtzapS2GBU": 4,
                    "MNvT5JekDpg": 4,
                    "Y90BJzUcqlI": 3,
                    "_RY1QUXjV10": 3,
                    "d4gGtcobq8M": 4,
                    "fOvTtapxa9c": 2,
                    "n25JjoixM3I": 1,
                    "uCUdlM8KnPk": 2
                },
                "count": 39,
                "group": 1,
                "index": 10,
                "name": "nlp",
                "videos_id": [
                    [
                        "5isBs5WFbf0",
                        9
                    ],
                    [
                        "4vLlF3flSeg",
                        5
                    ],
                    [
                        "LAtzapS2GBU",
                        4
                    ],
                    [
                        "MNvT5JekDpg",
                        4
                    ],
                    [
                        "d4gGtcobq8M",
                        4
                    ],
                    [
                        "_RY1QUXjV10",
                        3
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "3Q8wacwA4gs": 2,
                    "4vLlF3flSeg": 7,
                    "FLZvOKSCkxY": 4,
                    "GDso6md3DBw": 1,
                    "MC97BZqdq0w": 1,
                    "MNvT5JekDpg": 3,
                    "NT40U8zU1bg": 8,
                    "Y90BJzUcqlI": 3,
                    "d4gGtcobq8M": 1,
                    "fOvTtapxa9c": 4,
                    "n25JjoixM3I": 8,
                    "uCUdlM8KnPk": 2,
                    "w9OUpjiu_zg": 4
                },
                "count": 48,
                "group": 1,
                "index": 11,
                "name": "understand",
                "videos_id": [
                    [
                        "NT40U8zU1bg",
                        8
                    ],
                    [
                        "n25JjoixM3I",
                        8
                    ],
                    [
                        "4vLlF3flSeg",
                        7
                    ],
                    [
                        "w9OUpjiu_zg",
                        4
                    ],
                    [
                        "FLZvOKSCkxY",
                        4
                    ],
                    [
                        "fOvTtapxa9c",
                        4
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "d4gGtcobq8M": 3
                },
                "count": 3,
                "group": 1,
                "index": 12,
                "name": "spark cognition",
                "videos_id": [
                    [
                        "d4gGtcobq8M",
                        3
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "d4gGtcobq8M": 3
                },
                "count": 3,
                "group": 1,
                "index": 13,
                "name": "injury report",
                "videos_id": [
                    [
                        "d4gGtcobq8M",
                        3
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "5isBs5WFbf0": 3
                },
                "count": 3,
                "group": 1,
                "index": 14,
                "name": "neuro linguistic programming",
                "videos_id": [
                    [
                        "5isBs5WFbf0",
                        3
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "Sx3Fpw0XCXk": 3,
                    "fOvTtapxa9c": 2
                },
                "count": 5,
                "group": 1,
                "index": 15,
                "name": "language model",
                "videos_id": [
                    [
                        "Sx3Fpw0XCXk",
                        3
                    ],
                    [
                        "fOvTtapxa9c",
                        2
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "w9OUpjiu_zg": 10
                },
                "count": 10,
                "group": 1,
                "index": 16,
                "name": "rule-based approach",
                "videos_id": [
                    [
                        "w9OUpjiu_zg",
                        10
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "yKN8a8jgIN8": 7
                },
                "count": 7,
                "group": 1,
                "index": 17,
                "name": "flick",
                "videos_id": [
                    [
                        "yKN8a8jgIN8",
                        7
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "3Q8wacwA4gs": 1,
                    "4vLlF3flSeg": 2,
                    "FLZvOKSCkxY": 4
                },
                "count": 7,
                "group": 1,
                "index": 18,
                "name": "sentiment analysis",
                "videos_id": [
                    [
                        "FLZvOKSCkxY",
                        4
                    ],
                    [
                        "4vLlF3flSeg",
                        2
                    ],
                    [
                        "3Q8wacwA4gs",
                        1
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "n25JjoixM3I": 3,
                    "yKN8a8jgIN8": 1
                },
                "count": 4,
                "group": 1,
                "index": 19,
                "name": "search engine",
                "videos_id": [
                    [
                        "n25JjoixM3I",
                        3
                    ],
                    [
                        "yKN8a8jgIN8",
                        1
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "GDso6md3DBw": 1,
                    "fOvTtapxa9c": 6
                },
                "count": 7,
                "group": 1,
                "index": 20,
                "name": "speech recognition",
                "videos_id": [
                    [
                        "fOvTtapxa9c",
                        6
                    ],
                    [
                        "GDso6md3DBw",
                        1
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "MNvT5JekDpg": 8,
                    "Sx3Fpw0XCXk": 1
                },
                "count": 9,
                "group": 1,
                "index": 21,
                "name": "structured data",
                "videos_id": [
                    [
                        "MNvT5JekDpg",
                        8
                    ],
                    [
                        "Sx3Fpw0XCXk",
                        1
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "4vLlF3flSeg": 1,
                    "FLZvOKSCkxY": 5,
                    "NT40U8zU1bg": 1
                },
                "count": 7,
                "group": 1,
                "index": 22,
                "name": "english language",
                "videos_id": [
                    [
                        "FLZvOKSCkxY",
                        5
                    ],
                    [
                        "4vLlF3flSeg",
                        1
                    ],
                    [
                        "NT40U8zU1bg",
                        1
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "4kyJVwew0lg": 3
                },
                "count": 3,
                "group": 1,
                "index": 23,
                "name": "drink",
                "videos_id": [
                    [
                        "4kyJVwew0lg",
                        3
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "4vLlF3flSeg": 7,
                    "LAtzapS2GBU": 1,
                    "MNvT5JekDpg": 3,
                    "Sx3Fpw0XCXk": 5,
                    "fOvTtapxa9c": 2,
                    "n25JjoixM3I": 2,
                    "w9OUpjiu_zg": 1
                },
                "count": 21,
                "group": 1,
                "index": 24,
                "name": "google",
                "videos_id": [
                    [
                        "4vLlF3flSeg",
                        7
                    ],
                    [
                        "Sx3Fpw0XCXk",
                        5
                    ],
                    [
                        "MNvT5JekDpg",
                        3
                    ],
                    [
                        "n25JjoixM3I",
                        2
                    ],
                    [
                        "fOvTtapxa9c",
                        2
                    ],
                    [
                        "w9OUpjiu_zg",
                        1
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "5isBs5WFbf0": 2,
                    "FLZvOKSCkxY": 1,
                    "GDso6md3DBw": 2,
                    "MNvT5JekDpg": 2,
                    "Sx3Fpw0XCXk": 1,
                    "Y90BJzUcqlI": 1,
                    "n25JjoixM3I": 2,
                    "uCUdlM8KnPk": 2,
                    "w9OUpjiu_zg": 1
                },
                "count": 14,
                "group": 1,
                "index": 25,
                "name": "mean",
                "videos_id": [
                    [
                        "GDso6md3DBw",
                        2
                    ],
                    [
                        "n25JjoixM3I",
                        2
                    ],
                    [
                        "MNvT5JekDpg",
                        2
                    ],
                    [
                        "5isBs5WFbf0",
                        2
                    ],
                    [
                        "uCUdlM8KnPk",
                        2
                    ],
                    [
                        "w9OUpjiu_zg",
                        1
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "NT40U8zU1bg": 3
                },
                "count": 3,
                "group": 1,
                "index": 26,
                "name": "medical record",
                "videos_id": [
                    [
                        "NT40U8zU1bg",
                        3
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "3Q8wacwA4gs": 1,
                    "5isBs5WFbf0": 1,
                    "FLZvOKSCkxY": 1,
                    "LAtzapS2GBU": 1,
                    "MNvT5JekDpg": 5,
                    "Sx3Fpw0XCXk": 2,
                    "n25JjoixM3I": 1,
                    "w9OUpjiu_zg": 13
                },
                "count": 25,
                "group": 1,
                "index": 27,
                "name": "machine",
                "videos_id": [
                    [
                        "w9OUpjiu_zg",
                        13
                    ],
                    [
                        "MNvT5JekDpg",
                        5
                    ],
                    [
                        "Sx3Fpw0XCXk",
                        2
                    ],
                    [
                        "3Q8wacwA4gs",
                        1
                    ],
                    [
                        "LAtzapS2GBU",
                        1
                    ],
                    [
                        "n25JjoixM3I",
                        1
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "MNvT5JekDpg": 8
                },
                "count": 8,
                "group": 1,
                "index": 28,
                "name": "neural network",
                "videos_id": [
                    [
                        "MNvT5JekDpg",
                        8
                    ]
                ]
            },
            {
                "conceptCountForEachVid": {
                    "w9OUpjiu_zg": 7
                },
                "count": 7,
                "group": 1,
                "index": 29,
                "name": "ip address",
                "videos_id": [
                    [
                        "w9OUpjiu_zg",
                        7
                    ]
                ]
            }
        ]
    },
    "concept_sequences": {
        "0": [
            11,
            10,
            0
        ],
        "1": [
            11,
            10,
            0,
            25,
            27,
            24,
            1
        ],
        "2": [
            11,
            10,
            0,
            2
        ],
        "3": [
            11,
            10,
            0,
            25,
            27,
            24,
            3,
            1
        ],
        "4": [
            11,
            10,
            0,
            25,
            24,
            1,
            27,
            4
        ],
        "5": [
            11,
            10,
            0,
            25,
            27,
            24,
            5,
            1
        ],
        "6": [],
        "7": [],
        "8": [],
        "9": [
            11,
            10,
            0,
            25,
            24,
            15,
            1,
            20,
            27,
            9
        ],
        "10": [],
        "11": [],
        "12": [],
        "13": [
            12,
            13
        ],
        "14": [],
        "15": [
            11,
            10,
            0,
            15
        ],
        "16": [],
        "17": [],
        "18": [
            11,
            10,
            0,
            25,
            1,
            27,
            24,
            18
        ],
        "19": [
            11,
            10,
            0,
            25,
            27,
            24,
            1,
            7,
            5,
            4,
            19
        ],
        "20": [
            11,
            10,
            0,
            25,
            24,
            15,
            1,
            27,
            20
        ],
        "21": [
            11,
            10,
            0,
            25,
            27,
            24,
            15,
            21,
            1
        ],
        "22": [
            11,
            8,
            22
        ],
        "23": [],
        "24": [
            11,
            10,
            0,
            25,
            27,
            24,
            1
        ],
        "25": [
            11,
            10,
            0,
            25
        ],
        "26": [],
        "27": [
            11,
            10,
            0,
            25,
            27,
            24,
            1
        ],
        "28": [
            11,
            10,
            0,
            25,
            24,
            1,
            27,
            15,
            21,
            20,
            28
        ],
        "29": [
            16,
            29
        ]
    },
    "highlight_nodes": {
        "0": [
            0,
            10,
            11
        ],
        "1": [
            0,
            1,
            10,
            11,
            24,
            25,
            27
        ],
        "2": [
            0,
            10,
            2,
            11
        ],
        "3": [
            0,
            1,
            3,
            10,
            11,
            24,
            25,
            27
        ],
        "4": [
            0,
            1,
            4,
            10,
            11,
            24,
            25,
            27
        ],
        "5": [
            0,
            1,
            5,
            10,
            11,
            24,
            25,
            27
        ],
        "6": [
            6
        ],
        "7": [
            7
        ],
        "8": [
            8
        ],
        "9": [
            0,
            1,
            9,
            10,
            11,
            15,
            20,
            24,
            25,
            27
        ],
        "10": [
            10
        ],
        "11": [
            11
        ],
        "12": [
            12
        ],
        "13": [
            12,
            13
        ],
        "14": [
            14
        ],
        "15": [
            0,
            10,
            11,
            15
        ],
        "16": [
            16
        ],
        "17": [
            17
        ],
        "18": [
            0,
            1,
            10,
            11,
            18,
            24,
            25,
            27
        ],
        "19": [
            0,
            1,
            4,
            5,
            7,
            10,
            11,
            19,
            24,
            25,
            27
        ],
        "20": [
            0,
            1,
            10,
            11,
            15,
            20,
            24,
            25,
            27
        ],
        "21": [
            0,
            1,
            10,
            11,
            15,
            21,
            24,
            25,
            27
        ],
        "22": [
            8,
            11,
            22
        ],
        "23": [
            23
        ],
        "24": [
            0,
            1,
            10,
            11,
            24,
            25,
            27
        ],
        "25": [
            0,
            25,
            10,
            11
        ],
        "26": [
            26
        ],
        "27": [
            0,
            1,
            10,
            11,
            24,
            25,
            27
        ],
        "28": [
            0,
            1,
            10,
            11,
            15,
            20,
            21,
            24,
            25,
            27,
            28
        ],
        "29": [
            16,
            29
        ]
    },
    "search_info": {
        "NumOfVideos": 20,
        "key": "natural_language_processing_introduction_50",
        "similarity_threshold": 0.42677669529663687,
        "time_delta": 10.1,
        "voclist_SelectMethod": 0
    },
    "video_sequences": {
        "0": [
            [
                "NT40U8zU1bg",
                1.0
            ],
            [
                "5isBs5WFbf0",
                1.0
            ],
            [
                "n25JjoixM3I",
                1.0
            ]
        ],
        "1": [
            [
                "NT40U8zU1bg",
                1.0
            ],
            [
                "n25JjoixM3I",
                2.5
            ],
            [
                "5isBs5WFbf0",
                2.6666666666666665
            ],
            [
                "Sx3Fpw0XCXk",
                3.5
            ],
            [
                "w9OUpjiu_zg",
                3.6
            ]
        ],
        "2": [
            [
                "NT40U8zU1bg",
                1.0
            ],
            [
                "5isBs5WFbf0",
                1.0
            ],
            [
                "n25JjoixM3I",
                1.5
            ]
        ],
        "3": [
            [
                "NT40U8zU1bg",
                1.0
            ],
            [
                "n25JjoixM3I",
                2.5
            ],
            [
                "5isBs5WFbf0",
                2.6666666666666665
            ],
            [
                "w9OUpjiu_zg",
                3.8
            ],
            [
                "Sx3Fpw0XCXk",
                4.0
            ]
        ],
        "4": [
            [
                "NT40U8zU1bg",
                1.0
            ],
            [
                "fOvTtapxa9c",
                3.1666666666666665
            ],
            [
                "n25JjoixM3I",
                3.2857142857142856
            ],
            [
                "5isBs5WFbf0",
                3.3333333333333335
            ],
            [
                "Sx3Fpw0XCXk",
                3.75
            ],
            [
                "w9OUpjiu_zg",
                4.166666666666667
            ]
        ],
        "5": [
            [
                "NT40U8zU1bg",
                1.0
            ],
            [
                "5isBs5WFbf0",
                2.6666666666666665
            ],
            [
                "n25JjoixM3I",
                3.0
            ],
            [
                "Sx3Fpw0XCXk",
                3.5
            ],
            [
                "MNvT5JekDpg",
                3.5
            ],
            [
                "w9OUpjiu_zg",
                3.8
            ]
        ],
        "9": [
            [
                "NT40U8zU1bg",
                1.0
            ],
            [
                "n25JjoixM3I",
                3.0
            ],
            [
                "Y90BJzUcqlI",
                3.0
            ],
            [
                "fOvTtapxa9c",
                3.5714285714285716
            ],
            [
                "5isBs5WFbf0",
                4.0
            ],
            [
                "w9OUpjiu_zg",
                4.2
            ],
            [
                "Sx3Fpw0XCXk",
                4.4
            ]
        ],
        "13": [
            [
                "d4gGtcobq8M",
                0.5
            ]
        ],
        "15": [
            [
                "NT40U8zU1bg",
                1.0
            ],
            [
                "5isBs5WFbf0",
                1.0
            ],
            [
                "n25JjoixM3I",
                1.0
            ],
            [
                "Sx3Fpw0XCXk",
                2.5
            ]
        ],
        "18": [
            [
                "NT40U8zU1bg",
                1.0
            ],
            [
                "n25JjoixM3I",
                2.8333333333333335
            ],
            [
                "5isBs5WFbf0",
                3.0
            ],
            [
                "FLZvOKSCkxY",
                3.142857142857143
            ],
            [
                "w9OUpjiu_zg",
                3.6
            ],
            [
                "Sx3Fpw0XCXk",
                4.0
            ]
        ],
        "19": [
            [
                "NT40U8zU1bg",
                1.0
            ],
            [
                "5isBs5WFbf0",
                2.6666666666666665
            ],
            [
                "Sx3Fpw0XCXk",
                3.5
            ],
            [
                "MNvT5JekDpg",
                3.625
            ],
            [
                "fOvTtapxa9c",
                3.8333333333333335
            ],
            [
                "w9OUpjiu_zg",
                4.5
            ],
            [
                "n25JjoixM3I",
                4.9
            ],
            [
                "yKN8a8jgIN8",
                7.666666666666667
            ]
        ],
        "20": [
            [
                "NT40U8zU1bg",
                1.0
            ],
            [
                "n25JjoixM3I",
                2.8333333333333335
            ],
            [
                "5isBs5WFbf0",
                3.6666666666666665
            ],
            [
                "fOvTtapxa9c",
                3.7142857142857144
            ],
            [
                "w9OUpjiu_zg",
                4.0
            ],
            [
                "Sx3Fpw0XCXk",
                4.2
            ]
        ],
        "21": [
            [
                "NT40U8zU1bg",
                1.0
            ],
            [
                "n25JjoixM3I",
                2.5
            ],
            [
                "5isBs5WFbf0",
                2.6666666666666665
            ],
            [
                "MNvT5JekDpg",
                3.75
            ],
            [
                "w9OUpjiu_zg",
                4.0
            ],
            [
                "Sx3Fpw0XCXk",
                4.5
            ]
        ],
        "22": [
            [
                "NT40U8zU1bg",
                1.0
            ],
            [
                "FLZvOKSCkxY",
                1.0
            ]
        ],
        "24": [
            [
                "NT40U8zU1bg",
                1.0
            ],
            [
                "n25JjoixM3I",
                2.5
            ],
            [
                "5isBs5WFbf0",
                2.6666666666666665
            ],
            [
                "Sx3Fpw0XCXk",
                3.5
            ],
            [
                "w9OUpjiu_zg",
                3.6
            ]
        ],
        "25": [
            [
                "NT40U8zU1bg",
                1.0
            ],
            [
                "n25JjoixM3I",
                1.5
            ],
            [
                "5isBs5WFbf0",
                2.0
            ]
        ],
        "27": [
            [
                "NT40U8zU1bg",
                1.0
            ],
            [
                "n25JjoixM3I",
                2.5
            ],
            [
                "5isBs5WFbf0",
                2.6666666666666665
            ],
            [
                "Sx3Fpw0XCXk",
                3.5
            ],
            [
                "w9OUpjiu_zg",
                3.6
            ]
        ],
        "28": [
            [
                "NT40U8zU1bg",
                1.0
            ],
            [
                "n25JjoixM3I",
                2.6666666666666665
            ],
            [
                "5isBs5WFbf0",
                3.3333333333333335
            ],
            [
                "w9OUpjiu_zg",
                3.6
            ],
            [
                "fOvTtapxa9c",
                4.0
            ],
            [
                "MNvT5JekDpg",
                4.333333333333333
            ],
            [
                "Sx3Fpw0XCXk",
                5.0
            ]
        ],
        "29": [
            [
                "w9OUpjiu_zg",
                0.5
            ]
        ]
    },
    "videos_info": {
        "3Q8wacwA4gs": {
            "NumOfComments": 3,
            "caption_exist": "T",
            "channel_id": "UCl6cUxI-KREDbwC3WRa-1Ew",
            "channel_title": "CSRocks",
            "comment_sentiment": 0.1416666666666667,
            "concepts": [
                [
                    "analysis",
                    7
                ],
                [
                    "language",
                    4
                ],
                [
                    "natural",
                    3
                ],
                [
                    "pragmatic",
                    3
                ],
                [
                    "natural language processing",
                    2
                ],
                [
                    "knowledge",
                    2
                ],
                [
                    "syntactic analysis",
                    2
                ],
                [
                    "processing",
                    2
                ],
                [
                    "understand",
                    2
                ],
                [
                    "interpretation",
                    2
                ],
                [
                    "computer",
                    2
                ],
                [
                    "human",
                    2
                ],
                [
                    "nlp",
                    1
                ],
                [
                    "machine",
                    1
                ],
                [
                    "help",
                    1
                ],
                [
                    "deep learning",
                    1
                ],
                [
                    "sentiment analysis",
                    1
                ],
                [
                    "lexical analysis",
                    1
                ],
                [
                    "structural",
                    1
                ],
                [
                    "chatbots",
                    1
                ],
                [
                    "rule",
                    1
                ],
                [
                    "watching",
                    1
                ],
                [
                    "human language",
                    1
                ],
                [
                    "application",
                    1
                ],
                [
                    "semantics",
                    1
                ],
                [
                    "called",
                    1
                ],
                [
                    "find",
                    1
                ],
                [
                    "tree",
                    1
                ],
                [
                    "noun",
                    1
                ]
            ],
            "description": "Natural language processing allows computers to understand human language. It has plenty of applications. For example: \nText summarization, translation, keyword generation, sentiment analysis or chat bots.\n\nSo how it works? Let\u2019s take a closer look at it.\n\nPlease Like and Subscribe for more weekly videos!\n\nFollow me on Twitter: https://twitter.com/thecompscirocks\nFollow me on Instagram: https://www.instagram.com/thecompscirocks/\nFollow me on Facebook: https://www.facebook.com/thecompscirocks/\n\nSome sources & further reading:\nhttp://www.mind.ilstu.edu/curriculum/protothinker/natural_language_processing.php\nhttps://nlp.stanford.edu/\nhttps://research.google.com/pubs/NaturalLanguageProcessing.html\nhttps://en.wikipedia.org/wiki/Natural_language_processing\nhttps://en.wikipedia.org/wiki/Natural_language_understanding\nhttps://en.wikipedia.org/wiki/Natural_language_generation\nhttps://en.wikipedia.org/wiki/Tokenization_(lexical_analysis)\nhttps://en.wikipedia.org/wiki/Syntax\nhttps://en.wikipedia.org/wiki/Parsing\nhttps://en.wikipedia.org/wiki/Context-free_grammar\nhttps://en.wikipedia.org/wiki/Semantics\nhttps://en.wikipedia.org/wiki/Pragmatics\nhttps://en.wikipedia.org/wiki/Sentiment_analysis",
            "dislikeCount": "6",
            "duration": "PT2M47S",
            "likeCount": "85",
            "published_time": "2017-09-21T18:06:41.000Z",
            "tags": [
                "computer science",
                "programming",
                "education",
                "computer algorithms",
                "programming algorithms",
                "nlp",
                "natural language processing",
                "natural language understanding",
                "machine learning",
                "computational linguistics",
                "artificial analysis",
                "artificial intelligence",
                "sentiment analysis",
                "how nlp works",
                "nlp explained",
                "how natural language processing works",
                "natural language processing explained",
                "natural language processing in artificial intelligence",
                "syntactic analysis",
                "semantics",
                "pragmatics",
                "lexical analysis"
            ],
            "thumbnail": "https://i.ytimg.com/vi/3Q8wacwA4gs/hqdefault.jpg",
            "title": "How Can Computers Understand Human Language? | Natural Language Processing Explained",
            "transcript": "  natural language processing allows computers to understand human language let's take a closer look at it natural language processing or NLP has plenty of applications for example text summarization translation keyword generation sentiment analysis or chatbots so how it works we start with lexical analysis also known as tokenization which divides text into paragraphs sentences and words then we proceed with syntactic analysis or parsing parsing goes through sentence word by word to create structural description of a sentence usually in a form of tree it applies rules of context-free grammar to identify whether the word is noun or verb and so on this helps to understand the relationships between words once we know the structure of a sentence we need to find out its meaning this is the most complex phase because natural language can be quite ambiguous a simple sentence can be interpreted in many different ways semantic analysis gives us context independent interpretation or in other words a meaning without knowledge of the other sentences the result is called logical form at this point there is still may be some level of ambiguity so we call to help pragmatic analysis pragmatic analysis can derive better interpretation of the sentence by looking at the previous and succeeding sentences it also applies real-world knowledge for example that banana is a fruit birds can fly and so on finally it's worth noting that sometimes syntactic analysis semantics and pragmatics aren't completed in a sequential manner but rather simultaneous even though an LP is yunk field we've made quite progress over the last few years with advances in machine and deep learning it will be interesting to watch how the way humans and computers communicate with each other of evolves and as always thanks for watching if you enjoyed this video please hit that like button and don't forget to subscribe to see more videos like this in future",
            "userFeedbackScore": 0.35960622710622714,
            "videoid": "3Q8wacwA4gs",
            "viewCount": "5954"
        },
        "4KStHvq7OIg": {
            "NumOfComments": 1,
            "caption_exist": "T",
            "channel_id": "UCGXevIXsas-fsaFz0xuT4Qg",
            "channel_title": "autolangresearch",
            "comment_sentiment": 0.2333333333333333,
            "concepts": [
                [
                    "rule",
                    1
                ],
                [
                    "human",
                    1
                ],
                [
                    "computer",
                    1
                ]
            ],
            "description": "Natural Language processing (NLP) is a field of computer science and linguistics concerned with the interactions between computers and human languages.\r\nNatural-language understanding is sometimes referred to as an Artifial Inelligence-complete problem, because natural-language recognition seems to require extensive knowledge about the outside world and the ability to manipulate it, and is often considered a sub-field of artificial intelligence.\r\n\r\nModern NLP algorithms are grounded especially in statistical machine learning. Research into modern statistical NLP algorithms requires an understanding of a number of disparate fields, including linguistics, computer science, statistics (particularly Bayesian statistics), linear algebra and optimization theory.\r\n\r\nPrior implementations of language-processing tasks typically involved the direct hand coding of large sets of rules. The machine-learning paradigm often uses statistical inference to automatically learn such rules through the analysis of a set of documents that have been hand-annotated with the correct values to be learned. This documents are named corpus.\r\n\r\nAs an example, consider the task of determining the correct part of speech of each word in a given sentence, typically one that has never been seen before. A typical machine-learning-based implementation of a part of speech tagger proceeds in two steps, a training step and an evaluation step.\r\n\r\nThe training step : makes use of a corpus of training data, which consists of a large number of sentences, each of which has the correct part of speech attached to each word.\r\n\r\nThis corpus is analyzed and a learning model is generated from it, consisting of automatically-created rules for determining the part of speech for a word in a sentence, typically based on the nature of the word in question, the nature of surrounding words, and the most likely part of speech for those surrounding words. \r\n\r\nThe model that is generated is typically the best model that can be found that simultaneously meets two conflicting objectives: To perform as well as possible on the training data, and to be as simple as possible (so that the model avoids overfitting the training data.\r\n\r\nIn The evaluation step, the model that has been learned is used to process new previously unseen data. It is critical that the data used for testing is not the same as the data used for training; otherwise, the testing accuracy will be unrealistically high.\r\n\r\nMany different classes of machine learning algorithms have been applied to NLP tasks.\r\n\r\nResearch has focused on statistical models, which make soft, probabilistic decisions based on attaching real-valued weights to each input feature. \r\n\r\nSuch models have the advantage that they can express the relative certainty of many different possible answers rather than only one, producing more reliable results when such a model is included as a component of a larger system. \r\n\r\nIn addition, models that make soft decisions are generally more robust when given unfamiliar input, especially input that contains errors (as is very common for real-world data).\r\n\r\nThis was only an introduction, If you want to learn more watch next video. Thanks for your time.",
            "dislikeCount": "5",
            "duration": "PT3M30S",
            "likeCount": "14",
            "published_time": "2010-10-22T12:35:59.000Z",
            "tags": [
                "Natural",
                "Language",
                "processing"
            ],
            "thumbnail": "https://i.ytimg.com/vi/4KStHvq7OIg/hqdefault.jpg",
            "title": "Natural Language processing, short introduction.",
            "transcript": " the boards of directors and rob were there concrete figures from the minister  state  but due to integration there is no computers of residents  that all relatives of both institutions warn of slipperiness  ariza and that is from this plan  this costs that has long been a loss from yesterday it remains in peace already on  the scoreboard  nine months ago  those who go on vacation 28 Oct is not good either  tomorrow a snack  according to the analysts, however, you think so  the asset position offers, incidentally, linger on damage  cars reimbursed  completely justified  Van der Vaart  in vain the rules of the game, but SMS gets back  The bathroom is not even that far  Looking far into the second half of the interviewed was I want him too  trials have only been awarded today  just like in a bar  about the first five kilos  in weapons also carry the gaza strip realistically always the same time that  hp from egypt  partly by a police station  the shooter was armenia g\u00f6rges  captain of toll then there are the boss on the cd v the former top peak valve  offshore  in a beach tent  the arrangement with each number two tenths  What I also know that Jan is a beast of international waste water the stars  recently, 7 also became the spokeswoman  that know messi is still being cared for  brussels west of germany percent it's a flash what I already have a few eyes  special guest  the wing spike sting out of the Maoist was performed  the foundation even so long ago I got the impasse by the former  to be used mainly during peak hours  not just dealing with human trafficking properly back the court it was  thus morgan the power leader khadaffi is for Polish employees  the emergency app is unique I am quite possible that you dati on it  incident people with a big wink  the fire broke out behind the helm because they broke it  from two recently awaiting  zaltbommel  the union also see the trainer once  to restore balance  the man had seen a decline in the artistic person in 2009  I tell you again that is an obligation in the agenda that perpetrators  all disappeared live  the westerpark in libya arnhem vitesse  bayer leverkusen is on the rise and I have not refused fabiola and all  that guest  Drivers  had landed 30 kilos  people still be glad that I think this is a line underneath  master builder who is that moped rider  fransman fabien barthez that details were also extra broadcast or one in  this pace went up when people were treated  that is a man with a black school who wants to drop themselves today  said  may we usually it is unstoppable he may do my thing sometimes because there is  it is, however, only steady  there is justification now  the market continues to share all their interest in someone from the big league  at loss ",
            "userFeedbackScore": 0.30543859649122806,
            "videoid": "4KStHvq7OIg",
            "viewCount": "9135"
        },
        "4kyJVwew0lg": {
            "NumOfComments": 0,
            "caption_exist": "T",
            "channel_id": "UC6ZQ-SuhvQAeQIR5tHJGGmQ",
            "channel_title": "The Audiopedia",
            "comment_sentiment": 0,
            "concepts": [
                [
                    "mouse",
                    5
                ],
                [
                    "drink",
                    3
                ],
                [
                    "called",
                    2
                ],
                [
                    "training",
                    1
                ],
                [
                    "human",
                    1
                ],
                [
                    "computer",
                    1
                ],
                [
                    "computation",
                    1
                ]
            ],
            "description": "What is NATURAL LANGUAGE PROCESSING? What does NATURAL LANGUAGE PROCESSING mean? NATURAL LANGUAGE PROCESSING meaning - NATURAL LANGUAGE PROCESSING definition - NATURAL LANGUAGE PROCESSING explanation.\n\nSource: Wikipedia.org article, adapted under https://creativecommons.org/licenses/by-sa/3.0/ license.\n\nSUBSCRIBE to our Google Earth flights channel - https://www.youtube.com/channel/UC6UuCPh7GrXznZi0Hz2YQnQ\n\nNatural language processing (NLP) is a field of computer science, artificial intelligence and computational linguistics concerned with the interactions between computers and human (natural) languages, and, in particular, concerned with programming computers to fruitfully process large natural language corpora. Challenges in natural language processing frequently involve natural language understanding, natural language generation (frequently from formal, machine-readable logical forms), connecting language and machine perception, dialog systems, or some combination thereof.\n\nThe history of NLP generally started in the 1950s, although work can be found from earlier periods. In 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence.\n\nThe Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English. The authors claimed that within three or five years, machine translation would be a solved problem. However, real progress was much slower, and after the ALPAC report in 1966, which found that ten-year-long research had failed to fulfill the expectations, funding for machine translation was dramatically reduced. Little further research in machine translation was conducted until the late 1980s, when the first statistical machine translation systems were developed.\n\nSome notably successful NLP systems developed in the 1960s were SHRDLU, a natural language system working in restricted \"blocks worlds\" with restricted vocabularies, and ELIZA, a simulation of a Rogerian psychotherapist, written by Joseph Weizenbaum between 1964 and 1966. Using almost no information about human thought or emotion, ELIZA sometimes provided a startlingly human-like interaction. When the \"patient\" exceeded the very small knowledge base, ELIZA might provide a generic response, for example, responding to \"My head hurts\" with \"Why do you say your head hurts?\".\n\nDuring the 1970s, many programmers began to write \"conceptual ontologies\", which structured real-world information into computer-understandable data. Examples are MARGIE (Schank, 1975), SAM (Cullingford, 1978), PAM (Wilensky, 1978), TaleSpin (Meehan, 1976), QUALM (Lehnert, 1977), Politics (Carbonell, 1979), and Plot Units (Lehnert 1981). During this time, many chatterbots were written including PARRY, Racter, and Jabberwacky.\n\nUp to the 1980s, most NLP systems were based on complex sets of hand-written rules. Starting in the late 1980s, however, there was a revolution in NLP with the introduction of machine learning algorithms for language processing. This was due to both the steady increase in computational power (see Moore's law) and the gradual lessening of the dominance of Chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing. Some of the earliest-used machine learning algorithms, such as decision trees, produced systems of hard if-then rules similar to existing hand-written rules. However, part-of-speech tagging introduced the use of hidden Markov models to NLP, and increasingly, research has focused on statistical models, which make soft, probabilistic decisions based on attaching real-valued weights to the features making up the input data. The cache language models upon which many speech recognition systems now rely are examples of such statistical models. Such models are generally more robust when given unfamiliar input, especially input that contains errors (as is very common for real-world data), and produce more reliable results when integrated into a larger system comprising multiple subtasks....",
            "dislikeCount": "0",
            "duration": "PT9M41S",
            "likeCount": "0",
            "published_time": "2017-09-17T04:00:00.000Z",
            "tags": [
                "dictionary",
                "english dictionary",
                "online dictionary",
                "vocabulary",
                "english vocabulary",
                "online vocabulary",
                "how to pronounce words",
                "what do words mean",
                "natural language processing",
                "what is natural language processing",
                "natural language processing meaning",
                "natural language processing definition",
                "natural language processing explanation",
                "what is the meaning of natural language processing",
                "what is the definition of natural language processing",
                "what does natural language processing mean"
            ],
            "thumbnail": "https://i.ytimg.com/vi/4kyJVwew0lg/hqdefault.jpg",
            "title": "What is NATURAL LANGUAGE PROCESSING? What does NATURAL LANGUAGE PROCESSING mean?",
            "transcript": " [music]  Matte Representative Spell the answer, feel the part, see the part through the parts replies  In the inner node, we have a larger ratio of po  one's old cell counts are not crying Sun Computation Issue Nexus Sex King at low tide  2 large percentage of middle school students to work past their joining Ulsan is easy lowering and Eve's, not seen  If the Cai Jing tablespoons plus 2 Cam filled pug consumption sensors identify the state or frozen  Middle- bottom code and  Do not erase syawoeun junse Day 2 Cold water tribes fight this weekend or after doing  A Bone In My second star of the Nazi naeswik know what the theme prequel Paul  Rush up and give full bet My Mall genre  My eyes get rid of my eyes and the Ulsan combination.  Death drama operate or personal notes de came  Total More Fractional Channels Gone With Gold Room 50 Why Not Come Tea  Bounce punishment was the death of a naturally afraid it's an okay tour victory  This summer the US team disappointed in Switzerland showed that if x Sethi always carrying jjolji  Holden has sex, even though the net a little myr Deer stew Del Scarborough Lima write images  Essence verb wool cern Spy in Wardi Bar Born per web look medical  So you should know the shape of food Yaba be polite x dis  All drinks come Thanksgiving maechan yulma well written law codex 8 Presentation Standing  Insurance poet left spy shot Buy monsters and horses News  In July than chicken above sseuljul im not special Moss Dina were in the car owner  Something Monopolistic Chest Com Centers Oceanic Som Solder And Wrap  Nauru vs Abyss in a packaged but some of the same generations of women in the sex of anonymous sex  Weekend Gold Sense is not even a concept No Steel Hook Hoo woo post-it virtue  In February, I bought a cheap film, and then I went to the studio to buy a buggy cucumber .  Daseuti wide x font text 2 x 2 appearance after winning the veil  Formation Ava Human Per Roll Mouse New  Maybe the prenatal forest vero Mi-hee manga kenzo ono  The wi-fi in the air gave nothing is Greece and bounce 4x3 wer  Applicable  Joint holdings in de neve cancer of the woods this fight 1000000000000 Under Bright Memories  The Authorization flash if the water line is called Po dress that tickled a bit rate countless  What is Liquid Bodhisattva  Shah cheap ink Jim minutes you deserve tide shifted row you drink gin sub-da  You Ullmann following three sub-Jin da  Hmm. You Zeus Moo - hyun Jin sub-lease Sword  You're woomaru Jean d sub is more beneficial ansseo Scarborough burner luggage stacked circle  The bacterium is operated by a squarer d ribbon line 4 Star ii Man Ichu ring clinker  Mart said Kwak not catch the mouse anywhere 1a bis score goals put in front of the base  Dome of the press cases ssakssak nights one week  In the Tin-ai Iida area with the Sterling year , there are 54 billion  Eve, 02 pages, including chicken anesthesiologist Dr. troubling look at a lot of schools Liege Bush Press  Another juice can be two times the bridge to Saint yen square computer ic Nova  As good if osmosis is given when writing the first training Yui West Bengal  Written in seut Expo with cold Smash Basketball You probably are not going to load the pan  Desk ssoing know of my Seoul and easy method that with a grain of rice eseutek  Do not leading lady slut foul jipeoseo life to write a summary of Somerville stand the taste, huh itneunge  Joe's place in the Church once wrote Flats thin 2e Bruce writes that in ssem vacation  x-ridden one week no 2 agonists with all the filing Lee Yu also saw no more news  Seo Hye Rin Eat What did Chris Ross and neo pay under the above soljeoseu Pocket Manual  Stress also look meoro water chi-mc written press, albeit autonomous objects in space, money  Intangible Now yubeyiseu The Tudors 2 May Queen can give where first called me,  Asura Refurbished add more water, wet pocket by giving it what she recently updated  10-year-old Xuan Tidori gently remove the mask with a collection Roy cheap to do a test search  1 Sign Then counters coin More sweet Zen Life Stacking Egger  Day of the mantle above the law dael Bruce Willis &amp; His job is seojuwon  Color mouse compiled sseudeon bus lines make good the Styx Nanny fine sseuk to 6 people  Delos packed standing in autumn followed by the center sion news all levels shellfish  What are my wxd component Gail heartfelt and step test as a gum  Face Somewhere Extra Wave Jake rex Stinger Empty attachment Super one month  Do not fire the puck ds5 interview late Care Andres yulpi aenieun I switch Liaison times  Given the routing session, and bones can be solved Screenshot Ford transmission order bulmyeonseo  Junior State Girls Funding Storm  os Ross can be seen in 4.3 pens came in and almost outboard  Jaseuk writing as soon as look at the main device a little ugly water Steiner wrote muscle chain usb  Mr. eopne order difference multicolor fight evil in chapter one star cow hand  Haejumyeon thorough the media history when doing any service or none of the riches rolling sled  Jay  The number of the crystal wafers may be higher than the number of you can have the half-sen  The three sling Durham Chow other similar purposes in the imagination of the Church of Aosta only party  I took a cup of my work, and I put on a pair of two-year-old ,  I got the vialdre word, and the cucumber that my child sleeps in the back  I wrote the number rises will not use the main house peuba taking it cold quilt after 4 months  There will be a stop in mathematics and the town will hold on.  When you put the mouse in the tournament and you do this at more than 2 m Gabe toe Ankle  Perhaps 10 cuts of tea for the sence Well cut or something What cuts the cube 3 I  Petite chain here  I break the kid's funny how I hate what no x5 took place in unfamiliar areas chips Yahoo Ying  Sky rod 10 junseo shot but are memorial vibrator Judas captured rice kept y  Framed Moule Wine Bee Sen An Real Written by Kangwon Stress Confession Cushion nov  You the gift of 22nd 4 one t you do not have a match naejueo zip Residents  A frustration and a pounding  Dwien the method discussed in the bones Zucker metallocene step difference of 20 can not be increased even Malta  We Wars for doing additional sludge lens to the side Bath aunt gave yogeol internal rotation next week  50 pairs plus the rolling'll no sense dfu sense also test the fence Ivoire  Mare kulron cheap sell you can freeze in minutes Deanna clothing companies panoramic street of the future  Baeksan wrx Mainly in gerber, buds bathtub sts wave easier recording  The ratio is now in the annotated snail brush cut from the inulin school  High deulmyeo de tone hardware make the second Star mutual ghost version written by Blake after seukseuk  Write as sliced illuminate the full width of the second waeyiri funds required use cases 5 times  2e deoni Suns scene from Bruce Saunders points in time give me water hose minus 4  Blue stones on both sides  The Eve of Saint nv share our drinks so as to sd tests that meoro Crit  mixer  Load space is also given de Today fraction not poison the rats as an intangible Mauro European commitment  I forgot the boss Izu I was going to dance 3 I had to use it JUDAHIKEN x I WAS A GROUP  Annie's pain now come with arms spread between servers so pure winger non-members vain life  Tax Solutions hot lens make more juice for the San tools to seojuwon 4 Chunma  Ceze Ceses Ceses Ceses Ceses Ceses Ceses Ceses Ceses Ceses  Part 4 is divided in Ste Cecile Cecile Cecile Cecile Cecile Cecile Cecile Cecile Cecile Cecile Cecile Cecile air  For Dupuy Sub 1, 101 can be more lined c lined standing single ring ice  There is also a son ps on the mouse cup case  warez in Nozawa would give such actual axel  Full Tilt 2 jukgetne took to the ice edge services also German chess fight  Ghostbusters Skiing Separated by laughter Mast Original name Wen poison Bergen car  Inning All the way to and out of one line from one line to one user to  xbox dao May Seoul Jiangsu crackdown party  1 Event in Chin naked to Evil 4 inside Demo All Mole  In vais point 4 on both sides wrx Otsu Seansu also wear sex  The embargo comes in lv blind Susukino little space facing the journal and dwaetguyo  Unto you see what it took behind Weiss wrote yagael puck to come to the Nou scan dma  Sex was caused by a break in Scotland Blue Embroidered it means money spread to the base of one n Chris  Well, what you may be a bit gratuities academic attendance personalized steamed kicking around a stone Cai Jing Yan  US afterglow even after the Bible cabbage ahead of him a little money, no space Ax Lee Camp  Do not share this view sseujyo objects up mwohan  The letter came just 50 Rawlings Buzz jungen water as va-ring model where the core  Trading spun ding of its Hear I got my chest  In other words, standing there looking at me with a handshake bacteria that gold fan for rear  Edition Insurance SARS  U  Oo ",
            "userFeedbackScore": 0,
            "videoid": "4kyJVwew0lg",
            "viewCount": "4098"
        },
        "4vLlF3flSeg": {
            "NumOfComments": 1,
            "caption_exist": "T",
            "channel_id": "UCjFO5t0MLyQaidKGpGoRewg",
            "channel_title": "Fullstack Academy",
            "comment_sentiment": 0.0,
            "concepts": [
                [
                    "language",
                    34
                ],
                [
                    "natural",
                    25
                ],
                [
                    "processing",
                    23
                ],
                [
                    "natural language processing",
                    16
                ],
                [
                    "approach",
                    12
                ],
                [
                    "english",
                    11
                ],
                [
                    "application",
                    8
                ],
                [
                    "human",
                    7
                ],
                [
                    "understand",
                    7
                ],
                [
                    "google",
                    7
                ],
                [
                    "called",
                    6
                ],
                [
                    "nlp",
                    5
                ],
                [
                    "noun",
                    5
                ],
                [
                    "based",
                    4
                ],
                [
                    "human language",
                    4
                ],
                [
                    "single sentence",
                    3
                ],
                [
                    "machine learning",
                    3
                ],
                [
                    "computer",
                    3
                ],
                [
                    "symbolic approach",
                    3
                ],
                [
                    "information",
                    3
                ],
                [
                    "set",
                    3
                ],
                [
                    "united state",
                    3
                ],
                [
                    "conversational",
                    2
                ],
                [
                    "movie",
                    2
                ],
                [
                    "data",
                    2
                ],
                [
                    "sentiment analysis",
                    2
                ],
                [
                    "conversational agent",
                    2
                ],
                [
                    "main limit",
                    2
                ],
                [
                    "speech",
                    2
                ],
                [
                    "rule",
                    2
                ],
                [
                    "case google",
                    2
                ],
                [
                    "ai",
                    2
                ],
                [
                    "english language",
                    1
                ],
                [
                    "tonight",
                    1
                ],
                [
                    "linguistics",
                    1
                ],
                [
                    "pragmatic",
                    1
                ],
                [
                    "po tagging",
                    1
                ],
                [
                    "system",
                    1
                ],
                [
                    "technology",
                    1
                ]
            ],
            "description": "Learn more advanced front-end and full-stack development at: https://www.fullstackacademy.com\n\nNatural Language Processing is a way for computers to analyze, understand and derive meaning from human language. It was invented in the 1950s as a response to the global threat of the Cold War and has advanced greatly in the past decades. In this NLP Tutorial, we give an overview of Natural Language Processing: what it is, how it works, and what methods it uses in order to understand human language.  \n\nWatch this video to learn:\n\n- The different subfields of NLP\n- What is the main obstacle NLP faces\n- NLP's potential for the future",
            "dislikeCount": "0",
            "duration": "PT13M32S",
            "likeCount": "8",
            "published_time": "2017-03-17T19:30:52.000Z",
            "tags": [
                "Natural Language Processing",
                "NLP",
                "NLP Tutorial",
                "Natural Language Processing Tutorial",
                "PoS tagging"
            ],
            "thumbnail": "https://i.ytimg.com/vi/4vLlF3flSeg/hqdefault.jpg",
            "title": "Natural Language Processing (NLP) Tutorial - Introduction to Natural Language Processing",
            "transcript": "  hi everybody so my name is FDIC shoe care and today I will be doing an introduction into natural language processing so you may already know what natural language processing is but some of you don't and I will be looking today throughout what natural language processing is the different language applications that exist today from natural language processing the actual method methodology of national English language processing the way it works its limits I'll then show you examples of what natural language processing is and after that we'll actually look at the potential than that natural language processing has so an acronym that I'll be using during this talk is NLP instead of national language processing saves time and so a tool one of the most important tools that humans have created could be considered to be the wheel could be considered to be internet but the main tool that was actually able to lead to all these things is its language it's only natural to be able to find a way for computers to actually analyze understand and derive meaning from human language and this is exactly what natural language processing is its history is born in the 1950s it was actually created during the Cold War when tensions between America and the United States America and Russia was really high Americans were actually extremely worried about spies Russian spies being the United States they're also worried about nuclear weapons so in an effort to actually prevent that from happening and understanding what was going on they actually created natural English processing fun fact is that the Jew the geolocation that we use now is actually a technology that was also invented by the United States and for the purposes and the first application of natural language processing was a machine that translated Russian to English and the first sentence that was actually translated was a sentence from the Bible the Spirit is willing but the flesh is weak Moses the sentence will actually translate it from English to Russian and then moved back to English and in actually gave this vodka is good but the meat is rotten so we've come a long way since that thankfully and there's actually many applications today that use an exponential language processing one of these is machine translation we used on a daily day to day basis maybe the Google translation device which translates paragraphs in text from any language to English to or any other language in this case we have two french necks from this french author that translated to english and in this case the main reason why these texts actually well translated is because the english words that the french words that are used are extremely simple and direct there's no me duty and as i will show you later one of the main limits of natural language processing is the fact that there's ambiguity within human language the second aspect of natural natural language processing is automatic summarization again in the 1950s given a text the idea is that you basically reduce the whole text reduce the whole paragraph to a version that only keeps the most important information and there's two ways to do that the second way is this next generation approach where you basically use some kind of machine learning to generate words depending on the understanding that the program has this is a more complex approach than the extraction based approach and this one basically the software will look at the text that's given to it and in this case we'll only select the most important sentences within that text and actually create a summary with their specific information this is limited to the extent where there's things such as he or she that may be deemed a important in a sentence but when the summary will be rendered nobody will know who specifically he is so there's definitely limits to this approach a third application of natural language processing is the sentiment analysis so somebody at full-stack Academy for the hackathon has actually created a Twitter sentiment analysis software in this case the idea is to identify subjective information within the text and to rate it as either positive neutral or negative in this case this method is called polarity detection and again AUD can become tricky because if you have a tweet for example such as I hate supersize me it's gonna actually it's actually extremely clear and simple what the polarity of their sentence is but if you have a sentence like this where it says black mass is a great movie only thirty twice there's a component of irony and sarcasm that comes in which actually creates a level of maturity that some sufferers may not understand fourth application of the conversational agent are not NLP are conversational agents these are systems capable of having coherent conversations of humans using food all the robots you speak to on a monthly basis to pay for your internet bill and these also include the tey which is an AI ei which is an AI powered chat released by Microsoft last year so I don't know if most of any of you heard about day but it was a huge failure mainly because of trolls who knowing that Tay was learning after every single tweets actually sent a lot of misinformation to it to say the truth entropy and one of these this one of example one example of this is this tweet that she gave we're going to build a wall and Mexico is going to pay for it so this this chat bot was actually this conversation elation was taken down after a few days very very big failure but it still shows what natural orange processing can do so now how does an LP work NLP actually uses many different subfields of linguistics and there's a lot a lot of subfields that I did not know existed before I she looked into this for example one of these subfields is called pragmatics and this is the study of how context determines meaning within a sentence the whole field - just for that and if we reduce natural English processing to its most basic structure the last Russian understand the words that it's presented work in order I should understand the bigger picture which is a sentence and then the paragraph in text so how does it approach that it uses something called part of speech tagging or POS POS is basically used to analyze the words that are in front of it determine whether these words are objectives or nouns put them into these galleries so that later on I can actually understand the sentence as a whole and there's two approaches again to this the first approach is the symbolic approach in this case the programmer actually creates a set of rules that will mirror how the that specific language works if a verb is given at this point then an a is given after that and the word after that is definitely a noun that's one example of set of rules that you can create the statistical approach you actually uses machine learning to learn the language the problem with that technique is that you actually have to give these machine learning software's a lot of data a lot of label data with these categories so that international learner and there's an example of the symbolic approach is this if it's actually given a sentence which says John bought a book it will actually label each word John will be a noun but could apparently be an objective of a verb and in this case depending on the word action beforehand John will actually use that to determine where the body is an objective or a noun this is an example if I or this is an example of set of goals that can actually be used within the symbolic approach and this in this case this is a part of speech tagging method called the bill tagger approach which is one of the most famous ones so one of the limits the main limit of NLP is ambiguity human language is is extremely ambiguous words can have different meanings similar words can have similar words can have different meanings and different words can also have the same meaning so polysemy is refers to the fact that words can have different meanings in this case the example is the tank is full of soldiers versus the tank is full of hydrogen in both these cases tanks actually the first two different concepts and the way that they some programmers have actually solved this issue is by creating huge lexicons so huge databases where they will Boop certain words together so certain verbs certain objectives or nouns based on a certain theme and by actually looking at this huge lexicon in this case it's called wordnet it'll actually analyze it look at tank and then look at whether there's gas involved and look at within that lexicon itself and see what the nitrogen is actually there and by looking at all these different words understand the context of the sentence second part of the majority and second limit tonight NLP is context the huge part of human understanding is an understanding with length language and what we're talking about is the context of situation what was said beforehand may be inside jokes or said they were shared between people that refer to something completely different than what they actually say on paper and this case John says to Peter you're an idiot Peter responds ok thanks it's very kind of you program might actually label this if he was using some kind of sentiment or my labels is as positive just by simply basing that on that's very kind of you and rejected used so irony and sarcasm are really mechanisms that we take for granted some people struggle with it computers struggle with it even more and these are complex mechanisms that some people have tried to solve through things such as some twitter twitter programs that basically will analyze tweet and based on the objective that is used within that tweet and whether that objective is deemed as an exaggeration will deem that sentence to be ironic or not that's one first step towards establishing concepts which is irony within computers I'm gonna show you right now the Google natural language API in this case Google has actually created a very advanced a language natural language API more advanced than most centimeters I've seen and in this case that she'd given a sentence who ruled hike for Google headquartered in Mountain View unveiled a new Android phone at the Consumer Electronics Show etc this uses POS tagging the thing that I just introduced to you and categorizes every single sentence within within scatter eyes every single word within the sentence in this case Google was given the color blue because it said categorized as an organization mountain hue is given the color green because it's categorized as a location and each single one of these words within the sentence is given in level of importance quotes aliens this level reporters in this case if you look at Google it's 0.26 the highest one out of all the words that are colored and it's done so that the actual natural English process we can determine which part of the sentence is the most important one so later on can determine which parts can be taken away and which parts have to be kept if you look at the sentence the natural language API will actually also has a centimeter and every single sentence and based on the specific words that I used gives it a positive or negative rating in this case most of the ratings are positive 3 0.2 and 0.8 and we'll then average that to give a rating to the sentence as a whole finally this is actually the most advanced thing that I've seen out of all the api's that I've looked at who s also analyzes the syntax of every single sentence they look at the relation of each word in terms of the other so and here you can see that you can see the green line which is called dependency and he said Google is connected to availed which is then connected to right here you can see the line to add which is then connected to show by doing that they can actually minimize the sentence with most important components and they can actually group these different areas these different parts of the sentence together so that if shows taken away because all these words are dependent then the meaning is lost this is basically natural language processing and the potential for natural English processing for the future is actually great one of these things is the fact that BOTS can actually be enabled to have a deeper understanding of human language by allowing them to understand these different things such as you irony folk colloquialism so different words that are only used in certain locations these boss can actually be able to interact and as a result of that the customer service industry can actually be taken away which is something that people might consider to be a benefit or a curse the UI interface of websites and applications will also change because the UI is usually seen as only the visuals about the consumer sees but now the UI will also be an audio it also be what the consumers will listen and what they will interact with and by actually developing this you more and more websites will be using these different natural language processing devices that users can interact with them one of the last things about natural language processing is that I can act can actually greatly be improved if more variables are added to it if these natural language processing applications can actually analyze things such as tone which is a huge variable in terms of irony or sarcasm to even I even look at facial movement or area eye movement it can actually use that to determine the centum of a person when they said a certain sentence which is useful in many applications one of which could be trial cases or even just looking at movies or understanding other people and this is basically it this is my introduction to natural language processing thank you [Applause]",
            "userFeedbackScore": 0.3,
            "videoid": "4vLlF3flSeg",
            "viewCount": "1342"
        },
        "5isBs5WFbf0": {
            "NumOfComments": 17,
            "caption_exist": "T",
            "channel_id": "UCHBQVj6Cho6wuVaY_uUA_xw",
            "channel_title": "NLPTimes",
            "comment_sentiment": 0.24637565253374075,
            "concepts": [
                [
                    "nlp",
                    9
                ],
                [
                    "programming",
                    4
                ],
                [
                    "tool",
                    3
                ],
                [
                    "neuro linguistic programming",
                    3
                ],
                [
                    "field",
                    2
                ],
                [
                    "set",
                    2
                ],
                [
                    "first",
                    2
                ],
                [
                    "mean",
                    2
                ],
                [
                    "born",
                    2
                ],
                [
                    "parent",
                    2
                ],
                [
                    "subjective experience",
                    2
                ],
                [
                    "language",
                    1
                ],
                [
                    "impact",
                    1
                ],
                [
                    "root",
                    1
                ],
                [
                    "economy",
                    1
                ],
                [
                    "bos",
                    1
                ],
                [
                    "constraint",
                    1
                ],
                [
                    "human",
                    1
                ],
                [
                    "power",
                    1
                ],
                [
                    "series",
                    1
                ],
                [
                    "block",
                    1
                ],
                [
                    "resource",
                    1
                ],
                [
                    "skill",
                    1
                ],
                [
                    "moment",
                    1
                ],
                [
                    "called",
                    1
                ],
                [
                    "machine",
                    1
                ],
                [
                    "force",
                    1
                ],
                [
                    "scientist",
                    1
                ],
                [
                    "information",
                    1
                ],
                [
                    "help",
                    1
                ],
                [
                    "find",
                    1
                ],
                [
                    "content",
                    1
                ],
                [
                    "sign",
                    1
                ],
                [
                    "money",
                    1
                ],
                [
                    "eye",
                    1
                ],
                [
                    "communication",
                    1
                ]
            ],
            "description": "\u202ahttp://tinyurl.com/free-nlp-video-series In this video I share what is NLP (Neuro Linguistic Programming) and how it has been used by companies and people all around the world. Visit http://tinyurl.com/free-nlp-video-series to enjoy 20 free NLP videos.\u202c",
            "dislikeCount": "29",
            "duration": "PT5M2S",
            "likeCount": "206",
            "published_time": "2011-04-11T09:13:36.000Z",
            "tags": [
                "nlp",
                "neuro linguistic programing",
                "nlp courses",
                "derren brown nlp",
                "what is nlp",
                "richard bandler",
                "tony robbins",
                "nlp faq",
                "nlp for beginners",
                "neuro linguistic programming",
                "neuro-linguistic programming",
                "what is nlp?",
                "nlp introduction",
                "nlp what is",
                "nlp training",
                "introduction to nlp",
                "introducing nlp",
                "nlp times",
                "intro to nlp",
                "nlp explained",
                "nlp beginners",
                "nlp what is it",
                "what's nlp",
                "nlp intro"
            ],
            "thumbnail": "https://i.ytimg.com/vi/5isBs5WFbf0/hqdefault.jpg",
            "title": "What is NLP?  | Simple Explanation (Introduction to NLP)",
            "transcript": "  what is NLP this is a tricky question to answer because unlike other fields NLP doesn't have one specific definition and what NLP neuro-linguistic program is is going to differ from person to person however let me share with you my perspective but hopefully we give you a good grip on what this sometimes mystical field is all about let's start at the beginning human beings are learning machines from the very moment you're born through the day you die you're constantly having to adapt to your experience of living in the world and the cool thing is the experience each of us have you and I of living varies and it's gonna vary from person to person no to people experience being alive exactly the same way heck where you were born what your parents called you has a big impact on what you get to experience today neuro linguistic programming also known as NLP is concerned with how a person uses their mind and body to organize their perceptions and behavior now that's a fancy way for saying it's interested in how you think feel and use your body to produce specific results whether that is to make yourself feel great or friend make your friends laugh or your boss consistently accept your suggestions and literally everything in between the way you use your five senses your body and the way you language your experience from the basic building blocks and how you experience the world for example a trader will have a very different outlook on what different movements in the economy need first to say a mom or scientist and because they're better able to make better distinctions about new information they can perform much better in the pursuit of some goal essay to make more money for the company NLP shows us that it's not just what you know but how you think about something that really matters we call it knowing what's the difference that makes the difference neuro linguistic programming has opened up a whole new world of possibilities of having power four tools to help you improve your life by working on your mind because the meaning and distinctions someone can make about any given subject or experience is going to depend on who's looking how they're looking at it and what filters they're using where exactly they're looking at it from as practitioners of NLP we say we're interested in the structure of a person's subjective experience and what can be calculated from now subjective experience is just a fancy term it's a way for saying how an individual organizes their senses about the world for example if you've got kids when you come home do your first look to see what's out of place and hear yourself go geez he's still not tidied up and then have an angry feeling or perhaps you hear your kid playing see he's happy and think the place is a mess but that's fun growing up is all about and feel at ease what you do on the inside makes a big difference but why does all this mean in practice it means that you don't have to stay stuck with constraints or difficulties that you may have what are their thoughts feelings unhelpful behaviors you don't have to be stuck with some label or some poor dumontet performance if you don't want it it means you can create and have more of the things and experiences you want for your life much quicker whether that is a feeling of greater confidence a sense of peace I capability to produce a specific success in any area of your life but NLP is not a magic bullet you can't become somebody entirely new who has amazing skills at everything overnight but it is one of the most powerful personal change and communication tool sets available today and who doesn't have something they want to change or be better eyes NLP can provide you with the means to create a lasting change and be more effective in all areas of your life at its root NLP is concerned with helping you having more of the choice you want in your life through its series of powerful techniques anyone can re-educate the brain and body to act differently which will lead to new and much better results neuro linguistic programming has been used at this stage by millions of people around the world from world leaders not the Armed Forces sports team multinational companies entrepreneurs parents you know in the last 40 years it's been used by people around the world in numerous industries because it provides an exceptional tool set for cheating truly impressive results whatever it is that you decide you want those to be now if you'd like to learn more about noir linguistic programming then feel free to sign up to our newsletter at www.mptv.org or find love great resources and further content about many different aspects of MLP thanks for watching",
            "userFeedbackScore": 0.39842040358212916,
            "videoid": "5isBs5WFbf0",
            "viewCount": "39254"
        },
        "FLZvOKSCkxY": {
            "NumOfComments": 100,
            "caption_exist": "T",
            "channel_id": "UCfzlCWGWYyIQ0aLC5w48gBQ",
            "channel_title": "sentdex",
            "comment_sentiment": 0.20249528018278012,
            "concepts": [
                [
                    "language",
                    27
                ],
                [
                    "python",
                    20
                ],
                [
                    "nlt",
                    15
                ],
                [
                    "natural",
                    11
                ],
                [
                    "pretty",
                    10
                ],
                [
                    "first",
                    10
                ],
                [
                    "tokenize",
                    9
                ],
                [
                    "nlt kay",
                    8
                ],
                [
                    "download",
                    8
                ],
                [
                    "english",
                    8
                ],
                [
                    "form",
                    7
                ],
                [
                    "quick",
                    7
                ],
                [
                    "natural language processing",
                    7
                ],
                [
                    "processing",
                    7
                ],
                [
                    "separate",
                    6
                ],
                [
                    "analysis",
                    6
                ],
                [
                    "window",
                    5
                ],
                [
                    "english language",
                    5
                ],
                [
                    "stuff",
                    5
                ],
                [
                    "programming",
                    5
                ],
                [
                    "pip",
                    5
                ],
                [
                    "import",
                    4
                ],
                [
                    "journal",
                    4
                ],
                [
                    "computer",
                    4
                ],
                [
                    "speech",
                    4
                ],
                [
                    "find",
                    4
                ],
                [
                    "real quick",
                    4
                ],
                [
                    "space",
                    4
                ],
                [
                    "sentiment analysis",
                    4
                ],
                [
                    "module",
                    4
                ],
                [
                    "understand",
                    4
                ],
                [
                    "tokenizing",
                    4
                ],
                [
                    "list",
                    3
                ],
                [
                    "regular expression",
                    3
                ],
                [
                    "built",
                    3
                ],
                [
                    "programming language",
                    3
                ],
                [
                    "process",
                    3
                ],
                [
                    "course",
                    3
                ],
                [
                    "element",
                    3
                ],
                [
                    "word tokenize",
                    3
                ],
                [
                    "real basic",
                    3
                ],
                [
                    "medical journal",
                    3
                ],
                [
                    "dictionary",
                    2
                ],
                [
                    "power",
                    2
                ],
                [
                    "political",
                    2
                ],
                [
                    "location",
                    2
                ],
                [
                    "second",
                    2
                ],
                [
                    "type",
                    2
                ],
                [
                    "python programming language",
                    2
                ],
                [
                    "64-bit version",
                    2
                ],
                [
                    "capital",
                    2
                ],
                [
                    "spoken language",
                    2
                ],
                [
                    "hit enter",
                    2
                ],
                [
                    "wheel",
                    2
                ],
                [
                    "command prompt",
                    2
                ],
                [
                    "install thing",
                    2
                ],
                [
                    "nl ck",
                    2
                ],
                [
                    "main idea",
                    2
                ],
                [
                    "written language",
                    2
                ],
                [
                    "based",
                    2
                ],
                [
                    "nlt kay download",
                    2
                ],
                [
                    "python list",
                    2
                ],
                [
                    "understand text",
                    2
                ],
                [
                    "pretty cool",
                    2
                ],
                [
                    "market",
                    2
                ],
                [
                    "yeah",
                    2
                ],
                [
                    "article",
                    1
                ],
                [
                    "significant",
                    1
                ],
                [
                    "parameter",
                    1
                ],
                [
                    "general",
                    1
                ],
                [
                    "operating system",
                    1
                ],
                [
                    "system",
                    1
                ],
                [
                    "globe",
                    1
                ],
                [
                    "english dictionary",
                    1
                ],
                [
                    "interest",
                    1
                ],
                [
                    "information",
                    1
                ],
                [
                    "core",
                    1
                ],
                [
                    "nlp",
                    1
                ],
                [
                    "state",
                    1
                ],
                [
                    "control",
                    1
                ],
                [
                    "machine learning",
                    1
                ],
                [
                    "series",
                    1
                ],
                [
                    "matter",
                    1
                ],
                [
                    "animal",
                    1
                ],
                [
                    "mean",
                    1
                ],
                [
                    "fall",
                    1
                ],
                [
                    "link",
                    1
                ],
                [
                    "economy",
                    1
                ],
                [
                    "data",
                    1
                ],
                [
                    "block",
                    1
                ],
                [
                    "watching",
                    1
                ],
                [
                    "weather",
                    1
                ],
                [
                    "indicator",
                    1
                ],
                [
                    "training",
                    1
                ],
                [
                    "machine",
                    1
                ],
                [
                    "group",
                    1
                ],
                [
                    "united state",
                    1
                ]
            ],
            "description": "Natural Language Processing is the task we give computers to read and understand (process) written text (natural language). By far, the most popular toolkit or API to do natural language processing is the Natural Language Toolkit for the Python programming language. \n\nThe NLTK module comes packed full of everything from trained algorithms to identify parts of speech to unsupervised machine learning algorithms to help you train your own machine to understand a specific bit of text. \n\nNLTK also comes with a large corpora of data sets containing things like chat logs, movie reviews, journals, and much more!\n\nBottom line, if you're going to be doing natural language processing, you should definitely look into NLTK!\n\nPlaylist link: https://www.youtube.com/watch?v=FLZvOKSCkxY&list=PLQVvvaa0QuDf2JswnfiGkliBInZnIC4HL&index=1\n\nsample code: http://pythonprogramming.net\nhttp://hkinsley.com\nhttps://twitter.com/sentdex\nhttp://sentdex.com\nhttp://seaofbtc.com",
            "dislikeCount": "52",
            "duration": "PT19M54S",
            "likeCount": "2990",
            "published_time": "2015-05-01T16:25:39.000Z",
            "tags": [
                "Programming Language (Software Genre)",
                "Outline Of Natural Language Processing",
                "Natural Language Toolkit (Software)",
                "Python (Programming Language)",
                "Natural Language Processing (Software Genre)",
                "Computer Science (Field Of Study)",
                "tokenizing",
                "sent_tokenize",
                "word_tokenize",
                "nltk",
                "nlp"
            ],
            "thumbnail": "https://i.ytimg.com/vi/FLZvOKSCkxY/hqdefault.jpg",
            "title": "Natural Language Processing With Python and NLTK p.1 Tokenizing words and Sentences",
            "transcript": "  hello everybody and welcome to a Python programming tutorial for the NLT K or natural language toolkits module the natural language toolkit module is for natural language processing or NLP so what is that so natural language processing is the process of getting a computer to understand natural language now usually this is in the form of written language and sometimes it can be in the form of spoken language but usually spoken language gets converted to written language then to numbers but sometimes it doesn't it just gets straight converted to numbers as well so it is the process of converting some form of language to something that the computer can understand which is numbers so what can we do with that so n LT K is actually the first module that I ever worked with and is actually the reason why I chose the Python programming language because really no other programming language has any sort of API or module or whatever you want to call it for natural language processing so this here is my example this is my personal company or business that uses sentiment analysis which is a form of natural language processing so I'll just show real quick just 30 seconds some of the things that we do here just as an example what you can do but obviously sentiment analysis is such a tiny portion of what all you can do with a computer that can understand text so for example we do sentiment analysis for finance stuff so this would be for stocks so we could choose Apple for example and this is the sentiment analysis for Apple and we can actually see this sentiment has been going up pretty pretty strong and today's actually a pretty good day for Apple as well so there's that then we've liked politics so we measure sentiment on political issues we've got about 50 different political issues war is the most popular by far than NSA economy oil immigration you just keep going down we also have sentiment on politicians themselves this is not just the indicator obviously we have graphs too so there's sentiment for Barack Obama for example anyway so we do stuff like that and then also we have geographical this is probably my favorite one that I have so far but based on what people are saying and where they are from I plot it up on a globe we go basically by city so this gets as granular as per city and so we can do this we can get you know the last 30 days of sentiment globally but also we can find out what are the popular topics that people are talking about so for the United States or North America rather you've got love YouTube youtubes probably just because people are linking to YouTube videos Durer that's literally turn that's that okay so people are really talking about that right now for some reason I believe that's the most popular thing in the last one week right now yeah you've got Supreme Felix but anyways you can find out what people are talking about and their opinion on it in via the location so I think that's pretty cool can we do that for other locations as well so that's just a quick example of something that you can do and how powerful natural language processing can become and how you can translate just natural language to all sorts of things that are pretty cool and useful so moving on we've got n ltk org is basically where you're going to go to acquire n lck or any information on alt K although you don't actually have to get it from here and this is probably the more difficult path that you would take to even get it so the shorter path to getting it let me just close the existing one and let's open up the command prompt so to get that what you would do is if you've just installed Python obviously you're going to need Python to do this so if you don't have Python like this might actually be a lot of people's first foray into the Python programming language as it was mine because of NLT k so if it is your first you will need Python and we don't have Python up so let me pull up Python or click python.org and what you want to do if you don't have python go to downloads and then I'm pretty sure this just senses my operating system so you would just choose Python 3.4 or whatever the latest version of python is it should be cross-compatible the only thing that won't be is with two so please don't use two otherwise download that that will be the 32-bit version of Python and that should be fine so once you have that you should be able to open up bash your command prompt whatever and just do a simple pit install and ltk I would hit enter but it's not going to work in fact I'll show you it's just not going to work because this is four to seven and I have a 64-bit version of to seven so it's going to get angry if you are somebody who has a 64-bit version of Python you'll want to go to that website usually link to when you go ahead and pull it up real quick that is what's taking a while this website and then you can do ctrl f NL TK click on that and then here's your allen ck wheel and just click on that download it and what that's going to do is allow you to install it with pip and if you don't know how to install things with pip luckily for you there's a website for that and that's this website whoa it's mine so he can go to start learning here that's in the basics which is control f4 pip and bang here we have a pip installation tutorial which will also cover how to install things with NLT or I'm sorry with the wheel files like from this website for example so you can grab this if you don't know how to use pip otherwise once you have an LT k and you've got it installed or at least you think you do you're ready to move on to the next part so I'm going to go ahead just minimize this stuff because we don't need this right now so the next step that you're going to want to do is you're going to make sure you can go import NLT K in your idle or whatever IDE you use so this is just where you type your code so I like to use idle everyone has their own favorite and everyone thinks everyone should use theirs I like idle you can use whatever you want pycharm or whatever if you don't know what an IDE is this is ID le and if you don't know how to get there hit go up to your search or start bardu ID le and then you'll just click on one of these this is the one I'm going to be using it'll pop up a window like this go file new file and this is your new Python file then when you're ready you can save it save it wherever you want eventually deploy matter where you have it but about that later and you'll just have to save it to run it and that's about it so I'm going to close this because I've already got one open whoops I guess I hit yes and once you have yours open do import NLT kay and let's go ahead and make sure that works first so press the f5 key to run it it'll save it we'll run it it's taking a second and boom so the import of NLT Kay worked great now what we want to do is go ahead and do NLT Kay download and then empty parameters run that and you should get a pop-up window not just this one but another one I'm waiting for it sometimes it doesn't pop up as it should it's not here yet but it'll show hopefully soon yeah so popped under here it is so this is the window you get now if you are operating headless so say you're operating by a shell or something like that you can still do this you don't actually need a GUI or X or whatever you can still do NLT kay download and then you'll go to like downloads I think and then it'll be like identifier and just type in a ll for all hit enter and you'll download everything if you have a GUI yours looks like this only everything's probably read make sure you go to all and just download all this process can take anywhere from a few minutes to hours depending on your internet connection so choose all hit download and pause the video for now and resume the video once you have everything downloaded okay so once you have everything downloaded what you're going to want to do is maybe see like a real basic and quick example of what ltk can do for you so NLT Kay a natural language processing obviously is an interest for a lot of people that you know want to have computers to read or understand text or speech or whatever so what is the first step that you might do when you want to pull apart a body of text let's say well you're going to want to organize it somehow so let's say you're looking at an article on I don't know the Wall Street Journal and you don't know how to take your next step well your next steps probably going to be either separating paragraph or even separating by sentence and then maybe storing generally you're probably separate by sentence and then store a little identifier about which paragraph that sentence was a part of because if you if you think about it when people write if they write well they have paragraphs that contain you know main ideas and sentences that kind of back up that main idea of that paragraph or the subject of that paragraph whatever it happens to be so you do want to keep that in mind you don't want to just throw that out the window because that you know if the author is is a good author they're actually doing you quite a bit of a favor so it's not like you want to throw that out of the window but organizing by paragraph that's easy you know you split by a new line or something like that no problem now how about organizing by sentence or something like that that gets a little harder so what I want to talk about is tokenizing before we move on to the next video but before we get there probably just knock out a few kind of terms for natural language processing so you have yo seer terms like tokenizing what does tokenizing mean it's a form of grouping things so generally you're going to have two forms of tokenizer x' you're going to work tokenizer x' and then you're going to have sentence tokenizer x' and what they do is a word tokenizer just separates by words sentence tokenizer separates by sentence easy so just keep that in mind that's what tokenizing is you're also going to hear terms of lexicon and corporals what the heck so a corpora is just a body of text so think about a corpora might be a body of medical journal journals so example would be medical journals so this is kind of like it's a body of text where they're all kind of around the same thing so you might have medical journals you might have an example of maybe presidential speeches was another one we've got lexicon and also a core probe would be anything in the English language that's another example of a corpora then you've got lexicon and look Scott you can just think lexicon like a dictionary okay this is the words and their meanings now again this varies right so for the English language that would be like the English dictionary but consider for example the difference between investors speak and regular English speak okay so the difference we can see with someone who is a a bull versus someone who is a bear right so let's say investor speak bowl investor speak bowl equals someone who is positive about the market right that's a bowl some bullish on the market as opposed to you know English speak which is just the general English language that Bowl is you know scary animal you don't want running at you right that's a bull so keep that in mind the difference between corpora just a body of text lexicon is the words and their meaning basically and then as when you convert two numbers words and their and their values so those are some words let's talk about tokenizer z' for now and then we'll conclude this video so i just want to show you a real quick example of something real basic with NLT k yet extremely powerful and valuable as well so let's get rid of this NLT k download nonsense and first we're going to say uh we're going to do from NLT k tokenize we want to import the cent tokenize in word tokenize you might be able to guess what these do okay so let's just come down here I'm going to leave these just for the record I always post all of my code online so you'll be able to find the code here by going to Python program Internet dashboard data analysis and NLT kay it'll be right here this is the older version of NLT Kay I did have a series on NLT Kay long ago is filmed with potato and it needed to be updated very badly so here it is so you'll be able to find it here anyways whenever this is live I also post all the source code on github slash Python programming so plenty of options for you and obviously if you're falling behind or have questions you can always post on the video anyway moving on I'm going to leave this here just for the sample code purposes not everybody watches the videos so let's say we have an example text and this is going to be a sentence so our group of sentences will be something like hello there how are you so if I was to ask you first of all to separate this sentence by word how might you do it well most people are gonna be like okay that's simple uh we're going to just separate split by space right that's good enough that would split every single one of these words and then if we said um let's see how are you doing today the weather is great and Python is awesome okay and then let's say let's do the sky is pinkish blue you should not eat cardboard ok so now how would you separate so you've decided you're gonna separate words by a space ok that's probably like 85% accurate now what about splitting up sentences well you'd say probably okay that's easy enough we're going to use punctuation followed by a space followed by a capital letter that's pretty good too but what if we had something like this hello mr. Smith we've got punctuation space capital that is not a new line or a new sentence rather so things like this are going to trip you up really fast now of course you could build a pretty good regular expression to split by sentence and split by words but it would be a pretty significant one to get as much as an Tek is going to get so that's basically how n LT K does it so we're going to utilize n LT K to split this by sentence and by word and at least show you how powerful n LT K is and save you like hour years of riding around regular expressions okay so first let's do by sentence so let's print sense underscore tokenize and we want to sent tokenize example text so I'm going to copy and paste example text right in there so let's print that okay and it creates a list okay so this is just denote denoting that this is a Python list so the first element hello mr. Smith how you doing today so it did not fail or fall for this right and it captured everything awesome so then what if we wanted to do by word okay so now we can do print word underscore tokenize example texts we'll leave the other one there it's fine to leave it there now you can see it split it by word and again it left mr. period as its own word entirely because as you'll see it actually treats punctuation as its own board you can do away with that if you want by default it recognizes punctuation as its own kind of meaning so it's going to split that but as you can see it did not do it there as a successful catch otherwise it splits everything as you might expect now this is again a Python list but of course if you wanted to reference individual elements you could do something pretty simple so if you want to comment out a block of text it's really simple highlight everything alt 3 if you're an idol anyways and that will do it now what we could do is we could say 4 5 in and we'll do word tokenize we'll just say it will highlight this copy paste for I so for each element basically in word tokenize example text print I save it run that and I've got a nice output hello mr. Smith how are you doing today and so on ok so um those are just some real quick example of how we can begin to pull apart text and even sentences and then obviously like I said paragraphs it's not really so necessary to tokenize by paragraph because it's really simple to tell what a paragraph is but telling sentence is not so easy and telling words surprisingly enough not so easy now of course this is just the real basic stuff this is more of pre-processing of anything rather than any sort of analysis or anything like that but as we go on we'll see that NL CK can do really powerful things like part of speech tagging where it recognizes what part of speech things are and all that it's a lot more complex these are things that you probably wouldn't be able to do even in a few hours with regular expressions so that's we're going to start talking about the only other thing I will mention is that tokenizer x' we'll talk a little bit more in one of the next videos maybe the next one about some of the various forms of tokenizer x' so there's more than just this basic scent tokenizer there are some more advanced ones where you can actually use unsupervised machine learning built into an LT k you don't even know how it works you just use it to make your own tokenizer is entirely based on your fancy word corpora so that's that the only other thing I will say too is on CK by default works with the English language for the most part but it actually does work with other languages so if you're looking to do this with Spanish or whatever else look into it because it probably is included with NL CK it's not probably not going to be as built up as the English language is but the other major languages are actually pretty well built up so make sure to check that out and if not they can be because there are trainers and ltk trainers for just about anything you could make your own language training ltk to it and it would work so anyway a little bit long for the first video most videos won't be this long but I did want to give you guys at least a quick taste of the power of nl t cane really you can utilize this power in about three or four lines and see how how incredible it is already so I think it's really cool so there's a lot of cool stuff coming as always if you have any questions or comments please feel free to leave them below otherwise as always thanks for watching thanks for all the support and subscriptions until next time",
            "userFeedbackScore": 0.4314902858715358,
            "videoid": "FLZvOKSCkxY",
            "viewCount": "375841"
        },
        "GDso6md3DBw": {
            "NumOfComments": 0,
            "caption_exist": "T",
            "channel_id": "UC5zx8Owijmv-bbhAK6Z9apg",
            "channel_title": "Artificial Intelligence - All in One",
            "comment_sentiment": 0,
            "concepts": [
                [
                    "similarity",
                    23
                ],
                [
                    "system",
                    8
                ],
                [
                    "cat",
                    7
                ],
                [
                    "language",
                    4
                ],
                [
                    "pretty",
                    3
                ],
                [
                    "text similarity",
                    3
                ],
                [
                    "natural",
                    3
                ],
                [
                    "information",
                    3
                ],
                [
                    "natural language processing",
                    2
                ],
                [
                    "level",
                    2
                ],
                [
                    "human",
                    2
                ],
                [
                    "morphological similarity",
                    2
                ],
                [
                    "food desert",
                    2
                ],
                [
                    "return document",
                    2
                ],
                [
                    "processing",
                    2
                ],
                [
                    "desert",
                    2
                ],
                [
                    "name",
                    2
                ],
                [
                    "application",
                    2
                ],
                [
                    "mean",
                    2
                ],
                [
                    "data",
                    2
                ],
                [
                    "score",
                    2
                ],
                [
                    "data set",
                    2
                ],
                [
                    "set",
                    2
                ],
                [
                    "speech",
                    2
                ],
                [
                    "first",
                    2
                ],
                [
                    "english",
                    2
                ],
                [
                    "variance",
                    1
                ],
                [
                    "algorithm",
                    1
                ],
                [
                    "special",
                    1
                ],
                [
                    "approach",
                    1
                ],
                [
                    "based",
                    1
                ],
                [
                    "translation",
                    1
                ],
                [
                    "cost",
                    1
                ],
                [
                    "common",
                    1
                ],
                [
                    "content",
                    1
                ],
                [
                    "book",
                    1
                ],
                [
                    "suffix",
                    1
                ],
                [
                    "movie",
                    1
                ],
                [
                    "statistic",
                    1
                ],
                [
                    "understand",
                    1
                ],
                [
                    "speech recognition system",
                    1
                ],
                [
                    "synonym",
                    1
                ],
                [
                    "speech recognition",
                    1
                ],
                [
                    "noun",
                    1
                ],
                [
                    "information retrieval",
                    1
                ],
                [
                    "computer",
                    1
                ],
                [
                    "light",
                    1
                ],
                [
                    "pattern",
                    1
                ],
                [
                    "find",
                    1
                ],
                [
                    "range",
                    1
                ],
                [
                    "linguistics",
                    1
                ],
                [
                    "sound",
                    1
                ],
                [
                    "category",
                    1
                ]
            ],
            "description": ".\nCopyright Disclaimer Under Section 107 of the Copyright Act 1976, allowance is made for \"FAIR USE\" for purposes such as criticism, comment, news reporting, teaching, scholarship, and research. Fair use is a use permitted by copyright statute that might otherwise be infringing. Non-profit, educational or personal use tips the balance in favor of fair use.\n.",
            "dislikeCount": "1",
            "duration": "PT7M27S",
            "likeCount": "29",
            "published_time": "2016-03-25T03:53:18.000Z",
            "tags": [
                "Natural Language Processing",
                "Language Processing",
                "University of Michigan",
                "Michigan",
                "NLP",
                "Coursera",
                "Dragomir R. Radev",
                "Computational Linguistics",
                "Linguistics",
                "Information Retrieval",
                "Computer Science",
                "Video Lecture",
                "Video Tutorial",
                "Video Course",
                "Course",
                "Data Science",
                "Text Similarity"
            ],
            "thumbnail": "https://i.ytimg.com/vi/GDso6md3DBw/hqdefault.jpg",
            "title": "Lecture 8 \u2014 Text Similarity (Introduction) - Natural Language Processing | Michigan",
            "transcript": "  this segment is going to be about tech similarity text ability is one of the applications of linguistics and statistics to natural language processing and it helps in many different applications there are many ways in which people can express the same concept or related concepts for example we can say the plane leaves at 12 p.m. but we can also say the flight departs at noon except for the words like the a nap the rest of the words and the sentences are very different in yet they express the exact same meaning as I mentioned earlier at TechSoup light is one of the key components of natural language processing for example in an information retrieval task if the user is looking for information about cats we may want the system to return documents that mention the world kittens and not the word cat so the document may not have any words in common with the query and still be related because cat and kitten are similar words another example is if the user is looking for information about a food desert we may want the NRP system to return documents about peach tarts or Apple cobblers in each of those examples we have a specific fruit and a specific dessert but both of those items are special cases of food desert another example is about a speech recognition system for example if I want to fly to Dulles Airport sometimes the system may hear me incorrectly and figure out that I want to go to Dallas and it may put me on the wrong flight however if a system knows in advance that Dulles and Dallas are sound very similar it may tweak its algorithm so that if it picks up one of those two it may ask me to confirm if I didn't mean the other one it doesn't need to do this for names of cities that are not so similar so for exactly five ask about Dulles it's never going to ask me do you really mean San Francisco so in this segment of this lecture I'm going to teach you how text similarity can be modeled computationally let's start first with some human judgments of similarity I'm showing you here an example from a paper by Finkelstein at all for 2002 where they asked people to determine how similar two words are so they gave them words like tiger and and obviously they got to the maximum similarity score from the human judges in this case ten out of ten then they gave them tiger and cat and they got a similarity of an average of 7.35 book and paper had a similarity of about the same range computer and keyboard also about seven point five now some other examples playing in car had a similarity of five point seven cucumber and potato had a similarity of 5.92 one interesting thing is that the variance of those scores was actually pretty high so clearly there was not much user agreement whether certain two words are very similar or less similar but they still agreed generally about the overall level of similarity so one other example is from a more recent paper was just published in 2014 by Felix Hill at all it has a much larger data set with 999 words all kinds of parts of speech including adjectives verbs nouns and adverbs for example they figure that delightful and wonderful are very similar with the similarity of 8.60 five out of ten whereas modest and flexible were not similar at all their similarity being only 0.93 you can look at some of the examples on the slide just stop one of them argue and persuade were moderately related 6.33 similarity versus pursue and persuade which had a much lower similarity of 3.17 so this kind of data sets can be used to train natural language systems and they can also be used to evaluate systems that automatically compute text similarity one movies an example is by McAuliffe at all in the paper published in 2013 he uses the word to Veck approach which I'm going to talk about later and he was able to compute automatically the words that are most similar to France based on the context in which they appear those words are shown in the table so not surprisingly the words that are most similar to find our countries that are near France geographically Spain Belgium the Netherlands Italy Switzerland and so on now let me describe the different kinds of text similarity that exist the first kind is morphological similarity we have two words such as respect and respectful that have the same stem but then they have a some additional morphological change in this particular example the word respectful is an adjective derived from respect and the suffix fool tells us that it's an adjective but the two words are morphologically very similar they share pretty much the same meaning the next example is spelling similarity it can be useful for example in dealing with different versions of dialects of English for example in British and American English the word theater can be spelled either with an ER at the end or ar e so we want a system to understand that those are pretty much the same word because they look very similar and they follow a very specific pattern of changes that appears across those languages synonymy is when two words have very similar meanings it's very rare for towards to have exactly the same meaning but it is usually enough for there to be close enough to be considered synonyms so talkative and chatty are synonyms another category of similarity in text is homophony that's when you have multiple words that have possibly different meanings but have the same pronunciation so raised RA is e raised Raz and also raised as RA YS all of those are pronounced the same way we can also have different kinds of semantic similarity for example cat and tabby are semantically related because the word tab is usually used to refer to a specific kind of cat specific color cat they can also be similarities among sentences for example two sentences may paraphrase each other and we can have also simulated the level of documents for example two news stories reported independently on the same event we often very similar content and I would also like to add an additional example of similarity that namely cost lingual similarity for example the word for Japan in Japanese is Nihon so sometimes the name of an organization may be translated Nihon or Japan depending on who does the translation we want to be able to identify that those refer to the same country so in the next segment we're going to talk specifically about morphological similarity and stomach",
            "userFeedbackScore": 0.27999999999999997,
            "videoid": "GDso6md3DBw",
            "viewCount": "5588"
        },
        "LAtzapS2GBU": {
            "NumOfComments": 7,
            "caption_exist": "T",
            "channel_id": "UC9xghV-TcBwGvK-aEMhpt5w",
            "channel_title": "atoz knowledge",
            "comment_sentiment": 0.1879761904761905,
            "concepts": [
                [
                    "language",
                    16
                ],
                [
                    "natural",
                    12
                ],
                [
                    "natural language processing",
                    11
                ],
                [
                    "processing",
                    11
                ],
                [
                    "english",
                    5
                ],
                [
                    "nlp",
                    4
                ],
                [
                    "array",
                    3
                ],
                [
                    "type",
                    3
                ],
                [
                    "watching",
                    3
                ],
                [
                    "python",
                    2
                ],
                [
                    "link",
                    2
                ],
                [
                    "based",
                    2
                ],
                [
                    "application",
                    2
                ],
                [
                    "product",
                    2
                ],
                [
                    "cd",
                    2
                ],
                [
                    "process",
                    2
                ],
                [
                    "speech",
                    2
                ],
                [
                    "string",
                    1
                ],
                [
                    "control",
                    1
                ],
                [
                    "urban",
                    1
                ],
                [
                    "human",
                    1
                ],
                [
                    "stuff",
                    1
                ],
                [
                    "matter",
                    1
                ],
                [
                    "modulation",
                    1
                ],
                [
                    "name",
                    1
                ],
                [
                    "solid",
                    1
                ],
                [
                    "google",
                    1
                ],
                [
                    "variety",
                    1
                ],
                [
                    "movie",
                    1
                ],
                [
                    "machine",
                    1
                ],
                [
                    "content",
                    1
                ],
                [
                    "randomization",
                    1
                ],
                [
                    "classical",
                    1
                ],
                [
                    "circle",
                    1
                ],
                [
                    "technology",
                    1
                ],
                [
                    "plug-in",
                    1
                ],
                [
                    "front",
                    1
                ],
                [
                    "silicon",
                    1
                ],
                [
                    "knowledge",
                    1
                ],
                [
                    "computer",
                    1
                ],
                [
                    "neuron",
                    1
                ],
                [
                    "find",
                    1
                ],
                [
                    "normal",
                    1
                ],
                [
                    "machine learning",
                    1
                ]
            ],
            "description": "The application of computational techniques to the analysis and synthesis of natural language and speech.\n\nPython Core\n------------\nVideo in English  https://goo.gl/df7GXL\nVideo in Tamil     https://goo.gl/LT4zEw\n\nPython Web application \n----------------------\nVideos in Tamil   https://goo.gl/rRjs59\nVideos in English https://goo.gl/spkvfv\n\nPython NLP\n-----------\nVideos in Tamil   https://goo.gl/LL4ija\nVideos in English https://goo.gl/TsMVfT\n\nArtificial intelligence and ML\n------------------------------\nVideos in Tamil    https://goo.gl/VNcxUW\nVideos in English  https://goo.gl/EiUB4P\n\nChatBot\n--------\nVideos in Tamil   https://goo.gl/JU2WPk\nVideos in English https://goo.gl/KUZ7PY\n\nYouTube channel link\nwww.youtube.com/atozknowledgevideos\n\nWebsite \nhttp://atozknowledge.com/\nTechnology in Tamil  & English",
            "dislikeCount": "0",
            "duration": "PT3M5S",
            "likeCount": "23",
            "published_time": "2018-05-24T07:52:44.000Z",
            "tags": [
                "nlp",
                "Natural Language Processing",
                "text analysis",
                "data science",
                "voice",
                "voice recognition"
            ],
            "thumbnail": "https://i.ytimg.com/vi/LAtzapS2GBU/hqdefault.jpg",
            "title": "What is Natural Language Processing  {in \u0ba4\u0bae\u0bbf\u0bb4\u0bcd}?",
            "transcript": "  hi welcome to ATS of knowledge that comes this video is a language tunnel if you want the same video in English you can find the link in the description box of this video unique in americ-aa Capernaum inna NLP about natural language processing of being in the topic of natural language processing through the machine learning liam artificial Angela Gilliam were our advanced topic or other branch marina so natural language processing other available so human specifically and natural languages a process for another so I am on the English personal a Camille based on a Hindi person so now I'm on do or ammonium and the turn of a computer to pay samples and ammonia it does the process run to the natural language processing so in the many NLP is there are many applications sending a daily day-to-day life continues for you are again one of the application birthing my iPhone director CD meaning of a CD unfunded inning a base of the Cross responding to know who's responsible right so are they really been thinking up a Google assistant right Olivia leavening an array of XA from urban running a marina and array of the speech randomization chat box or movie number of paces no Nia - ah-hoo - OH salam\u00e9 are imagine the language converter a product layer Solaria after depending on the Chinese classical English latrans neurons enigma English no modulation so so like a language mediator Mary our town so I didn't have a natural language processing so natural language processing put the very Qunari apparently and I'm gonna need button otherwise heretic initiation after he went to Korea it being humble orderly earning avoid stuff is normal to know the crossbar on crema leaning on the type could I returning a solid so takes to to speech speech to texture the texture to texture in necessary example now Saldana if a word document learning would happen over everything now or never read mine girl so mistake so spelling mistake so I didn't love my older type of natural language processing de anima D Silla online myself like in LA Chrome or a plug-in like Mary but in my Graham leader after Rosalia planning on eating and ironing England are looking probably in the same meaning of the content type on the Nakhoda even in facebook you pay for a product rapid mistake little girl so no matter so no other ways position for ruining our the keep putting in a gram of mistakes idiot so now Mary Mary are absolutely birthing in a daily definitely used for need to call your name everything know it's a natural language processing that so natural language processing inning implement front of the turning in the language you analogous formula other than area and then be like to be silicon of the Python Arianna but the memory NLP libraries in Java SE string manipulations will call you up the natural language processing kana syllabary Santa create but you have that in Python and adamian the natural language processing Denarius subtopics silica or a texture classified under Liana behavior ad circles so on the variety some upcoming video channel description are short video on our program so he thought of gonorrhea and then will be practically ballooning apartment watching in mind the video either at the description box learning to prosper and the playlist link NLP video to go Elena Katherine could he see can my upload who knows thanks for watching a to acknowledge that thumb in the video put it soon as expect banana in your channel number friends and colleagues followed another thanks for watching here to acknowledge that angular channel an array here we use English limit immunity a technology real slow provide control packs for",
            "userFeedbackScore": 0.4315833333333333,
            "videoid": "LAtzapS2GBU",
            "viewCount": "722"
        },
        "MC97BZqdq0w": {
            "NumOfComments": 1,
            "caption_exist": "T",
            "channel_id": "UCSMqVwPTmerMiCaL_zKRjBw",
            "channel_title": "Dataiku",
            "comment_sentiment": 0.14285714285714285,
            "concepts": [
                [
                    "matrix",
                    9
                ],
                [
                    "data",
                    9
                ],
                [
                    "movie",
                    8
                ],
                [
                    "review",
                    7
                ],
                [
                    "processing",
                    6
                ],
                [
                    "language",
                    5
                ],
                [
                    "natural language processing",
                    5
                ],
                [
                    "natural",
                    5
                ],
                [
                    "probability",
                    4
                ],
                [
                    "tonight",
                    4
                ],
                [
                    "machine learning",
                    3
                ],
                [
                    "account",
                    3
                ],
                [
                    "sound",
                    2
                ],
                [
                    "computer",
                    2
                ],
                [
                    "html bracket",
                    2
                ],
                [
                    "called",
                    2
                ],
                [
                    "class",
                    2
                ],
                [
                    "set",
                    1
                ],
                [
                    "cat",
                    1
                ],
                [
                    "free training",
                    1
                ],
                [
                    "understand",
                    1
                ],
                [
                    "training",
                    1
                ],
                [
                    "spam detection",
                    1
                ],
                [
                    "computer science",
                    1
                ],
                [
                    "linguistics",
                    1
                ],
                [
                    "big data",
                    1
                ]
            ],
            "description": "Data Science Studio Free Training #9 with Hanna Julienne, (Dataiku's Data scientist). This Free Training was recorded on October 27th, 2015. \n\nYou can try Data Science Studio here http://www.dataiku.com/dss/trynow/``\n\nFind more information about Dataiku here : http://www.dataiku.com/\n\nDon't forget to follow us on Twitter to find out about upcoming Free Trainings here: https://twitter.com/dataiku",
            "dislikeCount": "4",
            "duration": "PT19M35S",
            "likeCount": "11",
            "published_time": "2015-10-28T13:04:31.000Z",
            "tags": [
                "Dataiku",
                "DSS",
                "Data Science Studio",
                "Big Data",
                "Data Science",
                "Webinar",
                "Free Training",
                "Natural Language Processing (Software Genre)",
                "How-to (Website Category)",
                "Data scientist"
            ],
            "thumbnail": "https://i.ytimg.com/vi/MC97BZqdq0w/hqdefault.jpg",
            "title": "Introduction to Natural Language Processing",
            "transcript": " it's true come to the ninth free  training was doing data a little pipe to  julienne mahalla honda 1 go into tokyo a  your natural language processing sow just  a few words add me aveline working  for canada size shot at his dating  track so what is natural language  processing and claude haegi general de  1,2 and tolzac finish this area  between linguistics 1 2  computer science this basic iao everything  deal with the text to his computer so in  natural language processing centers at  our machine learning at like world  taekwondo swing machine translation  bout'chou going to focus dead  specific ali at the junction between  natural language processing and machine  learning injunction we can find ascq  like topic segmentation fault this text  we're going to find automatically the  topic for each part of the text  hate singer sting because it's always  track techniques if you use the negative  matrix factorization yoav tarasque like  these spam detection and evry  but there when it wants an algorithm  everything is active hernia gold spam mails  it was never loved processing india  tonight we want to deal with feeling  automatic sow analysis at lille tel  if text is positive and negative 1 2  it can be your soul and sun tzu deal  with very large number  product photo illustrates said what black  turbine toulouse call girl competition  the bag of words  competition so it's fifty your zone move  heroes views which are strong attack  inner feeling going to use data  to learn how to clean text in the data  sound studio holland a togo  productive model with tax culture a  of the nar to use 10 models to predict  siemens in 2010 where the other tubes  writing ivory coast go into these  demonstrations them  we have to understand the little bit  water but carlton text or numbers  because machine learning algorithms  oliver stone number and we have to find  a way to the constructor presentation of  text with numbers so i'm going to  explain the bag of world  represent the chains so we are  going to have to matrix constructs with  the line by review india columns pie ix  onic world in the wall the text date to  710 example may have to cimpello view  this movie is great a house in India bad  bad movie and for each of you were going  to count the number of time it world  happy hours in the review of the first  line we-have this one time event and we  go home  the uav euros presentation of the world  with bad bad movie  do they say and we have to  too bad one of a movie 0if you can can  see that some guys are going to be you  like great house men pack  because they may vary between the review  insomar hairdresser the smic argonautes  forget present in all movie you like  the movies at the hours when we say fleury  necessary and secular tools world  industries in natural language  processing wiwa move from the data 7  so let's go for the demonstrations in  data is a studious of blur and to  deal with tonight we have the rain  was this from the call girl  competition and pouliot planet we can  See That we have a nice day review by cm  witch's tale 2  a weirdness way you love one for  positivo views a second child  negative and obnoxious a sword regime  and so are purple taxi use in the  way it contains non- alphabetic  character with eye foods and we also  6.7 and contains html bracket  this and six notes and your queen beds 1 2  they flee use it like that i know  go into my sap with the doc model  martens matrix we just sing in this  light and we need to clean any line  dataset this to do that we are going to  use prepared by registered action  prepared cherries may  have to processor one which is  processor that uses regula expression  tower moov up html bracket  this weekend just go back to to the  beginning lucie we have the atchiama  we all know i'm here  going to go foam ifans another in  alphabetical characters with the  second time that's it  you can see that you have to the arts  bishops all hindis simplify text  professor yu duck muse two worlds  this story  this europe by clicking here animals the  world as we can also stewart basic  list going to remove hall all the good  guys and dolls its different forms  of the same way to identify it all the  form of the soul man has the unique point  down while rajoie going to just like  that you're going  bill of modern hits i saw vi is clean  dataset we are going to create a new  world is big data this wii bucket akli  all this model stahl indicated kate  predictions nodl to predict zoo cm to  abu in to go to the setting inao cashew a  omis going to use zoology is that  rachel wood to use 7c parameters to use  tax too views sebai of future faults  to taxes which you are not taken in  by the studio studio it  can be taken out of space  should be something that they want to  put in the model so you have to tell  of incest or a feature whore a  arcade or go to choose the bag of  world representation which also because  they can not in the vectorization one  sound selecta of 10,10 way to  represents this text  we want to save things and the model  in Cairo its showcase to be to take you  see games sauzeau  and the oath rope the fruit of 12 to the  stable performance we see that we have  what to be satisfied moodle institute  check the confusion mc trx we see  that most view that are actually  positive after said he  quite positive mahmoud at 1 2 2  the review that are not correctly  predicted to are not arnott numerus ifri  Czech gives itself city cat or icisa  all class america she discriminates  haiti we have an absence of  producers probability 1d x or there had  of a titi representation of practices  head of probability by the present  class know if you go to the  relationships after interpreter of  models this weekend at bezons  coefficient of each world and we'll see  that negative France to negative confession  the file what story without  lyrics i was positive of like  excellence have positive that fish it so  it is it worked fail whale boots we can  you can not be in proves to 10 10  performances this to explain now we're  going to go back to decide just do it  all his friends  we have seen in the bag of words  representation saint paul bacot times of  representation we take it world  separated from each other from 8.11 tech  order in down payment boots  in fact order that amateur of vote be  Yann stotz we-have is to review the  first is not taxes were 10  movies will wright 1 2 seconds one is  this movie is not quite to mme ouellet  disappointed and its internal world  exact account is said so in tarn  representations in the bag of war 2  matrix 10 cents identical to 108 2  m6 mobile goddyn offer offer info  modeling and the what we can do is had  called in the matrix that represents  sus success if world says sarko to  Bahrain a we can not even go further  with and dreams an issoire own disc  stunts not good will be consider there  that if new world and we are going to  account each time not good aps one of  small ennahar matrix tonight in toulouse  at the data a studio or going to go  back to the models a loonie going to  modified setting so we go back  to the future  both taxes feature a william effect  lane as ingram by which enables  rise all your rich man and just one  world in account is going to put to  save the parameters and time the new  model is organized thou hast flow  ok so we see by the dissent score are  outside the model is better than the previous  one by one two go down to the co  efficiency interpretation soas before  we see that negative world have  negative that fish is beats so what is  well in this thing we have my way  this happy days to be to be very  informative finestone worth alone could  be in the world website of we have to  distinguished worth from not work  handicapped as well as to a states  negative that the files at best it  ferrari different forms best because  the best is negative  butt best show lady will fight back to  placards me steeve positive that the  files or so this is useful at work  positive flavors coffee shops why not war  except what does it mean to the negative  coffee shops a Yugoslavian france not  good be here you are at dingsheim  but claude of science in arms and it's  in the truth two models one of the two  ferries easy to gas so now that we  have a nice model weekend at  deploy  so i can do that have already done that  one suave deployed since can use  called option to score model sun  at munchhouse corse this test test data  from competition will snap a man  going to get the test data set with  the probability of being a negative  previews probability of being positive  review and at the prediction so if we  have one you have the right of the model  so that the fortunate thank you for  reaches 10.1 of if you won your way up  texts  ok so the sun and the used by words  by want want you go further mourning  or what baby g's are that way  it seems to me that would have more  complex in town 1 of cakes better  presentation of a text ie it is to  if you had more more successive world  you are going to cape more complex  features some 400 young people by barring  feature gerra going to have it so age  in two documentaries matrix is \u200b\u200bgoing to  be solage insos stuffing at you can just  stores it in memory of our nation 14  and matrix beat when evans thor the zoo  match between the term india  columns in the matrix a die in  disguise you have to use the h of  lashing trick boots in disguise you are  not going to have-have-have we seen coffee  shops in the middle  corresponding world you are just want to  have a nice day and said guy book of  by the aching function used 1 2 x games  to be more difficult if you interpret  zoobles soaz has always everything like  comatose indigo cost  if you are on orne washington for  you to choose the best model way it  would be all for tonight the good die 5th  highly anticipated ",
            "userFeedbackScore": 0.24,
            "videoid": "MC97BZqdq0w",
            "viewCount": "5926"
        },
        "MNvT5JekDpg": {
            "NumOfComments": 33,
            "caption_exist": "T",
            "channel_id": "UCJS9pqu9BzkAMNTmzNMNhvg",
            "channel_title": "Google Cloud Platform",
            "comment_sentiment": 0.41691738816738816,
            "concepts": [
                [
                    "yeah",
                    33
                ],
                [
                    "data",
                    22
                ],
                [
                    "language",
                    21
                ],
                [
                    "natural",
                    20
                ],
                [
                    "model",
                    15
                ],
                [
                    "research",
                    9
                ],
                [
                    "natural language generation",
                    8
                ],
                [
                    "structured data",
                    8
                ],
                [
                    "neural network",
                    8
                ],
                [
                    "human",
                    7
                ],
                [
                    "rule",
                    7
                ],
                [
                    "computer",
                    7
                ],
                [
                    "weather",
                    7
                ],
                [
                    "cloudy",
                    6
                ],
                [
                    "recurrent neural network",
                    6
                ],
                [
                    "machine learning",
                    5
                ],
                [
                    "first",
                    5
                ],
                [
                    "degree",
                    5
                ],
                [
                    "machine",
                    5
                ],
                [
                    "nlp",
                    4
                ],
                [
                    "conversational",
                    4
                ],
                [
                    "link",
                    4
                ],
                [
                    "response",
                    4
                ],
                [
                    "information",
                    4
                ],
                [
                    "pretty",
                    3
                ],
                [
                    "recurrent neural net",
                    3
                ],
                [
                    "processing",
                    3
                ],
                [
                    "understand",
                    3
                ],
                [
                    "field",
                    3
                ],
                [
                    "general",
                    3
                ],
                [
                    "set",
                    3
                ],
                [
                    "column",
                    3
                ],
                [
                    "google",
                    3
                ],
                [
                    "diagonal line",
                    3
                ],
                [
                    "temperature",
                    2
                ],
                [
                    "natural language processing",
                    2
                ],
                [
                    "sound good",
                    2
                ],
                [
                    "generation side",
                    2
                ],
                [
                    "specific location",
                    2
                ],
                [
                    "future",
                    2
                ],
                [
                    "mean",
                    2
                ],
                [
                    "content",
                    2
                ],
                [
                    "location",
                    2
                ],
                [
                    "ai",
                    2
                ],
                [
                    "deep neural network",
                    2
                ],
                [
                    "conversational user interface",
                    2
                ],
                [
                    "cat",
                    2
                ],
                [
                    "architecture",
                    2
                ],
                [
                    "paying attention",
                    2
                ],
                [
                    "user question",
                    2
                ],
                [
                    "time step",
                    2
                ],
                [
                    "ai adventure",
                    2
                ],
                [
                    "sound",
                    2
                ],
                [
                    "approach",
                    1
                ],
                [
                    "overview",
                    1
                ],
                [
                    "graph",
                    1
                ],
                [
                    "algorithm",
                    1
                ],
                [
                    "lattice",
                    1
                ],
                [
                    "input/output",
                    1
                ],
                [
                    "shower",
                    1
                ],
                [
                    "range",
                    1
                ],
                [
                    "focus",
                    1
                ],
                [
                    "common",
                    1
                ],
                [
                    "based",
                    1
                ],
                [
                    "matter",
                    1
                ],
                [
                    "second",
                    1
                ],
                [
                    "form",
                    1
                ],
                [
                    "find",
                    1
                ],
                [
                    "engineering",
                    1
                ],
                [
                    "system",
                    1
                ],
                [
                    "policy",
                    1
                ],
                [
                    "conglomerate",
                    1
                ],
                [
                    "level",
                    1
                ],
                [
                    "visualization",
                    1
                ],
                [
                    "stable",
                    1
                ],
                [
                    "audio",
                    1
                ],
                [
                    "target",
                    1
                ],
                [
                    "solution",
                    1
                ],
                [
                    "called",
                    1
                ],
                [
                    "neuron",
                    1
                ],
                [
                    "order",
                    1
                ],
                [
                    "pretty cool",
                    1
                ],
                [
                    "computer system",
                    1
                ]
            ],
            "description": "In this episode of AI Adventures, Yufeng interviews Google Research engineer Justin Zhao to talk about natural text generation, recurrent neural networks, and state of the art research!\n\nRNNs in TensorFlow: https://goo.gl/ss5dEY\nCharacter-level language models: https://goo.gl/ffcq52\n\nWatch more episodes of AI Adventures: https://goo.gl/UC5usG\n\nSubscribe to get all the episodes as they come out: https://goo.gl/S0AS51",
            "dislikeCount": "16",
            "duration": "PT14M40S",
            "likeCount": "807",
            "published_time": "2017-10-19T20:42:18.000Z",
            "tags": [
                "Machine Learning",
                "TensorFlow",
                "Big Data",
                "Cloud",
                "Artificial intelligence",
                "AI",
                "ML",
                "machine learning with gcp",
                "gcp machine learning",
                "cloud and machine learning",
                "ai adventures",
                "training",
                "machine learning models",
                "natural language generation",
                "natural language processing",
                "research",
                "natural text generation",
                "product: machine learning",
                "fullname: Yufeng Guo",
                "Location: MTV",
                "Team: Scalable Advocacy",
                "Type: DevByte",
                "GDS: Full Production"
            ],
            "thumbnail": "https://i.ytimg.com/vi/MNvT5JekDpg/hqdefault.jpg",
            "title": "Natural Language Generation at Google Research (AI Adventures)",
            "transcript": "  welcome today on AI adventures we're joined in the studio by Justin Zhou a Google research engineer hey Justin all right thanks for joining in the studio today yeah it's great to be here we're gonna be talking today about natural language interfaces and how computers and humans can talk to each other in ways that are natural and not awkward yep sounds good awesome so I want to start by talking a little bit about your team's area of research and kind of the general natural language processing field and then we'll delve into your area of research and see where our conversation takes us yeah that sounds great so broadly speaking the area of my research is natural language processing or NLP and what that is NLP is all about trying to understand how humans communicate with each other and how to get a computer to kind of replicate that behavior so that we can interact with computers in a more natural manner wow you guys really picked a small field to target yeah I know if he sounds super broad yeah it's like everything yeah it's pretty broad um so in fact like I have some slides that we can pull yeah that'd be great yeah yeah so first I think it's important to talk about the conversational user interface and for something like the Google assistant there's two big domains of NLP problems that come into play on one side you have the problem of understanding which is what did the users say what was the user's intent and on the other side you have the problem of generation which was what should we say to the user and how do we respond in a way that's intelligent and conversational right so I work on the generation side and the ultimate goal of natural language generation is to teach computers to turn some kind of structured data into natural language which we can use to respond to the user in a conversation wonderful and this is definitely something that I feel like conventionally NLP has really been broadly thought about as a field where it's all about processing the words and understanding what text means but you are working on the generation side which in a lot of ways often gets overlooked and so it's really great that you're able to kind of tell us more about this side of things yeah mmm that's what I'm here for so how do you then teach a computer to generate natural language rather than just understand it right so for now let's set aside the structured data you know part of natural language generation and we can focus on the natural part of the natural language generation so what makes a conversation like the one we're having no human speaking of the one we're having it's a little meta that we're having a conversation about what makes something so that's a common remark on our team yeah we have to not be too robotic in our conversation yeah so I think this breaks down into two kinds of requirements first of all the content of what we have to say it has to make sense in the context of the conversation so is what I'm saying an appropriate response to what you're saying does or is it out of the blue hey what are you having for dinner so that's kind of out of the loop that's kind of out of the blue yeah definitely so yeah exactly and then I have to think about if what I'm gonna say is actually gonna answer your question so if you were gonna ask me where we want to go for dinner it would be weird to just to suggest like a coffee shop or a clothing store right yeah yeah unless you really wanted to get some coffee stains on your clothes for dinner yeah I guess the second requirement is that you accept to use the language correctly so this is like you know how's my grandma do my verbs agree or you know if I'm using a pronoun is it ambiguous that makes sense so it's basically what do you say and then how do you say it exactly okay yeah and you also mentioned earlier there's this structured data that we kind of put aside where does that come into play that's a great question so structured data primarily helps us figure out the first requirement which is what we want to say for example if let's say a user asked us about the weather next week in Santa Clara in Google search results we see a box filled with all this information about the weather for the next week okay and some are within this data hopefully answers the users question and we just have to figure out all this data into a response to the user that's kind of the problem that we're focusing on in natural language generation and that's because we're talking about a situation where we're going to say our answers not just show them the box to look at that's correct it's like an audio interface in that case I guess I can imagine a sort of naive solution for this sort of problem we already have the data right yeah so but I don't know if it would be sufficient well you know that's depends by all means go for it right so let's say we make some kind of a template right and we can say you know on blank day it'll be blank temperature and then some blank weather condition like on Tuesday it'll be 72 degrees and partly cloudy and then you could build a full forecast by just iterating through all the days of the week like that so I will say that that is a very straightforward approach and some assistants do use that implementation however in practice it's a lot less conversational than you might think so how about you try asking me what's the weather like this week and then I'll use your algorithm to generate a response all right sounds good we'll call this the Adjustment Assistance set perfect okay Justin what's the weather like next week hi you Fang Sunday it'll be 66 degrees and partly cloudy Monday it'll be 63 degrees and cloudy Tuesday it will be 66 degrees and partly cloudy Wednesday it'll be 68 degrees in cloudy oh boy okay yeah that's too long and just too robotic yeah let's let's call it let's call it that yeah you've been saying it for me you felt a little strange yeah so clearly generating natural language from structured data is non-trivial how would you actually go about using a computer system to answer the users question then well first you know I would want to think about how it answered as a human so you know as a human I would hope that I'd be a little more contextually aware and I would realize that there's actually a lot of repetitive information in the data so I'd probably try to summarize it something like it'll be cloudy until Thursday with showers the rest of the week temperatures range from the high 40s to the mid 60s hey you might want to consider a career as a weather forecaster if you know the research thing doesn't work out yeah maybe all right so we've done a little bit of an overview of natural language generation about what makes conversation natural and we even gave kind of a admittedly silly example of leveraging this structured data to select content for a natural language response yeah and we've also included some links with more info in the video that's right now we have all right so then getting back to the topic at hand how how does machine learning then get involved well that's the ultimate question that our team is trying to answer without machine learning everything that we've talked about so far from parsing the data to figure out what to say to actually figure out how to say it it had you have to do this with writing lots of rules and rules are great they're very stable they're very predictable but they're usually very specific and they require a lot of engineering and because of that it's not really scalable to new inputs and outputs for example if we wanted to talk about finance instead of weather or if we wanted to support an entire new language altogether sure it would require writing a whole new set of rules yeah and it sounds like that would be way harder to maintain as well keeping all those rules lined up as things change and it would also be hard to replicate that creativity and spontaneity that comes with human conversation right so that's exactly one of the motivations of our research our hope is that by giving the model examples of data and the language it needs to generate we can let the model form its own rules about what to do and not only does this save us from having to write these rules ourselves by hand but it also gives the computer more free rein to be creative in its own way so showing many examples to answer questions you might say so that you can write fewer rules I mean that's kind of the crux of machine learning as a whole that's wonderful exactly yeah and and so what kind of machine learning architectures then are you guys exploring to try to protect this problem well so far we've seen really promising results with recurrent neural networks but that's just one kind of neural architecture that we're exploring okay recurrent neural networks so on our previous episode we looked at deep neural networks on the show and that had neurons connected in layers resulting in something kind of lattice structure right and for our viewers can you explain what it means to have a recurrent neural network yeah so you can kind of think of a recurrent neural network as a deep neural network but just wrapped in a for loop and the network is recurrent because the outputs of the network feed back into itself and instead of this kind of one-shot you know input/output the model can kind of make decisions over several time steps okay awesome that's a really great way that I kind of conceptualize it really love that and we've also included some links about recurrent neural networks down below and if you have more questions about this kind of network structure feel free to leave them below in the comments and we'll try to get to them for now we'll talk about why recurrent neural networks will be useful for doing natural language generation right so it's important to keep in mind that language just in general is extremely sequential sure yeah for example the cat sat on the mat is a very different sentence from cats at than that on yeah order matters definitely so are nuns are especially good at remembering what it kind of saw earlier because it enforces a sequential policy over the data the inputs are decided in a very ordered manner and instead of in these kind of large conglomerates okay so I guess it's both amazing and not entirely surprising that recurrent neural Nets would be useful for natural language problems it sounds like so as humans we rely a lot on what we previously said to figure out what we'll say next exactly well let's talk a bit more than on how you're using these recurrent neural nets to generate this language so one kind of fun variation when it comes to recurrent neural nets is that since the output is generated one step at a time you can kind of choose the granularity of your output so some models can choose coarser outputs like entire word phrases just words in general and then this goes all the way down to models that outputs like bytes a single bytes at a time by the time and for us the we've been using outputs at the character level okay so be like spelling out the words really right okay and this kind of model is called ik is a character based RNN and you can find out more information in the links below so when we first talked about having you on the show you showed me this interesting graph here right I would love to understand a little better what is it showing us exactly so this is a small visualization of our recent research each row here represents different pieces of our structured data the shading of the squares indicates how much the model actually cares about that piece of structured data and lastly each column represents a single step in our model so as we travel across the columns you can see how the model has learned to pay attention to the structure data at different time steps okay so we're kind of traveling left to right character by character for each column and so the lit portions the lighter parts are parts that the model is paying attention to right exactly okay and then on this model over here for example it means the model is paying attention to this bit to decide what character it out but it's not saying that that's the character we'll say it'll just that's just the data it's looking at right exactly so it's gonna look at that particular piece of data to try to think about what - what character town exactly and then one really cool result is this diagonal line in headed oh about that it's kind of formulaic and it almost looks like you guys added that in afterwards - yeah it'd make it make for something interesting it's like hard coded yeah so those particular pieces of data are basically the characters for a specific location and what that diagonal line is showing us is that when the model has reached the part of the sentence where it wants to spell out the specific location is learn to read that from the data character by character wow that is that is awesome and no one taught the model to do that they were just able to learn how to do that just by looking at examples exactly that's the magic ncredible that's that's super outstanding yeah so um the diagonal line is pretty cool but if you dive into our data there's actually a lot of other intriguing ways that the model kind of learns by itself how to reference the data to decide what character to output so you know that said there's still a ton to explore but I'm super excited to see what you know where we come up with in the future and how far we can push our research this looks super cool Justin and I am really excited to hear about what your team comes up with next maybe maybe you'll write a research paper using one of these networks interview yeah that sounds pretty fun yeah Justin I want to thank you so much for coming into the studio today and teaching our viewers about natural language generation looking forward to catching up again in a minute I'm gonna wrap up here yeah okay sounds good it was my pleasure all right well I hope you enjoyed this episode of AI adventures I certainly did in our conversation we talked about using machine learning for natural language generation and its role in conversational user interfaces I had a blast chatting with Justin and if you like this format please let us know in the comments below and for more information and details about everything that we talked about we've included tons of links in the description and be sure to subscribe to the channel to catch future episodes and maybe some more interviews as they come out",
            "userFeedbackScore": 0.5801775301618861,
            "videoid": "MNvT5JekDpg",
            "viewCount": "39795"
        },
        "NT40U8zU1bg": {
            "NumOfComments": 1,
            "caption_exist": "T",
            "channel_id": "UC5zx8Owijmv-bbhAK6Z9apg",
            "channel_title": "Artificial Intelligence - All in One",
            "comment_sentiment": 1.0,
            "concepts": [
                [
                    "computer",
                    9
                ],
                [
                    "understand",
                    8
                ],
                [
                    "challenge",
                    7
                ],
                [
                    "language",
                    5
                ],
                [
                    "virus",
                    5
                ],
                [
                    "first",
                    4
                ],
                [
                    "book",
                    4
                ],
                [
                    "natural language processing",
                    3
                ],
                [
                    "brazil",
                    3
                ],
                [
                    "processing",
                    3
                ],
                [
                    "name",
                    3
                ],
                [
                    "president",
                    3
                ],
                [
                    "second",
                    3
                ],
                [
                    "type",
                    3
                ],
                [
                    "natural",
                    3
                ],
                [
                    "medical record",
                    3
                ],
                [
                    "short sentence",
                    2
                ],
                [
                    "background event",
                    2
                ],
                [
                    "constraint",
                    2
                ],
                [
                    "human",
                    2
                ],
                [
                    "system",
                    2
                ],
                [
                    "previous sentence",
                    2
                ],
                [
                    "named entity",
                    2
                ],
                [
                    "cell",
                    2
                ],
                [
                    "information",
                    2
                ],
                [
                    "current event",
                    1
                ],
                [
                    "digital",
                    1
                ],
                [
                    "future",
                    1
                ],
                [
                    "gravity",
                    1
                ],
                [
                    "order",
                    1
                ],
                [
                    "green",
                    1
                ],
                [
                    "common",
                    1
                ],
                [
                    "mouse",
                    1
                ],
                [
                    "content",
                    1
                ],
                [
                    "english language",
                    1
                ],
                [
                    "weather",
                    1
                ],
                [
                    "mass",
                    1
                ],
                [
                    "process",
                    1
                ],
                [
                    "wood",
                    1
                ],
                [
                    "research",
                    1
                ],
                [
                    "transcription",
                    1
                ],
                [
                    "course",
                    1
                ],
                [
                    "english",
                    1
                ],
                [
                    "bracket",
                    1
                ],
                [
                    "digital library",
                    1
                ],
                [
                    "protein",
                    1
                ],
                [
                    "specie",
                    1
                ]
            ],
            "description": ".\nCopyright Disclaimer Under Section 107 of the Copyright Act 1976, allowance is made for \"FAIR USE\" for purposes such as criticism, comment, news reporting, teaching, scholarship, and research. Fair use is a use permitted by copyright statute that might otherwise be infringing. Non-profit, educational or personal use tips the balance in favor of fair use.\n.",
            "dislikeCount": "0",
            "duration": "PT7M52S",
            "likeCount": "36",
            "published_time": "2016-03-25T02:44:07.000Z",
            "tags": [
                "Text Examples",
                "Natural Language Processing",
                "Language Processing",
                "University of Michigan",
                "Michigan",
                "NLP",
                "Coursera",
                "Dragomir R. Radev",
                "Computational Linguistics",
                "Linguistics",
                "Information Retrieval",
                "Computer Science",
                "Video Lecture",
                "Video Tutorial",
                "Video Course",
                "Course",
                "Data Science"
            ],
            "thumbnail": "https://i.ytimg.com/vi/NT40U8zU1bg/hqdefault.jpg",
            "title": "Lecture 2 \u2014 Examples of Text - Natural Language Processing | University of Michigan",
            "transcript": "  in the next course segment we're going to discuss why our natural language processing has challenges that come from text specifically we're going to look at an example of a news story that talks about an event that happened recently in Brazil the story is about a candidate for president who died in a plane crash we want to build a system that would understand the story and be able to answer questions about for example what happened and where and so on I'm going to now highlight a few of the pieces of the document for example the word they the phrase is expected and then an entire sentence and a few more phrases I have a specific reason to highlight those can you figure out why I highlighted them and why each of them presents a different sort of challenge to the computer oh the answer will be on the next slide the first sentence is Brazil crowds attend funeral of late candidate campus the reason why I chose the sentence is because it tells us the main event of the story so computers have to be able to understand entire sentences and figure out how they relate to what happened the second sentence is mr. compasses jet crashed in bad weather and Santos so this is a background event the current event is the funeral and the background event in with the context of which the funeral happens is that the jet crashed and the search sentence is also very interesting it says mr. campuses socialist party is expected to a point so this is not an event this is a speculation about what may happen in the future president Dilma Rouseff well this sentence gives you a property of a person it tells you that Dilma Rousseff is the president of Brazil and they attended the funeral mass here the wood they only makes sense in the context of the previous sentences in this particular case what's important is that the word they again first to their hundreds of thousands of people who attended the funeral so this is known in natural language processing as a poor nominal reference to an entity in a previous sentence there are many different genres of text in each of them presents different challenges Computers let's see what are the most common kinds of texts that computers are likely to encounter well there include the most obvious genres of text such as blogs and emails press releases chats on the internet debates and so on so on the left-hand side here I have a small snapshot you're not expected to read it you can go to the website create debate and see what that side is all about I'm just going to describe it here really quickly anybody can go to this website and post a controversial topic for example he's Manchester United the best football team ever or in this particular example do you think that schools should provide more tests for developmentally challenged people and you can decide whether you're on the yes side or the no side and then everybody can participate in this discussion and enter arguments on both sides so this kind of text presents interesting challenges because we want to understand what each person's opinion is whether they're on the yes side or the north side the second example here is from Wikipedia it includes an entry about a specific politician Tony Blair and it can be used to understand the basic events and facts about his biography now let's look at the more challenging piece of text this is a scientific paper its title itself already tells you how difficult this topic can be induction of influenza specifically cause of immunity by an attenuated recombinant sendai virus I've extracted some of the text from this sentence from this document sorry and I want to show you some of the specific challenges to computers so the first thing is this phrase here sentai virus this is a named entity it's specifically a virus and it has to be recognized by the system as such there are other examples of named entities for example human parainfluenza virus type 1 or HP IV 1 then sendai virus is mentioned a few more times luciferase green fluorescent protein or GFP those are all there are also examples of speculation for example reported and suggesting which are in purple we have instances of species for example the word human mice ferrets we have cell types for example nasal epithelial cells we have also facts and we have references the things in the square brackets are references to other papers so a computer would need to understand the purpose of each of those words and phrases and references in order to understand the content of the document so another interesting type of documents that can be challenging to computers are medical records medical records have two interesting properties first of all they are often the result of transcriptions and they don't contain grammatical sentences and the second polar with medical records is that when they use for research purposes they have to be anonymized so for example in this medical record here the name of the person has been changed to something that is not personally identifiable information a more interesting challenge comes from literary texts or fiction texts those can be very difficult for computers to process I'm going to show you some examples from Project Gutenberg which is an online digital library that contains old books just some examples from classic books like Ulysses you can see that there are some proper names that are difficult to understand if you don't know the context of story there's some rare words such as Waggoner here and so on that example is from Jane Eyre here you have again sure gratitude with short sentences but then we also have sentences in parentheses which indicate some additional information and another example from The Wizard of Oz which is a little bit longer but luckily for a computer program it has relatively short sentences that are easy to understand now on the other end of the spectrum we have some really long literary sentences for example try to parse this sentence and this is just one Center that occupies the entire screen it talks about again obscure names of people it uses some words that are not even words in the English language can you guess where this text is fun well on the previous slide I showed you an excerpt of gravity's rainbow this is a book that is known for its use of very keen words and complicated sentences and also a fairly complicated plot structure another such work that you may have heard about is Finnegan's Wake by James Joyce which is probably one of the most difficult books to read and translating or understanding poetry can be even more difficult because in addition to the constraints that I'm posed by language you also have constraints that I imposed by the metric structure I'm and the structure of the individual lines so the next item we're going to talk about some funny sentences that present specific challenges to natural language processing systems",
            "userFeedbackScore": 1.0,
            "videoid": "NT40U8zU1bg",
            "viewCount": "10770"
        },
        "Sx3Fpw0XCXk": {
            "NumOfComments": 73,
            "caption_exist": "T",
            "channel_id": "UCK8sQmJBp8GCxrOtXWBpyEA",
            "channel_title": "Google",
            "comment_sentiment": 0.19977875213320426,
            "concepts": [
                [
                    "language",
                    9
                ],
                [
                    "meet",
                    8
                ],
                [
                    "model",
                    6
                ],
                [
                    "google",
                    5
                ],
                [
                    "system",
                    5
                ],
                [
                    "google wave",
                    3
                ],
                [
                    "web",
                    3
                ],
                [
                    "language model",
                    3
                ],
                [
                    "set",
                    2
                ],
                [
                    "natural",
                    2
                ],
                [
                    "machine",
                    2
                ],
                [
                    "dictionary",
                    1
                ],
                [
                    "natural language processing",
                    1
                ],
                [
                    "pretty",
                    1
                ],
                [
                    "technology",
                    1
                ],
                [
                    "sydney",
                    1
                ],
                [
                    "likelihood",
                    1
                ],
                [
                    "list",
                    1
                ],
                [
                    "structured data",
                    1
                ],
                [
                    "error",
                    1
                ],
                [
                    "application",
                    1
                ],
                [
                    "quality",
                    1
                ],
                [
                    "mean",
                    1
                ],
                [
                    "called",
                    1
                ],
                [
                    "processing",
                    1
                ],
                [
                    "information",
                    1
                ],
                [
                    "data",
                    1
                ]
            ],
            "description": "Casey Whitelaw describes the natural language processing behind Google Wave's spelling correction on the deck of the Sydney office. Birds and boat horns for effect.",
            "dislikeCount": "44",
            "duration": "PT5M5S",
            "likeCount": "357",
            "published_time": "2009-05-28T09:27:15.000Z",
            "tags": [
                "google wave",
                "natural language",
                "sydney",
                "engineering"
            ],
            "thumbnail": "https://i.ytimg.com/vi/Sx3Fpw0XCXk/hqdefault.jpg",
            "title": "Google Wave: Natural Language Processing",
            "transcript": "  hi my name is Casey white log I'm the tech lead for the natural language processing group here in Sydney and today I'm going to talk to you a little bit about some of the cool things they were added to Google Wave so one of the main things that we want to stay focused on you Google Wave is productivity that we want users to be able to stay productive whether they're reading or whether they're writing one of the ways that we've done that is with our spell correction system what we'd like is for users just to be able to focus on what they're typing and not worry about whether there's any mistakes that made we think that if people could just loosen up a little bit and you know it maybe type 5% faster and that's 5% less time that they spend time so I'll start with an example it's probably the easiest way to explain let's say you know you're you want to meet up with one of your friends you're having a chat so you write let's meet oops tomorrow so here you see I've made a mistake they've written met instead of meet here at my finger slipped on the e so now the way that we implemented spelling is have we introduced an automatic participant called smelly who works just like a nother user that's participating on the wave with you so smelly is on your wave with you and it can see that you've typed let's meet tomorrow and it's now going to try and spell check it for each word it doesn't have any kind of dictionary so it's it doesn't know where the met is a well spelled word or a misspelling so to start with it comes up with a list of possible candidate corruptions for this word so some examples of that might be meat the food or meat the correctly spelled version of this and you can imagine lots of others so set or net or me all kinds of different worms that we would evaluate to see whether they're what you actually meant a time we have learned from the web the kind of misspellings that people make in which things are more and less likely so we know that for instance maybe slipping and inserting an A is relatively likely but misspelling the very first letter might be less likely in this case so we've got some suggestions and the next thing that we do is evaluate these suggestions in context so there are other systems at Google that already use the same phone of statistical language models as this such as the Google Translation system that essentially encode information about how languages use and these are learned from the web from looking at billions of web pages so we get a really good idea about the way that people really use language in preface so what we will do is look at the likelihood of let's meet tomorrow and let's meet tomorrow less likely and let's meet tomorrow which is going to be more likely than either of these and we combine that with our error model which tells us how likely the misspellings are you know without any context to get a final determination as to what other most likely words the most likely word that you meant right here and so in this case we would suggest meet once once we think that a word is misspelled we need to get that back to the Google Wave client so that you can actually see that the user can actually see it and either correct it automatically or manually two kinds of ways that this differs from existing spelling system is one of them is just that it's in its hosted and this means that we can do the same kind of spelling for you regardless of which device you're you're connecting from so whether you're on your laptop or your mobile or your desktop and we get the same quality spelling regardless and that applies across languages too so you know we're doing this for other alphabetic languages also so the we like I said we use large statistical language models when I said large we train them from billions of words they end up being many many gigabytes and it's pretty infeasible to run these on a single machine which isn't such a problem in a datacenter where you can have a set of machines running a language model and there was spelling model together and then we can share the we can share that scaling model between many users so that the cost per user is very low so it's very efficient for us to do this once you realize that you've got a system that supports collaborative editing that has structured data and that you can change the user interface by having remote participants then really the sky's the limit I mean there's all kinds of existing natural language technologies like spell checking or translation that we can apply and we're seeing a lot of new applications as the way that we communicate changes as well so you know really it's going to be exciting times",
            "userFeedbackScore": 0.37400971502192126,
            "videoid": "Sx3Fpw0XCXk",
            "viewCount": "134087"
        },
        "Y90BJzUcqlI": {
            "NumOfComments": 3,
            "caption_exist": "T",
            "channel_id": "UC2wMHF4HBkTMGLsvZAIWzRg",
            "channel_title": "J-Secur1ty",
            "comment_sentiment": 0.6166666666666667,
            "concepts": [
                [
                    "language",
                    11
                ],
                [
                    "specie",
                    10
                ],
                [
                    "space",
                    5
                ],
                [
                    "natural",
                    4
                ],
                [
                    "english",
                    4
                ],
                [
                    "nlp",
                    3
                ],
                [
                    "tokenize",
                    3
                ],
                [
                    "first",
                    3
                ],
                [
                    "function",
                    3
                ],
                [
                    "spacey",
                    3
                ],
                [
                    "understand",
                    3
                ],
                [
                    "python",
                    2
                ],
                [
                    "list",
                    2
                ],
                [
                    "stuff",
                    2
                ],
                [
                    "name",
                    2
                ],
                [
                    "called",
                    2
                ],
                [
                    "order",
                    2
                ],
                [
                    "download",
                    2
                ],
                [
                    "supply",
                    2
                ],
                [
                    "tool",
                    2
                ],
                [
                    "help",
                    2
                ],
                [
                    "technology",
                    2
                ],
                [
                    "blood",
                    2
                ],
                [
                    "fire",
                    2
                ],
                [
                    "yeah",
                    2
                ],
                [
                    "window",
                    2
                ],
                [
                    "model",
                    2
                ],
                [
                    "string",
                    1
                ],
                [
                    "similarity",
                    1
                ],
                [
                    "shape",
                    1
                ],
                [
                    "human",
                    1
                ],
                [
                    "top",
                    1
                ],
                [
                    "power",
                    1
                ],
                [
                    "series",
                    1
                ],
                [
                    "developer",
                    1
                ],
                [
                    "processing",
                    1
                ],
                [
                    "error",
                    1
                ],
                [
                    "mean",
                    1
                ],
                [
                    "form",
                    1
                ],
                [
                    "based",
                    1
                ],
                [
                    "pretty",
                    1
                ],
                [
                    "boundary",
                    1
                ],
                [
                    "data",
                    1
                ],
                [
                    "ai",
                    1
                ],
                [
                    "unicode",
                    1
                ],
                [
                    "web",
                    1
                ],
                [
                    "movie",
                    1
                ],
                [
                    "service",
                    1
                ],
                [
                    "watching",
                    1
                ],
                [
                    "capital",
                    1
                ],
                [
                    "modem",
                    1
                ],
                [
                    "speech",
                    1
                ],
                [
                    "natural language processing",
                    1
                ],
                [
                    "quick",
                    1
                ],
                [
                    "named entity",
                    1
                ],
                [
                    "find",
                    1
                ],
                [
                    "normal",
                    1
                ],
                [
                    "contribution",
                    1
                ]
            ],
            "description": "SpaCy Python Tutorial - Introduction,Word Tokens  and Sentence Tokens\nIn this tutorial we will learn how to do Natural Language Processing with SpaCy- An Advanced Industrial Strength NLP library.\nWe will discuss how to so word and sentence tokens as well as word shape.",
            "dislikeCount": "4",
            "duration": "PT12M45S",
            "likeCount": "33",
            "published_time": "2018-05-04T06:20:56.000Z",
            "tags": [
                "spaCy",
                "word tokens",
                "sentence tokens",
                "how to use spacy for tokenization",
                "nlp with spacy",
                "how to read files in spacy",
                "how to read text in spacy",
                "python",
                "spacy python tutorial",
                "word shapes in spacy",
                "NLP tutorial with SpaCy",
                "modern NLP with SpaCy",
                "python SpaCy tutorial",
                "Patrick Harrison | Modern NLP in Python",
                "Introduction to SpaCy",
                "Matthew Honnibal SpaCy",
                "SpaCy JCharisTech J-Secur1ty",
                "Natural Language Processing With SpaCy",
                "nlp in julia",
                "nlp in python",
                "nltk"
            ],
            "thumbnail": "https://i.ytimg.com/vi/Y90BJzUcqlI/hqdefault.jpg",
            "title": "SpaCy Python Tutorial - Introduction,Word Tokens  and Sentence Tokens(Natural Language Processing)",
            "transcript": "  hello and welcome back again my name is Jesse an ending to this tutorial on natural language processing be learning how to do natural language possess and awaits its PC so what is species the species is a very useful and advanced natural language library puts us in like B which is very useful just created by explosion AI and it is the lead developer so it's quite easy to learn and that's one of their most of us just that's right one of the fastest just like an LT key as well as test blow so let's see how to do it space to it to install it just go shoot away with the tip install specie then you download some some models right so we have English we have Frenchy of German so if you want just most of em these are the major ones imagine it's not every language but the major learn English French German and then some other languages so you want to install it on Windows you just go to kondeh install TQ DM it's very important but sometimes when you install it on Windows you will be having a lot of issues so you can just use condom to install it in any space or uninstall this ticking DM fist then you install quanta you install your specie hitter with this one or it is for price the interlude a library the modem English but you must download admitted a film splitter so let's start so first of all let's see how to do that so by the end of this tutorial in this series you'll be learning how to use Spacey for several of these functions such as tokenization part of speech dependency parsing the meta is a named entity recognition which is very interesting similarity sentence dependency boundary these are very useful feature that comes with species right so let's add a package but this one it's peaceful and slightly interested too so let's see how to do that so first of all let's load our party time Tony let's go is input specie right then good good NLP it's going to be Spacey total load yeah so this en is the language that we downloaded right they don't know the language by the model I told you en is for the English but if they are going to be working with French just glue it perfect so when you run this function there are a lot of you that is going with anything so what is going behind this e is trying to create an LP object so this is what is going behind you see yes I found for Twitter so what happens when you call space a load so when you do that this what would happen straightaway the pitch is service file entry then it's going to move through it and then build a load it in binary data right in it put Annunaki object which is quite interesting so it is really disrupted that you'd be working with all that you're going to be doing if it now let's see how to read a farm so how do you read a test document or power tool we have already imported it with this function in criticize just going to go with less call it us Docs right which we have faced far so good to be NLP then you could just apply what about this so Spacey is a cool too right so this is going to read it perfect before so if I go it talks this way to read what about side which is quite interested so this thing can be read in a different way even the Unicode format like this you bring you here right so let's call it species is an amazing to name like a no te ll TT it's quite nice so this is just going to and it's going to activate right so we can even read this file we're going to wait for us if it is wicked so now let's see how to read a natural fire if you have a fire on to me how do this crisis because I screech mind file then open the normal Python will open a file then we'll supply for example oh right as I probably will you quit it then don't read so when you go to pass it this one inside into species who was called dog bum channel pee then here I'm going to supply my farm to perfected what you read it perfectly for us so everything is wicked - if I read don't farm I call this it's going to print it profess it for us so their best error messages they want and advise yourself which is very nice quick to do it okay so this is how to read a comment farm right there's another symbol of it if I'm and file which can be this way so don't you doing this by this plane teeny like this you can do it in this simple right NLP let's collect doc Wow - and then I'm going to do it like an open right now go to pass in our open this file what you pass in distantly still going to I give you go to pass this one here perfect so you can also read it in this format it's going to make a fast start this weekend read it so doc so - let's work him perfectly nice okay that is how to read a fast I let's see how to detox what is top magazine suit tokenization media splitting and test inches to kids so anytime I just speak Oh anytime he mumbling speak we friends over to take the language that's a sticky so if I see Kotori Jasper I see Katella or bones you you just read it at a language then you split the language into two kings before you start to understand what that is greatly and that's how human beings understand language okay so we're trying to tokenize the ways that we are hearing don't organize the tests so we do we do incentives to kernelization and then wait totalization how do you do synthetic nitrogen this was our father to her drop farm what is the test that we had here but you want to tokenize them talking either in two sentences so we're going to use a petition to tokenize them into sentences let's see also to be doing do to be for sentence in car dog farm right this out of poetry heard here this farm then you paint this st. so perfect and unique of our sentence it's good to print our sentence for us perfectly right it's printing it individual visually sentence so this one can be can do it in a more politically by integrating it if you want to immunity to let's call it us a number then we're going to animate it so a new we read tell to see order the list of the the numbers of the same tense day right so this is a more pertinent way this works in Python 3.5 enough was sweet phyto-drip word for me or for three verses so now then this right is way to actively perfect that is a task emitted Bethesda's reduce eternity at once it is to is dividing them oscillated them into sentence based on the punctuation it's very very interesting very suggestive okay now let's see how to do web technology with specie so to you that when technology is just placing them into words right so our first file was this dog pound space it on a meeting tools I want to split it into what I wish it would kind of do it forward go to key-in dog blood test right to photo Killian dogs I'm just going to go hit print cooking blood test so to put it individual so this is individual talking so we can make it in a list form so this is how I do mine is a stuff from the back taking the test little anything with then I'll bring the stuff in the back in our movie so the copy that's one else are to do editing on this cute way it always works yes FSU's despot a little extra so this is a way to key perfect so this is similar to this split in that we did with the tokenization similar to doing something like this pie dough so doc test don't split then this right to splitting in this finished piece but the specie Moodle is very very intelligent in this aspect that it's going to be able to see pretty to go over to us and let's do some slick to turn about the way that they are done can also do more about like weight like under the ship for the weight as well as whether they were it's an alpha awesome you stop - let's try an example like that with our Canadian fur right species and I mean into - if I want to check for the word ship is this going to move it oh wait in dock right then I'm going to go to like this so that's called print weight dot test that's for the test then wait don't so there's one thing about this that like when I do it like this it's going to print it for us giving us the right but this number is a number that we don't understand - just one - numbers is that it's if you bring this tip this body I don't know how to decode it but this bar it's good not only with it nobody read it and have a good to give you the actual string the presentation of that way right so that if I do it like that that is given at the spring ability she which is half the town that'd be the purpose of the ship moving by the ship of the way but sometimes some of the worst maybe they seem like hello hello hello and then this you may want to normalize them most mostly we normalize them but you can use space to your table help you to note the shift the weight so specie start with the capita cut the s then it's happy to see here right if it is professor let's try this simple example with this theme shipped up on something should I change time to all so let's let me quit another far so let's call it example dog then I'm going to call it as an LP mu T passing some ways to hello right in half hello now hello then you help you write these are different ways so if I want to find the shape of these ways all of them are hello it is the same but I want to analyze it also is going to be through forward in yes print and I'm going to call that the word don't you bring the weight so it is going to be the word I want to print to the word so order to kiss all right let's call it the to chemo so and then the token itself is going to be talking it's all is going to be the where the test and I'm going to add the ship to she so it is going to be come on wait got ship that's cool right or they buy that at my school I think yeah I think it's a nice girl so that this original purpose - hello ship the ship here their weight hello kappa kappa kappa small small or capital so they are not taken to Deaconess word but I sang alphabetical not with wait wait what is ha ha how you would give us true or false right so true this turn up a bit and I up animate true true true true and then you can also do it for if it is you can also do it for if it's a a stop point so wait note is stopped so false false false hodiza and oh stop with ok so thank you for watching this tutorial if you have any questions or contribution okay I just made let me know can put aside the comment session and please don't forget to subscribe",
            "userFeedbackScore": 0.6668018018018018,
            "videoid": "Y90BJzUcqlI",
            "viewCount": "4593"
        },
        "_RY1QUXjV10": {
            "NumOfComments": 1,
            "caption_exist": "T",
            "channel_id": "UCJUmE61LxhbhudzUugHL2wQ",
            "channel_title": "codedamn",
            "comment_sentiment": 0.8,
            "concepts": [
                [
                    "nlp",
                    3
                ],
                [
                    "language",
                    3
                ],
                [
                    "series",
                    3
                ],
                [
                    "response",
                    3
                ],
                [
                    "based",
                    3
                ],
                [
                    "natural language processing",
                    3
                ],
                [
                    "processing",
                    3
                ],
                [
                    "natural",
                    3
                ],
                [
                    "data",
                    3
                ],
                [
                    "ai",
                    3
                ],
                [
                    "pretty",
                    2
                ],
                [
                    "wit dot ai",
                    2
                ],
                [
                    "web",
                    1
                ],
                [
                    "service",
                    1
                ],
                [
                    "second",
                    1
                ],
                [
                    "algorithm",
                    1
                ],
                [
                    "watching",
                    1
                ],
                [
                    "power",
                    1
                ],
                [
                    "chatbots",
                    1
                ],
                [
                    "stuff",
                    1
                ],
                [
                    "string",
                    1
                ],
                [
                    "email id",
                    1
                ],
                [
                    "regular expression",
                    1
                ],
                [
                    "quick",
                    1
                ],
                [
                    "yeah",
                    1
                ],
                [
                    "artificial intelligence",
                    1
                ],
                [
                    "model",
                    1
                ]
            ],
            "description": "Learn how to create smart and sophisticated chatbots using natural language processing by wit.ai and create powerful messenger chatbots\n\nAll tutorials: https://www.youtube.com/watch?v=_RY1QUXjV10&list=PLYxzS__5yYQkptDjLxQVqvM1312YO32fq",
            "dislikeCount": "4",
            "duration": "PT2M55S",
            "likeCount": "29",
            "published_time": "2017-12-13T23:06:56.000Z",
            "tags": [
                "chatbot",
                "chatbots",
                "nlp",
                "natural language processing"
            ],
            "thumbnail": "https://i.ytimg.com/vi/_RY1QUXjV10/hqdefault.jpg",
            "title": "#1: Introduction - Chatbots with Natural Language Processing",
            "transcript": "  so what is going on YouTube my name is May ho and welcome to your I guess first tutorial for natural language processing chatbots and if you have fallen along my last series of creating messenger chat BOTS what we did and that series was pretty boring we just created a script file and noches API endpoint which just listens for Facebook calling your chat board and just returns responses based on some hard-coded strings or maybe our regular expressions which kind of mimics a child word brain but not really so to actually create powerful chat BOTS what we need is to harness the power of artificial intelligence and that is in this expect the natural language processing or NLP as people say so we're gonna not start off NLP from the very basics because it's quite complicated field its mathematical and you've gotta learn all those sort of algorithms and all that stuff so what we're gonna make use of is something known as you can call NLP out of service why not because this is essentially the same thing so wit dot AI was acquired by Facebook in 2015 and these guys what they do is that they sit in the middle not really in the middle this hit the back right and you can send whatever you get from Facebook to these guys and essentially that's not even the case because with Facebook you can seamlessly integrate with your there so let's say if you're developing a chat bot for some company X right not for messenger so what would you do is that you get the text from the company X you send that text to wit dot AI with that AI based on the model you have trained with your data would return you the Chaisson of you know everything's formatted like what these were asking about what the users talking and all the things separated like phone number email ID everything based on your data but processed by wits engine right so you can use that easily in your response you can parse the data send appropriate response to the user and accordingly when the internet so yeah so essentially in this quick web series we're going to take a look at is how to build smart chat BOTS with a natural language processing and that is that pretty much and if you liked it then don't forget subscribe and thank you for watching I'll see you then in the second tutorial",
            "userFeedbackScore": 0.7872727272727272,
            "videoid": "_RY1QUXjV10",
            "viewCount": "6174"
        },
        "d4gGtcobq8M": {
            "NumOfComments": 2,
            "caption_exist": "T",
            "channel_id": "UC6bkDYWHnlS-iY1u3CFoOmA",
            "channel_title": "SparkCognition",
            "comment_sentiment": 0.4791666666666667,
            "concepts": [
                [
                    "data",
                    8
                ],
                [
                    "nlp",
                    4
                ],
                [
                    "language",
                    3
                ],
                [
                    "natural",
                    3
                ],
                [
                    "computer",
                    3
                ],
                [
                    "repair",
                    3
                ],
                [
                    "injury report",
                    3
                ],
                [
                    "spark cognition",
                    3
                ],
                [
                    "deep nlp",
                    2
                ],
                [
                    "processing",
                    2
                ],
                [
                    "called",
                    2
                ],
                [
                    "unstructured data",
                    2
                ],
                [
                    "natural language processing",
                    2
                ],
                [
                    "understand",
                    1
                ],
                [
                    "challenge",
                    1
                ],
                [
                    "information",
                    1
                ],
                [
                    "human",
                    1
                ],
                [
                    "matrix",
                    1
                ],
                [
                    "ai",
                    1
                ],
                [
                    "stuff",
                    1
                ],
                [
                    "technology",
                    1
                ]
            ],
            "description": "Not sure what natural language processing is and how it applies to you? In this video, we lay out the basics of natural language processing so you can better understand what it is, how it works, and how it's being used in the real world today. \n\nTo learn more on how SparkCognition is taking artificial intelligence into the real world, check out our DeepNLP solution: http://bit.ly/2JA74Cq",
            "dislikeCount": "0",
            "duration": "PT4M11S",
            "likeCount": "55",
            "published_time": "2018-06-06T17:52:48.000Z",
            "tags": [
                "natural language processing",
                "NLP",
                "learningnlp",
                "datascience",
                "deeplearning",
                "AI",
                "artificialintelligence",
                "bigdata",
                "naturallanguage",
                "processing",
                "usingnlp",
                "technology"
            ],
            "thumbnail": "https://i.ytimg.com/vi/d4gGtcobq8M/hqdefault.jpg",
            "title": "The Basics of Natural Language Processing",
            "transcript": "  energy companies want to improve operations and keep their employees safe but it is never easy Machinery breaks and someone has to go fix it picture yourself 200 feet in the air on an icy oil rig these repairs are not only expensive but also dangerous now companies know that by better analyzing their data they can improve their operations thereby saving money and keeping their employees safer but there's a challenge only 20% of the data needed for this analysis is in a structured format like spreadsheets or databases that's data that computers usually use the other 80% of it is in the form of text like repair manuals injury reports and notes shouted down by technicians this information is extremely valuable but due to its size and structure it has largely been invisible to analytics teams imagine you're searching a database of injury reports you want to find lower body injuries what do you search analysis from one large utility company showed that lower body injuries returned only a small number of results far fewer than existed in reality that's because their search tool was looking for the exact keywords lower body injuries but when the analysts use more specific search terms like foot injuries that returned many more results where foot was used in the context of distance so while they had more results than searching for just lower body injuries they weren't the results they wanted this was because a foot can be both a body part and a unit of measurement and while humans can determine context and know the difference until recently computers were largely stumped thanks to this field of AI called natural language processing computers can now analyze and understand textual data in case you're curious here's how natural language processing works at a high level NLP algorithms can't read text like we do but they can look for patterns and they find these patterns by turning huge amounts of text into matrices when analyzing text the algorithm might first remove words that don't really offer as much value stuff like a the is an R these are called stop words then the out of the might split the sentences into groups of words and count how many times each group of words appears in each document and how many documents have that group of words out of all the documents being analyzed without knowing anything at all about the text the algorithm can then tell how often a given word or phrase appears in a given document and how many documents contain that phrase out of all of the documents so tokens that appears lots of times in lots of documents may not mean much but tokens that appear frequently in only a few documents tell us that something's going on for example if we fed easier reports across all of our oil wells into this basic algorithm and we see that falling debris entries are clustered around reports from rigs in the Gulf of Mexico we might then know about a new piece of machinery or process or environmental condition or something else that is causing injuries before management hears about it now this is just a basic example when combining vast amounts of data and advanced NLP algorithms develop its spark-ignition our customers are seeing tremendous improvements in operational efficiency and safety wind turbine operators are finding answers that previous solutions missed spark Commission finds the meaning in the data and makes that available oil and gas operators are able to ask natural language questions when performing Diagnostics before repairs so with advanced technology like deep NLP from spark cognition you can now unlock the value of your unstructured data every email every maintenance log in every injury report become actual insights that can drive revenue and reduce costs and it's not just the energy industry that can harness the power of deep NLP if you want to learn more about how spark cognition can help you generate value from your unstructured data please keep reading at spark cognition calm",
            "userFeedbackScore": 0.6354166666666666,
            "videoid": "d4gGtcobq8M",
            "viewCount": "4637"
        },
        "fOvTtapxa9c": {
            "NumOfComments": 100,
            "caption_exist": "T",
            "channel_id": "UCX6b17PVsYBQ0ip5gyeme-Q",
            "channel_title": "CrashCourse",
            "comment_sentiment": 0.20665678532116025,
            "concepts": [
                [
                    "computer",
                    22
                ],
                [
                    "language",
                    21
                ],
                [
                    "speech",
                    16
                ],
                [
                    "sound",
                    14
                ],
                [
                    "noun",
                    10
                ],
                [
                    "human",
                    10
                ],
                [
                    "rule",
                    8
                ],
                [
                    "natural",
                    7
                ],
                [
                    "data",
                    7
                ],
                [
                    "called",
                    7
                ],
                [
                    "speech recognition",
                    6
                ],
                [
                    "system",
                    6
                ],
                [
                    "voice",
                    5
                ],
                [
                    "information",
                    5
                ],
                [
                    "phoneme",
                    4
                ],
                [
                    "understand",
                    4
                ],
                [
                    "set",
                    3
                ],
                [
                    "technology",
                    3
                ],
                [
                    "computer science",
                    3
                ],
                [
                    "course",
                    3
                ],
                [
                    "english",
                    3
                ],
                [
                    "pretty",
                    2
                ],
                [
                    "dictionary",
                    2
                ],
                [
                    "nlp",
                    2
                ],
                [
                    "language model",
                    2
                ],
                [
                    "chatbots",
                    2
                ],
                [
                    "google",
                    2
                ],
                [
                    "human language",
                    2
                ],
                [
                    "processing",
                    2
                ],
                [
                    "crash course",
                    2
                ],
                [
                    "vocabulary",
                    2
                ],
                [
                    "speech recognition system",
                    2
                ],
                [
                    "research",
                    2
                ],
                [
                    "siri",
                    2
                ],
                [
                    "phrase structure rule",
                    2
                ],
                [
                    "give computer",
                    2
                ],
                [
                    "speech synthesis",
                    2
                ],
                [
                    "chatbot",
                    2
                ],
                [
                    "crash course computer science",
                    2
                ],
                [
                    "vertical axis",
                    2
                ],
                [
                    "machine learning",
                    2
                ],
                [
                    "parse tree",
                    1
                ],
                [
                    "based",
                    1
                ],
                [
                    "approach",
                    1
                ],
                [
                    "alexa",
                    1
                ],
                [
                    "deep neural network",
                    1
                ],
                [
                    "separate",
                    1
                ],
                [
                    "meet",
                    1
                ],
                [
                    "programming",
                    1
                ],
                [
                    "voice user interface",
                    1
                ],
                [
                    "application",
                    1
                ],
                [
                    "knowledge graph",
                    1
                ],
                [
                    "natural language processing",
                    1
                ],
                [
                    "computing",
                    1
                ],
                [
                    "linguistics",
                    1
                ]
            ],
            "description": "Today we\u2019re going to talk about how computers understand speech and speak themselves. As computers play an increasing role in our daily lives there has been an growing demand for voice user interfaces, but speech is also terribly complicated. Vocabularies are diverse, sentence structures can often dictate the meaning of certain words, and computers also have to deal with accents, mispronunciations, and many common linguistic faux pas. The field of Natural Language Processing, or NLP, attempts to solve these problems, with a number of techniques we\u2019ll discuss today. And even though our virtual assistants like Siri, Alexa, Google Home, Bixby, and Cortana have come a long way from the first speech processing and synthesis models, there is still much room for improvement. \n\nProduced in collaboration with PBS Digital Studios: http://youtube.com/pbsdigitalstudios \n\nWant to know more about Carrie Anne?\nhttps://about.me/carrieannephilbin\n\nThe Latest from PBS Digital Studios: https://www.youtube.com/playlist?list=PL1mtdjDVOoOqJzeaJAV15Tq0tZ1vKj7ZV\n\nWant to find Crash Course elsewhere on the internet?\nFacebook - https://www.facebook.com/YouTubeCrash...\nTwitter - http://www.twitter.com/TheCrashCourse\nTumblr - http://thecrashcourse.tumblr.com \nSupport Crash Course on Patreon: http://patreon.com/crashcourse\nCC Kids: http://www.youtube.com/crashcoursekids",
            "dislikeCount": "59",
            "duration": "PT11M50S",
            "likeCount": "3707",
            "published_time": "2017-11-22T22:01:48.000Z",
            "tags": [
                "John Green",
                "Hank Green",
                "vlogbrothers",
                "Crash Course",
                "crashcourse",
                "education",
                "computing",
                "computers",
                "crash course computer science",
                "compsci",
                "computation",
                "natural language processing",
                "nlp",
                "speech synthesis",
                "speech",
                "parse tree",
                "parts-of-speech",
                "knowledge graph",
                "siri",
                "google home",
                "alexa",
                "bixby",
                "cortana",
                "speech recognition",
                "phonemes",
                "language model",
                "voice user interface"
            ],
            "thumbnail": "https://i.ytimg.com/vi/fOvTtapxa9c/hqdefault.jpg",
            "title": "Natural Language Processing: Crash Course Computer Science #36",
            "transcript": "  hi I'm Kerry Ann and welcome to crash course computer science last episode we talked about computer vision giving computers the ability to see and understand visual information today we're going to talk about how to give computers the ability to understand language you might argue they've always had this capability back in episodes 9 and 12 we talked about machine language instructions as well as higher level programming languages while they certainly meet the definition of a language they also tend to have small vocabularies and follow highly structured conventions code will only compile and run if it's a hundred percent free of spelling and syntactic errors of course this is quite different from human languages what are called natural languages containing large diverse vocabularies words with several different meanings speakers with different accents and all sorts of interesting wordplay people also make linguistic faux pars when writing and speaking like slurring words together leaving out key details so things are ambiguous and mispronouncing things but for the most part humans can roll right through these challenges the skillful use of language is a major part of what makes us human and for this reason the desire for computers to understand and speak our language has been around since they were first conceived this led to the creation of natural language processing or NLP and interdisciplinary field combining computer science and linguistics [Music] there's an essentially infinite number of ways to arrange words in a sentence we can't give computers a dictionary of all possible sentences to help them understand what humans are blabbing on about so an early and fundamental NLP problem was deconstructing sentences into bite-sized pieces which could be more easily processed in school you learned about nine fundamental types of English words nouns pronouns articles verbs adjectives adverbs prepositions conjunctions and interjections these are all called parts of speech there are all sorts of subcategories too like singular versus plural nouns and superlative versus comparative adverbs but we're not going to get into that knowing a words type is definitely useful but unfortunately there are a lot of words that have multiple meanings like rows and leaves which can be used as nouns or verbs a digital dictionary alone isn't enough to resolve this ambiguity so computers also need to know some grammar for this phrase structure rules were developed which encapsulate the grammar of a language for example in English there's a rule that says a sentence can be comprised of a noun phrase followed by a verb phrase noun phrases can be an article like thir followed by a noun or they can be an adjective followed by a noun and you can make rules like this for an entire language then using these rules is fairly easy to construct what's called a parse tree which not only tags every word with a likely part of speech but also reveals how the sentence is constructed we now know for example that the noun focus of this sentence is the mongols and we know it's about them doing the action of rising from something in this case leaves the smaller chunks of data allow computers to more easily access process and respond to information equivalent processes are happening every time you do a voice search like where's the nearest pizza the computer can recognize this is a where question knows that you want the noun pizza and the dimension you care about is nearest the same process applies to what is the biggest giraffe or who sang thriller by treating language almost like Lego computers can be quite adept at natural language tasks they can answer questions and also process commands like set an alarm for 2:20 or play t-swizzle and Spotify but as you've probably experienced they fell when you start getting too fancy and they can no longer parse the sentence correctly or capture your intent hey Siri methinks the mongols doth roam too much or thinkI on this most gentle Midsummer's day I should also know that phrase structure rules and similar methods that codify language can be used by computers to generate natural language text this works particularly well when data is stored in a web of semantic information where entities are linked to one another in meaningful relationships providing all the ingredients you need to craft informational sentences thriller was released in 1983 and sung by Michael Jackson Google's version of this is called knowledge graph at the end of 2016 it contained roughly seventy billion facts about and relationships between different entities these two processes parsing and generating text are fundamental components of natural language chatbots computer programs that chat with you early chatbots were primarily rule-based where experts would encode hundreds of rules mapping what a user might say to how a program should reply obviously this was unwieldy to maintain and limited the possible sophistication a famous early example was eliza created in the mid 1960s at MIT this was a chatbot that took on the role of a therapist and used basic syntactic rules to identify content in written exchanges which it would turn around and ask the user about sometimes it felt very much like human human communication but other times it would make simple and even comical mistakes chatbot some more advanced dialogue systems have come a long way in the last 50 years and can be quite convincing today modern approaches are based on machine learning where gigabytes of real human to human chats are used to train chat BOTS today the technology is finding use in customer service applications where there's already heaps of example conversations to learn from people have also been getting chat BOTS to talk with one another and in the Facebook experiment chat BOTS even started to involve their own language this experiment got a bunch of scary sounding press but it was just the computer's crafting a simplified protocol to negotiate with one another it wasn't evil it was efficient but what about if something has spoken how does a computer get words from the sound that's the domain of speech recognition which has been the focus of research for many decades Bell Labs debuted the first speech recognition system in 1952 nicknamed Audrey the automatic digit recognizer it could recognize all ten numerical digits if you set them slowly enough five nine seven the project didn't go anywhere because it was much faster to enter telephone numbers with a finger ten years later at the 1962 World's Fair IBM demonstrated a shoebox size machine capable of recognizing 16 words to boost research in the area DARPA kicked off an ambitious five-year funding initiative in 1971 which led to the development of harpy at Carnegie Mellon University HAARP he was the first system to recognize over a thousand words but on computers of the era transcription was often 10 or more times slower than the rate of natural speech fortunately thanks to huge advances in computing performance in the 80s and 90s continuous real-time speech recognition became practical there was simultaneous innovation in the algorithms for processing natural language moving from handcrafted rules to machine learning techniques that could learn automatically from existing data sets of human language today the speech recognition systems with the best accuracy are using deep neural networks which we touched on in episode 34 to get a sense of how these techniques work let's look at some speech specifically the acoustic signal let's start by looking at vowel sounds like R and E these are the waveforms of those two sounds as captured by a computer's microphone as we discussed in episode 21 on files and file formats this signal is the magnitude of displacement of a diaphragm inside of a microphone and sound waves caused it to oscillate in this view of sound data the horizontal access is time and the vertical axis is the magnitude of displacement or amplitude although we can see there are differences between the waveforms it's not super obvious what you would point to and say aha this is definitely an e sound to really make this pop out we need to view the data in a totally different way a spectrogram in this view of the data we still have time along the horizontal axes but now instead of amplitude on the vertical axis we plot the magnitude of the different frequencies that make up each sound the brighter the color the louder that frequency component this conversion from waveforms of frequencies is done with a very cool algorithm called a fast Fourier transform if you've ever stared at a stereo systems EQ visualiser it's pretty much the same thing a spectrogram is plotting that information over time you might have noticed that the signals have a sort of ribbed pattern to them that's all the resonances of my vocal tract to make different sounds I squeezed my vocal cords mouth and tongue two different shapes which amplifies or dampens different resonances we can see this in the signal with areas that are brighter and areas that are darker if we work our way up from the bottom labeling where we see peaks in the spectrum what are called formants we can see the two sounds have quite different arrangements and this is true for all vowels it's exactly this type of information the less computers recognize spoken valves and indeed whole words let's see a more complicated example like when I say she was happy we can see our I found here and our sound here we can also see a bunch of other distinctive sounds like the sounding she the once in was and so on these sound pieces that make up words are called phonemes speech recognition software knows what all these phonemes look like in English there are roughly 44 so it mostly boils down to fancy pattern matching then you have two separate words from one another figure out when sentences begin and end and ultimately you end up with speech converted into text allowing for techniques like we discussed at the beginning of the episode because people say words in slightly different ways due to things like accents and mispronunciations transcription accuracy is greatly improved when combined with a language model which contains statistics about sequences of words for example she was is most likely to be followed by an adjective like happy it's uncommon for she was to be followed immediately by a noun so if the speech recognizer was unsure between happy and happy it would pick happy since the language model would report that as a more likely choice finally we need to talk about speech synthesis that is giving computers the ability to output speech this is very much like speech recognition but in Reverse we can take a sentence of text and break it down into its phonetic components and then play those sounds back to back out of a computer speaker you can hear this changing of phonemes very clearly with older speech synthesis technologies like this 1937 hand operated machine from Bell Labs say she saw me with no expression now say it an answer to these questions who saw you did you buy the 1980s this has improved a lot but that discontinuous and awkward blending of phonemes still created that signature robotic sound thriller was released in 1983 and sewn by Michael Jackson today synthesized computer voices like Siri katana and Alexa have got a much better but they're still not quite human but we're so so close and it's likely to be a solved problem pretty soon especially because we're now seeing an explosion of voice user interfaces on our phones in our cars and homes and mainly soon plugs right into our is this ubiquity is creating a positive feedback loop where people are using voice interaction more often which in turn is giving companies like Google Amazon and Microsoft more data to train their systems on which is enabling better accuracy which is leading to people using voice more which is enabling even better accuracy and the loop continues many predict that speech technologies will become as common a form of interaction as screens keyboards trackpads and other physical input/output devices that we use today that's particularly good news for robots who don't want to have to walk around with keyboards in order to communicate with humans but we'll talk more about them next week see you then crash course computer science is produced in association with PBS Digital Studios at their channel you can check out a playlist of shows like Ian's physics girl and it's okay to be smart this episode was filmed at the chad and stacey emigholz studio in indianapolis and it was made with the help of all these nice people and our wonderful graphics team thought cafe thanks for the random access memories I'll see you next time",
            "userFeedbackScore": 0.43525985593830124,
            "videoid": "fOvTtapxa9c",
            "viewCount": "141670"
        },
        "n25JjoixM3I": {
            "NumOfComments": 2,
            "caption_exist": "T",
            "channel_id": "UC5zx8Owijmv-bbhAK6Z9apg",
            "channel_title": "Artificial Intelligence - All in One",
            "comment_sentiment": 0.1,
            "concepts": [
                [
                    "language",
                    35
                ],
                [
                    "natural",
                    19
                ],
                [
                    "processing",
                    15
                ],
                [
                    "natural language processing",
                    14
                ],
                [
                    "computer",
                    14
                ],
                [
                    "human",
                    9
                ],
                [
                    "first",
                    8
                ],
                [
                    "understand",
                    8
                ],
                [
                    "system",
                    7
                ],
                [
                    "course",
                    7
                ],
                [
                    "human language",
                    6
                ],
                [
                    "science",
                    5
                ],
                [
                    "field",
                    5
                ],
                [
                    "movie",
                    4
                ],
                [
                    "application",
                    4
                ],
                [
                    "linguistics",
                    4
                ],
                [
                    "level",
                    3
                ],
                [
                    "interaction",
                    3
                ],
                [
                    "class",
                    3
                ],
                [
                    "engine",
                    3
                ],
                [
                    "search engine",
                    3
                ],
                [
                    "statistic",
                    2
                ],
                [
                    "interpretation",
                    2
                ],
                [
                    "based",
                    2
                ],
                [
                    "mathematics",
                    2
                ],
                [
                    "theory",
                    2
                ],
                [
                    "translation",
                    2
                ],
                [
                    "mean",
                    2
                ],
                [
                    "method",
                    2
                ],
                [
                    "resource",
                    2
                ],
                [
                    "second",
                    2
                ],
                [
                    "technology",
                    2
                ],
                [
                    "coursera",
                    2
                ],
                [
                    "computer science",
                    2
                ],
                [
                    "computational",
                    2
                ],
                [
                    "google",
                    2
                ],
                [
                    "nlp",
                    1
                ],
                [
                    "theoretical computer science",
                    1
                ],
                [
                    "menu",
                    1
                ],
                [
                    "overview",
                    1
                ],
                [
                    "challenge",
                    1
                ],
                [
                    "common",
                    1
                ],
                [
                    "bay",
                    1
                ],
                [
                    "earthquake",
                    1
                ],
                [
                    "television",
                    1
                ],
                [
                    "name",
                    1
                ],
                [
                    "speech",
                    1
                ],
                [
                    "space",
                    1
                ],
                [
                    "machine",
                    1
                ],
                [
                    "pragmatic",
                    1
                ],
                [
                    "engineering",
                    1
                ],
                [
                    "statistical",
                    1
                ],
                [
                    "artificial intelligence",
                    1
                ],
                [
                    "machine translation",
                    1
                ],
                [
                    "psychology",
                    1
                ],
                [
                    "type",
                    1
                ],
                [
                    "knowledge",
                    1
                ],
                [
                    "natural language generation",
                    1
                ],
                [
                    "research",
                    1
                ],
                [
                    "ground",
                    1
                ],
                [
                    "treatment",
                    1
                ],
                [
                    "watson",
                    1
                ],
                [
                    "called",
                    1
                ],
                [
                    "software",
                    1
                ],
                [
                    "find",
                    1
                ],
                [
                    "animal",
                    1
                ],
                [
                    "theoretical",
                    1
                ],
                [
                    "communication",
                    1
                ],
                [
                    "siri",
                    1
                ]
            ],
            "description": ".\nCopyright Disclaimer Under Section 107 of the Copyright Act 1976, allowance is made for \"FAIR USE\" for purposes such as criticism, comment, news reporting, teaching, scholarship, and research. Fair use is a use permitted by copyright statute that might otherwise be infringing. Non-profit, educational or personal use tips the balance in favor of fair use.\n.",
            "dislikeCount": "2",
            "duration": "PT8M39S",
            "likeCount": "181",
            "published_time": "2016-03-25T02:29:54.000Z",
            "tags": [
                "Introduction - Natural Language Processing",
                "Natural Language Processing",
                "Language Processing",
                "University of Michigan",
                "Michigan",
                "NLP",
                "Coursera",
                "Dragomir R. Radev",
                "Computational Linguistics",
                "Linguistics",
                "Information Retrieval",
                "Computer Science",
                "Video Lecture",
                "Video Tutorial",
                "Video Course",
                "Course",
                "Data Science"
            ],
            "thumbnail": "https://i.ytimg.com/vi/n25JjoixM3I/hqdefault.jpg",
            "title": "Lecture 1 \u2014 Introduction - Natural Language Processing | University of Michigan",
            "transcript": "  welcome to the natural language processing class this is the introductory lecture my name is Drago Mira dev I have a PhD from Columbia University the course is going to be approximately 20 hours long ten weeks of two hours and the intended audience is primarily students in computer science in linguistics and informatics and some other fields such as mathematics statistics management and engineering there are other online courses available in natural language processing this course however is more introductory than the course that Michael Collins taught on Coursera in 2013 and it is more focused on linguistics and computational resources than the drafts kid Manning version on Coursera in 2012 so the first question that we want to ask ourselves is what is natural language processing why do we want to study it the definition of NLP or natural language processing is very simple it's the study of the computational treatment of natural language when people say natural language they usually mean human language doesn't mean for example the language of some animals in other words this course is about teaching computers how to understand but also how to generate human language let me start by asking you where this quote came from do you know this movie it was from the time when I was a kid you probably haven't seen this movie it has a person talking with a computer and the person says open the pod bay doors Hal and the computer says I'm sorry Dave I'm afraid I cannot do that oh here's the answer to the quiz this is a quote from 2001 a Space Odyssey it's a 1968 science fiction movie by Stanley Kubrick and it was written by him and arthur c clarke it's one of the first major science fiction movies that talks about computers that interact with humans using natural language nowadays however there are actual applications of natural language processing to the real world not just science fiction I'm going to show you some examples here the most obvious ones are search engines all the major search engines such as Google Yahoo Bing and some other search engines in other languages like by doing Chinese Oh use natural language processing technology to understand your queries and find the matching documents another application is question answering for example a few years ago IBM's Watson system famously played on television against the best human contestants in jeopardy and one there are nowadays natural language assistance such as Apple Siri and translation systems you're probably familiar with Google Translate there are other applications by other companies for example news digest from Yahoo there are applications to text generation for example the LA Times applies some computer software to generate reports about earthquakes automatically all those techniques use natural language processing and many person years have gone into building those systems now in the course of 20 hours we're going to try to figure out what sort of technologies and what sort of insights are necessary to build systems like this let me make some notes here first of all computers are not inherently designed to understand human language in fact they're very confused by human language some very specific techniques are needed that would teach computers how to use human language natural language processing is the field that teaches computers how to understand language and I want to word it that natural language processing is a very multidisciplinary field it draws on research in linguistics which is the study of language theoretical computer science mathematics statistics artificial intelligence and even fields like psychology and databases and user interfaces and whatnot so this class has multiple goals the first goal is to understand that language processing is hard you really cannot do a natural language processing if you don't have a very intuitive understanding of the faculties of human language not only do you need to know that language is difficult but you also need to understand why so this is the first theme of this class the second theme is to provide the students with an overview of the key problems in natural language processing for example machine translation and parsing the third topic is to learn about the methods used to address these problems those techniques could involve specific statistical techniques or specific language resources and finally and just as importantly we need to understand the limitations of these methods don't expect that the techniques that work for one type of text will work for another or the techniques that work for one language will carry over to other languages so let's start first with a little bit of background in linguistics and I want to warn you that this course is going to spend a lot of time on some of the linguistic intuition behind natural language processing so very often will you see slides that address specific linguistic issues as they relate to this field so in communication people have focused on the interaction between a speaker and a listener this theory applies not only to interactions between computers and humans but also of interactions between different people so what does the speaker do the speaker first has to have an intention of something that sure he wants to say that can include a certain goal it can include some shared knowledge and beliefs about the topic that they're going to discuss the next thing is once the goal has been formulated is to generate some representation of the sentence or the discourse that will be said and the third step is to actually synthesize and say produce the sentence that can be done in text or in speech depending on the system now on the listener side we have three steps again the first one is perception that's when the listener hears or sees the text that was uttered by the speaker the second step is the interpretation of what the speaker said and the interpretation can be done at the syntactic level which is the grammatical structure of the sentence the semantic level which is the meaning of the sentence or the pragmatics level which is the purpose of the sentence what did the speaker intend to communicate and the third step is their incorporation of what the speaker just said this is also known as internalization or understanding that's when the listener actually takes some action or learn something based on what the speaker just said and both the speaker and the listener have to have some common ground for example if you are in a restaurant you can point to a certain dish on the menu and say this or you can talk about a certain person and say he or she so this is all part of the shared context between the speaker and the listener and it is known in linguistic theory as part of grounding so basic natural language processing system has the following structure it has two components u stands for understanding that's the part that takes you from language to computer representation they often a natural language processing may only have an understanding component for example if you want to ask a question you may just want to the computer to perform an action based on it and not answer anything back to you in other cases you may have an entire dialogue system which includes both understanding in generation in that case the computer will hear you and then using a technique called natural language generation produce a sentence or perhaps a longer piece of text that would go back to you now in the next segment we're going to talk about some specific examples of text and understand why they present challenges to computers",
            "userFeedbackScore": 0.36344262295081964,
            "videoid": "n25JjoixM3I",
            "viewCount": "37527"
        },
        "uCUdlM8KnPk": {
            "NumOfComments": 12,
            "caption_exist": "T",
            "channel_id": "UCU_WIBiDdkd6LDUv_ZYXX-A",
            "channel_title": "Abu Tech",
            "comment_sentiment": 0.15416666666666667,
            "concepts": [
                [
                    "language",
                    13
                ],
                [
                    "natural",
                    10
                ],
                [
                    "natural language processing",
                    5
                ],
                [
                    "computer",
                    5
                ],
                [
                    "processing",
                    5
                ],
                [
                    "data",
                    5
                ],
                [
                    "delta",
                    3
                ],
                [
                    "python",
                    2
                ],
                [
                    "nlp",
                    2
                ],
                [
                    "polymer",
                    2
                ],
                [
                    "fungus",
                    2
                ],
                [
                    "mean",
                    2
                ],
                [
                    "download",
                    2
                ],
                [
                    "nlt",
                    2
                ],
                [
                    "understand",
                    2
                ],
                [
                    "english",
                    2
                ],
                [
                    "money",
                    2
                ],
                [
                    "power",
                    1
                ],
                [
                    "article",
                    1
                ],
                [
                    "based",
                    1
                ],
                [
                    "ordinary",
                    1
                ],
                [
                    "coil",
                    1
                ],
                [
                    "import",
                    1
                ],
                [
                    "first",
                    1
                ],
                [
                    "modern",
                    1
                ],
                [
                    "pretty",
                    1
                ],
                [
                    "monomer",
                    1
                ],
                [
                    "theory",
                    1
                ],
                [
                    "function",
                    1
                ],
                [
                    "quantum",
                    1
                ],
                [
                    "tool",
                    1
                ],
                [
                    "common",
                    1
                ],
                [
                    "consumer",
                    1
                ],
                [
                    "general",
                    1
                ],
                [
                    "response",
                    1
                ],
                [
                    "data set",
                    1
                ],
                [
                    "set",
                    1
                ],
                [
                    "process",
                    1
                ],
                [
                    "block",
                    1
                ],
                [
                    "introduction",
                    1
                ],
                [
                    "front",
                    1
                ],
                [
                    "engine",
                    1
                ],
                [
                    "knowledge",
                    1
                ],
                [
                    "cell",
                    1
                ],
                [
                    "methanol",
                    1
                ],
                [
                    "vertex",
                    1
                ],
                [
                    "track",
                    1
                ],
                [
                    "element",
                    1
                ],
                [
                    "yeah",
                    1
                ],
                [
                    "model",
                    1
                ]
            ],
            "description": "Natural language processing (Wikipedia): \u201cNatural language processing (NLP) is a field of computer science, artificial intelligence, and computational linguistics concerned with the interactions between computers and human (natural) languages",
            "dislikeCount": "2",
            "duration": "PT5M8S",
            "likeCount": "34",
            "published_time": "2017-06-10T14:06:08.000Z",
            "tags": [
                "NLP",
                "NLP in tamil",
                "Natural language processing",
                "NLP tamil"
            ],
            "thumbnail": "https://i.ytimg.com/vi/uCUdlM8KnPk/hqdefault.jpg",
            "title": "Introduction to Natural Language Processing in Tamil | NLP",
            "transcript": "  hello guys welcome back to our tech town tutorials I'm individual in the Box wanna NLP having a booty poppin off NLP of Nenana natural language processing yeah natural language up nanana monetary values for the Korean language it up natural language eponymous our personal modern art Okun hindi KO on America pakka English R&amp;R Allah Arabic a sauna over the persona memory money release colloquial language down natural language so in the language and work process Pune for other that natural language processing if were upon our a for a vicious and normally certain and Sultana now sold another poem you know na soloq Korea reach it under sample korea kappa break even they are Ricky Ricky are they sitting over computer to Sultana I look at the cream al China Korea you know Ricky and also appreciate understand Peru Korea caliber Tierra Korea so you get in there to remain upon a piranha and the computer train Monica other than I in a solo for angry they are they understand for every time one of four eeper there on the chrome them on live ordinary she ready you know are you volume for Uruguay today when you're Walla Walla Valera 60 external pacer a positive as a listen Milotic isaac aluminum appear Solingen so or they might not given the computer owns it on numerically away you know gamma decay so Luca Luca no in the Mallory in the money now so Nana are the Queen Indumati Barcelona on getting even better natural language person other than a mother computer tiny mini tip are they Jeffrey react phenomenal register Saldana are the key every single body salon owner up insulted not try Manipur so he does natural language Cranston so if a example expose on mom Nair Emily Spier P high key sniffing a high close this not a sharp little tip for each article so I'll return my end up no more message panel methanol kill play pond so either love the natural language processing is Juanita ponies fungus so if natural language processing an infringer come so the natural language processing an area we say milky so Mahalo art activity report on individual number are the keys for CUDA tool Salafi no mean cell phone of work say principles knowledge a Python miss Felicia now program in front of Allah Sonya first in a container by this does text czar in the librarians are pretty common vertex plop is paulina Python learn on a program for Nepal so in the text scrap on this NL TK base paneer K so my Delta n Delta J is phenomenal coil of text blah peaceful today call your ECI Kosala noggin our text block these mantras so in the text club between is Connor pasta is solemn on the NLT kate del tower I mean Zarkon how's it nice on a layer the man but no more is it the Sunnah I liked in BR the body so no so all the key so on the library is trying many keep on trying Delta on this a chip on upon our own car track there will be a NLT key data you don't in the computer on this time minute Akana so main the Missouri for a record Scoob Moreno my response for no no no no Mary Ellen Willard wanna model data Salem a a chip on data sets from the HT fungus the Proform looking for you Chandra so in the data engine off a sheet down low for no so the F together soda in a potato pies done in post general TK in LT k we import consumer equal English tea K dot download on this download function fuller are all day town will create online so if I end up antenna you click on your letter on Vienna on the data element size connect Pierce so another unit our already made furnace here one here which give it a quarter turn upon oppression Ella then complete a town of I'm using a couple monomer hopefulness are we came with you know made along the power of quantum theory Guerrero so another we complete a tower or everything anyways partner us eyes connect Pierce's so NOLA tomorrow receive a polymer now Audrey toner pointers on all the questioner beeper number if I over logo introduction is learns return again so no Martha vanilla program for no no maybe approaching the like polymers are pregnant YouTube channel subscriber Nina thanks for watching",
            "userFeedbackScore": 0.3745833333333333,
            "videoid": "uCUdlM8KnPk",
            "viewCount": "2386"
        },
        "w9OUpjiu_zg": {
            "NumOfComments": 2,
            "caption_exist": "T",
            "channel_id": "UCQJr7YGI_e8lzhLjsroFVDQ",
            "channel_title": "Aditya Ambasth",
            "comment_sentiment": 0.08354978354978355,
            "concepts": [
                [
                    "approach",
                    21
                ],
                [
                    "rule",
                    21
                ],
                [
                    "based",
                    20
                ],
                [
                    "data",
                    16
                ],
                [
                    "machine",
                    13
                ],
                [
                    "machine learning",
                    13
                ],
                [
                    "rule-based approach",
                    10
                ],
                [
                    "algorithm",
                    9
                ],
                [
                    "set",
                    9
                ],
                [
                    "pattern",
                    9
                ],
                [
                    "list",
                    8
                ],
                [
                    "ip address",
                    7
                ],
                [
                    "called",
                    5
                ],
                [
                    "feedback",
                    5
                ],
                [
                    "static",
                    5
                ],
                [
                    "machine learning based approach",
                    5
                ],
                [
                    "science",
                    4
                ],
                [
                    "spam email",
                    4
                ],
                [
                    "account",
                    4
                ],
                [
                    "service",
                    4
                ],
                [
                    "understand",
                    4
                ],
                [
                    "email service",
                    4
                ],
                [
                    "domain knowledge",
                    3
                ],
                [
                    "dynamic",
                    3
                ],
                [
                    "explicitly marked",
                    3
                ],
                [
                    "large body",
                    3
                ],
                [
                    "spam detection",
                    3
                ],
                [
                    "email id",
                    3
                ],
                [
                    "class",
                    3
                ],
                [
                    "key difference",
                    3
                ],
                [
                    "knowledge",
                    3
                ],
                [
                    "defining characteristic",
                    2
                ],
                [
                    "historical",
                    2
                ],
                [
                    "stuff",
                    2
                ],
                [
                    "historical data",
                    2
                ],
                [
                    "first",
                    2
                ],
                [
                    "complex rule",
                    2
                ],
                [
                    "content",
                    2
                ],
                [
                    "system",
                    2
                ],
                [
                    "fall",
                    2
                ],
                [
                    "mechanism",
                    2
                ],
                [
                    "long time",
                    2
                ],
                [
                    "white list",
                    2
                ],
                [
                    "second",
                    1
                ],
                [
                    "form",
                    1
                ],
                [
                    "pretty",
                    1
                ],
                [
                    "first principle",
                    1
                ],
                [
                    "mean",
                    1
                ],
                [
                    "arm",
                    1
                ],
                [
                    "ml",
                    1
                ],
                [
                    "google",
                    1
                ],
                [
                    "method",
                    1
                ],
                [
                    "help",
                    1
                ],
                [
                    "sign",
                    1
                ],
                [
                    "pump",
                    1
                ],
                [
                    "genetics",
                    1
                ],
                [
                    "walk",
                    1
                ],
                [
                    "computer",
                    1
                ],
                [
                    "application",
                    1
                ],
                [
                    "map",
                    1
                ],
                [
                    "response",
                    1
                ],
                [
                    "process",
                    1
                ],
                [
                    "course",
                    1
                ],
                [
                    "frequency",
                    1
                ],
                [
                    "production",
                    1
                ],
                [
                    "future",
                    1
                ],
                [
                    "computer science",
                    1
                ],
                [
                    "classification",
                    1
                ],
                [
                    "rule-based system",
                    1
                ],
                [
                    "production system",
                    1
                ],
                [
                    "quality",
                    1
                ]
            ],
            "description": "",
            "dislikeCount": "7",
            "duration": "PT16M32S",
            "likeCount": "19",
            "published_time": "2016-08-24T15:03:11.000Z",
            "tags": [],
            "thumbnail": "https://i.ytimg.com/vi/w9OUpjiu_zg/hqdefault.jpg",
            "title": "1 Machine Learning and Natural Language Processing Tutorial",
            "transcript": "  machine learning is quite a big buzzword these days it's been around for a long time but these days it's applications are wide and far ranging from computer science to genetics to even the social sciences now from the outside it seems like an abstract science a little obscure heavy on the map difficult to understand a little bit like rocket science but it's really not like anything else if you take the time to understand it from first principles you really get what's going on we will take an example and walk you through how machine learning is useful in this particular example and what you can do with it okay let's get started what is machine learning when is it appropriate to use it then should you use it instead of say something like a rule-based approach that's what we'll cover in this class if machine learning is a car this class will tell you what a car is why you should drive it and when you should drive it let's consider the problem of spam detection have you ever received a lot of emails from people who are trying to sell you stuff and they just clutter up your inbox this is what's called spam say you use any email service and suddenly you started getting a lot of emails from people trying to sell you stuff or getting you to sign up for things that you are not really interested in these can blow up really quickly and start cluttering up your inbox and just obscuring the really meals that you want to see these are generally called harm emails and the irrelevant ones are called spam emails wouldn't it be nice if your email service would be able to automatically detect or filter out the irrelevant emails or spam emails so that you would never have to see them that's exactly what Gmail and a lot of other email services do they filter out emails or spam emails from your inbox before they even reach you now imagine that you work at a large email service something like say Gmail at Google and you need to do the same thing you have to actually solve this problem of spam detection what you need to do is to figure out a way to test if emails coming in to inboxes are spam or HAMB HAMB is what non-spam emails are called as I just mentioned the basic idea is that you would be able to monitor the attributes of different emails that are coming in to inboxes and some of these attributes would be able to tell you whether that email is a spam email or a Hannigan so it's your job to figure out how do you automatically mark something as far with up one way of doing this is to use something called a rule-based approach what you would do is you would define a set of rules these are things that you would check for before you allow an email to pass into an inbox or before you mark some email to be spam how do you come up with these rules some are intuitive and logical such as say all the emails from people in your contact list are not spam some would be based on domain knowledge such as emails from certain kinds of IP addresses which generally spammers use should be marked as spam some would be a basis some study of patterns in historical data so you would have to spend a lot of time have a lot of domain knowledge to actually figure out what the rules to be used are let's say you did all of that you spend weeks or months on it and came up with a certain set of rules these are the rules that you came up with any email from a certain IP address or email id is spam you found that there were a list of emails or IP addresses from which the emails are mostly marked as spam so let's maintain a blacklist of emails and you would create this blacklist after studying the patterns in some historical data just like you have a blacklist you could always have a whitelist as well you can say that any email from a contact of a contact is not spam so all emails from your contacts and their contacts are white listed for a particular email these are all based on the sender of the email you can also look at what the email actually contains what the subject is and what the content is any email containing a set of set of certain set of words which you know to be spammy can be considered spam this could be words like sell or offer or things like that these are just some examples of different rules that you can come up with you can have a lot more complex rules as well such as an email from a certain IP address with a certain frequency and if the recipient has not opened X percent of those emails something like that a very complex rule could also be set up great you have done all of this and you set up a rule-based system and it seems to be working well not just that don't forget you put in a lot of effort to figure out what the rules are now the problem is a rule-based approach to a problem like spam detection is that the rules that we can come up with a rather static and they change really slowly what does that mean as you can see most of the rules that we came up with above consists of some lists like a blacklist a white list of senders and the black list or a white list of words now maintaining this list and actually updating them is a very cumbersome process not just at any production system which implements these rules would be difficult to build and hard to update with new rules say you want to add a new rule or you want to update the list of an old on the other hand the behavior patterns of spammers a pretty dynamic so they are really smart and they can figure out what you are doing and they change superfast in response to those rules for example they'll immediately figure out that one IP address or email ID is being blocked and start using a new email address or IP address they can also respond really quickly to the words being marked as spam and start sending different kinds of emails with different words or different titles or there might be news farmers that are coming up with who use different words and you have not taken that into account now an alternative to a rule-based approach what might that be think not so heavily reliant on having an analyst or a modeler who will take a long time to understand the patterns in the data or someone with a lot of domain knowledge of how these farmers work all of this was not taking into account something that was available to us from the beginning the users themselves are marking each email as per more ham if they mark it as spam it's spam of course and if they don't ten'll Siham email you could figure out the patterns in the kinds of emails that are explicitly marked as spam by users let's consider for a second that there was some way to look at all the data that's exclusively marked as farmed by the user and automatically figure out what the patterns in that are then what you do when a new email comes in is to check whether that email confirms to those patterns or not now what might these patterns be we'll get to that in a bit but let's consider that you could do it if yes we'll mark it as spam and if not we'll mark it as ham this is basically what a machine learning based approach is what is the key difference here the use of the data or the email that are explicitly mark by users that is the difference let's just go through each method again and see what the key differences are first let's see the rule-based approach we'll start with an input which is an email that is coming into some inbox this email is then passed through an algorithm which applies the rules that we have come up with so it checks this email and its attributes against all of those rules the output is a verdict which says whether this email is firm or half so the algorithm that applies the rules is the program the email which came in is the input and this far more ham Burdick is the output now the main thing to note here is that this approach is static the algorithm that applies a rule doesn't really change based on whether it's working or not once somebody sets it up there is no real feedback loop it's just static until you go and change it again remember that users are giving us feedback on the quality of the algorithm they are marking emails as spam explicitly or the me mails that you are marking as pump they might be marking as but this rule-based approach is not taking that into account at all this static algorithmic approach is missing out on the opportunity to improve itself based on feedback that user actions provide it's not taking into account feedback that is available to it so what happens this farmers are really spot they keep masking their IP addresses changing their email ids and they alter what they are seeking to sell it change the words and the content of the subjects and the emails and a rule-based approach will slowly just fall behind it will not on for all these changes that are happening it's just inevitable that it will become obsolete let's move on to the machine learning based approach in this approach we'll have a similar setup the input or the email comes in it passes through a machine learning based spam classifier pay attention to the term classifier this is actually a standard term that's used in machine learning then it actually checks with the corpus this is a large body of spam and harm emails how did we get this corpus these are the emails that are explicitly marked as pom or ham by our users it gets some input from that large body of spam and harm emails and uses that to do its classification then it outputs a verdict whether that email is spam or ham what is the key difference between this and the previous example of the rule-based approach the machine learning based approach varies its algorithm the box which contains algorithm of the program is changing based on what the data tells it so it adjusts itself based on the data the corpus is dynamic and can constantly be updated with the users input since there is a dynamic input mechanism that's existing and the algorithm keeps adjusting itself based on that it will not fall behind like the rule based approached it it will always keep up with what is happening in the real world this feedback mechanism and varying the algorithm based on the data is what identifies a machine learning approach on the other hand the rule-based approach was static it did not have any way to update itself based on what the data then said and therefore it became obsolete and fell behind remember we've never said anything about which approach is more complex in fact the amount of effort that goes in and the number of rules that you would have to come up with to be really effective would make it such that the rule-based approach could be more complex so it could be more complex but less accurate or less up-to-date in any case it's not complexity that is the defining characteristic of a machine learning based approach the defining based approach is that it adjusts itself based on data the algorithm that is used to classify something or to produce an output adjusts itself based on the data this is the defining characteristic of a machine learning based approach so we've seen what machine learning is we have seen what a car is so now that you know what a car is and when you can drive it it's time to learn how to drive we spoke about how our ml based arm detector would learn from a corpus of data learning just means identifying what the patterns are in that corpus of data and using them to make decisions in the future the corpus is just a word for a large collection of data it could be a large body of documents or text or some data that you want to use here the emails explicitly marked up by users as form or harm is the corpus so what are some of the ways in which we could learn from a set of data how do we drive lets cycle through a few different techniques in the next couple of classes this will help you understand what kind of possibilities are there",
            "userFeedbackScore": 0.19694638694638694,
            "videoid": "w9OUpjiu_zg",
            "viewCount": "3763"
        },
        "yKN8a8jgIN8": {
            "NumOfComments": 1,
            "caption_exist": "T",
            "channel_id": "UC5rOnSvWwxdul6tx-Vkpbyw",
            "channel_title": "Nury Amanmadov",
            "comment_sentiment": 1.0,
            "concepts": [
                [
                    "watson",
                    8
                ],
                [
                    "flick",
                    7
                ],
                [
                    "matrix",
                    6
                ],
                [
                    "movie",
                    5
                ],
                [
                    "stuff",
                    2
                ],
                [
                    "machine learning",
                    1
                ],
                [
                    "search engine",
                    1
                ],
                [
                    "called",
                    1
                ],
                [
                    "rule",
                    1
                ]
            ],
            "description": "Working principle of An AI machine built by IBM",
            "dislikeCount": "3",
            "duration": "PT2M55S",
            "likeCount": "41",
            "published_time": "2015-08-07T13:00:35.000Z",
            "tags": [
                "Machine Learning (Software Genre)",
                "Natural Language Processing (Software Genre)",
                "Artificial Intelligence (Industry)",
                "Data Mining (Software Genre)"
            ],
            "thumbnail": "https://i.ytimg.com/vi/yKN8a8jgIN8/hqdefault.jpg",
            "title": "Machine Learning , Natural Language Processing  and Artificial Intelligence all in - IBM Watson",
            "transcript": "  consider this clue Keanu Reeves had a Nokia phone but it took a landline to slip in and out of this the title of a 1999 sci-fi flick the correct response is what is the matrix but how can one sand figure that out first he breaks down the clue into grammatical parts identifying key words and phrases then Watson's powerful search engines churn through millions of documents including the Internet Movie Database we do next is we take these documents and we pull out candidate and answers and we'll pull out okay Keanu Reeves that could be candidate I pull out Nokia will pull out the matrix other movie starring Keanu Reeves also become possible answers we'll pull out the matrix to pull out Speed Bill and Ted's Excellent Adventure all this stuff and Watson pulls out other famous sci-fi flicks like Blade Runner and it generates hundreds of possible answers with hundreds of choices how can Watson pick the one answer that's correct next thing that Watson is going to do is going to take those answers and say well let's assume all of them might be right so these are its competing hypotheses Watson starts considering evidence for and against each candidate using rules like a movie is sometimes called a flick and we'll look at things like well it's looking for a flick is this candid answer flick is the matrix a flick yes it's speed a flag yes this counter is a flip no all right so we're starting to learn something within a matter of milliseconds Watson analyzes every possible answer in hundreds of different ways and scores each piece of evidence behind every answer in the list that's a lot of scores problem is you have all these different scores and they don't agree you know some of the scores are gonna say the matrix is the right answer some of the scores gonna say camera reads the right answer so we're gonna think matrix 2 is the right answer and a lot of scores think Bladerunner is the right answer because it shows up so often as a sci-fi play so you need someone at the end to listen to all these different votes and decide what's the best answer this is where Watson's machine-learning kicks in having studied thousands of other jeopardy questions and their correct answers Watson has learned what evidence is important and what's not what machine learning will start to do is learn how to weigh them differently and say wait questions like this calling on a phone not calling on a phone not so important on this other stuff will have a sci-fi movie is the person named the character in that movie very very important for questions like this in this case he successfully weighs the evidence and identifies sci-fi flicks from 1999 starring Keanu Reeves so he picks the one answer matching all those elements the matrix",
            "userFeedbackScore": 0.959090909090909,
            "videoid": "yKN8a8jgIN8",
            "viewCount": "14645"
        }
    }
}